{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ad9f9fa2098c418db796754ba426aee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_162ec182002949c996a13bece9e69792",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_42fd2f0612bf4ba5b4bd40b7e95e36da",
              "IPY_MODEL_a007f63f66374ef18694c40efe5ad825"
            ]
          }
        },
        "162ec182002949c996a13bece9e69792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42fd2f0612bf4ba5b4bd40b7e95e36da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8de47aa928164cf488755ce592cfdd3c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f60bb2ab062d44e787ef7a62437d17a7"
          }
        },
        "a007f63f66374ef18694c40efe5ad825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_111c8b1bd5a548e78c3b4fd4943af55d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 3.24MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc70c306bd794693b865e15418c31d1c"
          }
        },
        "8de47aa928164cf488755ce592cfdd3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f60bb2ab062d44e787ef7a62437d17a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "111c8b1bd5a548e78c3b4fd4943af55d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc70c306bd794693b865e15418c31d1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "228cb30c960a44539f4957675b3b22f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4331f0360a1f47b7861435a2e995bc40",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee0019534a404efbb71b926d160cfd5d",
              "IPY_MODEL_dd9b82d3e2da4215a8ed2a9231904373"
            ]
          }
        },
        "4331f0360a1f47b7861435a2e995bc40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee0019534a404efbb71b926d160cfd5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d682e4300a6f4508a4b9d7e807e88277",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25dea491556a47b1a2844e0e27f63625"
          }
        },
        "dd9b82d3e2da4215a8ed2a9231904373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ecf43bf9550411583c0a0210c2c2905",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 4.45MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b8e4991dd934f068c8b786393388aba"
          }
        },
        "d682e4300a6f4508a4b9d7e807e88277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25dea491556a47b1a2844e0e27f63625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ecf43bf9550411583c0a0210c2c2905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b8e4991dd934f068c8b786393388aba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8171f292265e423f82ed521ebb564d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ed37fb829b434a79a2637184be46b8ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5279cfe0b2204d75babadb856b20f6f7",
              "IPY_MODEL_899a10016b024b40904d0a4c9a201e18"
            ]
          }
        },
        "ed37fb829b434a79a2637184be46b8ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5279cfe0b2204d75babadb856b20f6f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_659bdb3155974348bd9051ded4a0e0e4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01f0acdb50c041b8993aad30dade4a34"
          }
        },
        "899a10016b024b40904d0a4c9a201e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08a47c95565f4fccb647c5efd2c919e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:15&lt;00:00, 31.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e58b74e744d44802be32044f5d14e390"
          }
        },
        "659bdb3155974348bd9051ded4a0e0e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01f0acdb50c041b8993aad30dade4a34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08a47c95565f4fccb647c5efd2c919e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e58b74e744d44802be32044f5d14e390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bf168827d36444a811962d56487858e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d6fcb08c3b549dd9a671075e0a08f50",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d1be5c7de14741daaf3b68ccf17e216a",
              "IPY_MODEL_217d4f27224d4c2081acb7fda7331a5b"
            ]
          }
        },
        "0d6fcb08c3b549dd9a671075e0a08f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1be5c7de14741daaf3b68ccf17e216a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7a85d6b816cc43c498290a00858faf39",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b2c07e985fa437d84d85e1bcbcd4cc0"
          }
        },
        "217d4f27224d4c2081acb7fda7331a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fbe274e5286e48f9a96a99caeabea434",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:08&lt;00:00, 59.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2153f4283f994af58e287150ceae1e5a"
          }
        },
        "7a85d6b816cc43c498290a00858faf39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b2c07e985fa437d84d85e1bcbcd4cc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbe274e5286e48f9a96a99caeabea434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2153f4283f994af58e287150ceae1e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "colab": {
      "name": "fastai-with-transformers-bert-roberta.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohitJuneja/FinBERT-1/blob/master/fastai_with_transformers_bert_roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT-5eulWtDSH"
      },
      "source": [
        "# Fastai with HuggingFace ðŸ¤—Transformers (BERT, RoBERTa, XLNet, XLM, DistilBERT)\n",
        "\n",
        "![fastai + Transformers](https://i.ibb.co/qspmrcm/fastai-transformers-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxqWmoQltDSN"
      },
      "source": [
        "N.B. This implementation is a supplement of the Medium article [\"Fastai with ðŸ¤—Transformers (BERT, RoBERTa, XLNet, XLM, DistilBERT)\"](https://medium.com/p/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2?source=email-29c8f5cf1dc4--writer.postDistributed&sk=119c3e5d748b2827af3ea863faae6376).\n",
        "\n",
        "**Also, remember the upvote button is next to the fork button, and it's free too!** ðŸ˜‰"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ4cQo0ztDSP"
      },
      "source": [
        "# Introduction : Story of transfer learning in NLP\n",
        "In early 2018, Jeremy Howard (co-founder of fast.ai) and Sebastian Ruder introduced the  [Universal Language Model Fine-tuning for Text Classification](https://medium.com/r/?url=https%3A%2F%2Farxiv.org%2Fpdf%2F1801.06146.pdf) (ULMFiT) method. ULMFiT was the first **Transfer Learning** method applied to NLP. As a result, besides significantly outperforming many state-of-the-art tasks, it allowed, with only 100 labeled examples, to match performances equivalent to models trained on 100Ã—  more data.\n",
        "\n",
        "The first time I heard about ULMFiT was during a [fast.ai course](https://course.fast.ai/videos/?lesson=4) given by Jeremy Howard. He demonstrated how it was easy â€Š-â€Š thanks to the ``fastai`` library â€Š-â€Š to implement the complete ULMFit method with only a few lines of codes. In his demo, he used an AWD-LSTM neural network pre-trained on Wikitext-103 and get rapidly state-of-the-art results. He also explained key techniques - also demonstrated in ULMFiT - to fine-tune the models like **Discriminate Learning Rate**, **Gradual Unfreezing** or **Slanted Triangular Learning Rates**.\n",
        "\n",
        "Since the introduction of ULMFiT, **Transfer Learning** became very popular in NLP and yet Google (BERT, Transformer-XL, XLNet), Facebook (RoBERTa, XLM) or even OpenAI (GPT, GPT-2) begin to pre-train their own model on very large corpora. This time, instead of using the AWD-LSTM neural network, they all used a more powerful architecture based on the Transformer (cf. [Attention is all you need](https://arxiv.org/abs/1706.03762)).\n",
        "\n",
        "Although these models are powerful, ``fastai`` do not integrate all of them. Fortunately, [HuggingFace](https://huggingface.co/) ðŸ¤— created the well know [transformers library](https://github.com/huggingface/transformers). Formerly knew as ``pytorch-transformers`` or ``pytorch-pretrained-bert``, this library brings together over 40 state-of-the-art pre-trained NLP models (BERT, GPT-2, RoBERTa, CTRLâ€¦). The implementation gives interesting additional utilities like tokenizer, optimizer or scheduler.\n",
        "\n",
        "The ``transformers`` library can be self-sufficient but incorporating it within the ``fastai`` library provides simpler implementation compatible with powerful fastai tools like  **Discriminate Learning Rate**, **Gradual Unfreezing** or **Slanted Triangular Learning Rates**. The point here is to allow anyone â€” expert or non-expert â€” to get easily state-of-the-art results and to â€œmake NLP uncool againâ€.\n",
        "\n",
        "It worth noting that the integration of the HuggingFace ``transformers`` library in ``fastai`` has already been demonstrated in:\n",
        "* Keita Kurita's article [A Tutorial to Fine-Tuning BERT with Fast AI](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/) which makes ``pytorch_pretrained_bert`` library compatible with ``fastai``.\n",
        "* Dev Sharma's article [Using RoBERTa with Fastai for NLP](https://medium.com/analytics-vidhya/using-roberta-with-fastai-for-nlp-7ed3fed21f6c) which makes ``pytorch_transformers`` library compatible with ``fastai``.\n",
        "\n",
        "Although these articles are of high quality, some part of their demonstration is not anymore compatible with the last version of ``transformers``.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8wlAAnDtDSP"
      },
      "source": [
        "# ðŸ›  Integrating transformers with fastai for multiclass classification\n",
        "Before beginning the implementation, note that integrating ``transformers`` within ``fastai`` can be done in multiple different ways. For that reason, I decided to bring simple solutions, that are the most generic and flexible. More precisely, I try to make the minimum of modification in both libraries while making them compatible with the maximum amount of transformer architectures.\n",
        "\n",
        "Note that in addition to this NoteBook and the [Medium article](https://medium.com/p/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2?source=email-29c8f5cf1dc4--writer.postDistributed&sk=119c3e5d748b2827af3ea863faae6376), I made another version available on my GitHub(TODO add link)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_moOKeIatDSQ"
      },
      "source": [
        "## Libraries Installation\n",
        "Before starting the implementation, you will need to install the ``fastai`` and ``transformers`` libraries. To do so, just follow the instructions [here](https://github.com/fastai/fastai/blob/master/README.md#installation) and [here](https://github.com/huggingface/transformers#installation).\n",
        "\n",
        "In Kaggle, the ``fastai`` library is already installed. So you just have to instal ``transformers`` with :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbjAszKrtDSR",
        "outputId": "a56a07e0-b6c2-4b01-9eb9-ee18a07889ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#%%bash\n",
        "!pip install transformers==2.5.1\n",
        "!pip install fastai==1.0.58"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 501kB 13.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 52.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (4.41.1)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/31/4d4861a90d66c287a348fd17eaefefcdc2e859951cab9884b555923f046d/boto3-1.16.23-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 38.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 54.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (1.18.5)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.7MB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (3.0.12)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.20.0,>=1.19.23\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/49/c8c99477416fdebb59078bda624acc5b3c7008f891c60d56d6ff1570d83e/botocore-1.19.23-py2.py3-none-any.whl (6.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.9MB 49.8MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.1) (0.17.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (2.10)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.23->boto3->transformers==2.5.1) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=681ba35c0c5057e2060952d82d4d954e42fead394b6916d9eae1b9dfc6871835\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "\u001b[31mERROR: botocore 1.19.23 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sentencepiece, jmespath, botocore, s3transfer, boto3, sacremoses, tokenizers, transformers\n",
            "Successfully installed boto3-1.16.23 botocore-1.19.23 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.5.2 transformers-2.5.1\n",
            "Collecting fastai==1.0.58\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/88/386289f6926a59cbd2765b033f5fe8414d6ff89ab27044dffe740cc1a5f3/fastai-1.0.58-py3-none-any.whl (236kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245kB 15.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (1.1.4)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (1.18.5)\n",
            "Requirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (1.0.0)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (1.3.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (7.0.0)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (7.352.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (0.8.1+cu101)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (1.4.1)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (2.2.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (3.2.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (20.4)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (0.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (3.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (4.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai==1.0.58) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai==1.0.58) (2.8.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (2.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (50.3.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (0.8.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (3.0.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.58) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.58) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.58) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastai==1.0.58) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai==1.0.58) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai==1.0.58) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.58) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.58) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.58) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.58) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.58) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.58) (3.4.0)\n",
            "Installing collected packages: fastai\n",
            "  Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "Successfully installed fastai-1.0.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "HlB6EnvFtDSU"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from pathlib import Path \n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "import random \n",
        "\n",
        "# fastai\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "\n",
        "# transformers\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
        "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoaL7vartDSZ"
      },
      "source": [
        "The current versions of the fastai and transformers libraries are respectively 1.0.58 and 2.5.1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niiPL5jstDSa",
        "outputId": "39fa1074-1de2-430f-ee11-c2511a6820d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import fastai\n",
        "import transformers\n",
        "print('fastai version :', fastai.__version__)\n",
        "print('transformers version :', transformers.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fastai version : 1.0.58\n",
            "transformers version : 2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8inJcAetDSe"
      },
      "source": [
        "## ðŸŽ¬ The exampleÂ task\n",
        "The chosen task is a multi-class text classification on [Movie Reviews](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/overview).\n",
        "\n",
        "For each text movie review, the model has to predict a label for the sentiment. We evaluate the outputs of the model on classification accuracy. The sentiment labels are:\n",
        "* 0 â†’ Negative\n",
        "* 1 â†’ Somewhat negative\n",
        "* 2 â†’ Neutral\n",
        "* 3 â†’ Somewhat positive\n",
        "* 4 â†’ Positive\n",
        "\n",
        "The data is loaded into a ``DataFrame`` using ``pandas``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-nk7I35tyMs",
        "outputId": "57dc0575-0521-4d25-96d5-c6ffc5da6f6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir sentiment-analysis-on-movie-reviews\n",
        "!mv *.zip sentiment-analysis-on-movie-reviews/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat '*.zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PE8nHvwtDSe",
        "outputId": "dad6affd-a9a3-4aae-9618-3af601a56c36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for dirname, _, filenames in os.walk('.'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./.config/gce\n",
            "./.config/config_sentinel\n",
            "./.config/.last_opt_in_prompt.yaml\n",
            "./.config/.last_survey_prompt.yaml\n",
            "./.config/active_config\n",
            "./.config/.last_update_check.json\n",
            "./.config/.metricsUUID\n",
            "./.config/logs/2020.11.13/17.33.44.836274.log\n",
            "./.config/logs/2020.11.13/17.33.22.211003.log\n",
            "./.config/logs/2020.11.13/17.33.45.553060.log\n",
            "./.config/logs/2020.11.13/17.33.29.478721.log\n",
            "./.config/logs/2020.11.13/17.32.45.071309.log\n",
            "./.config/logs/2020.11.13/17.33.07.342211.log\n",
            "./.config/configurations/config_default\n",
            "./sentiment-analysis-on-movie-reviews/train.tsv.zip\n",
            "./sentiment-analysis-on-movie-reviews/test.tsv.zip\n",
            "./sample_data/README.md\n",
            "./sample_data/anscombe.json\n",
            "./sample_data/california_housing_train.csv\n",
            "./sample_data/mnist_train_small.csv\n",
            "./sample_data/mnist_test.csv\n",
            "./sample_data/california_housing_test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "TsmyQIcstDSi",
        "outputId": "4f63c531-f48c-47c3-ed24-ea2230d14a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "DATA_ROOT = Path(\".\") / \"./sentiment-analysis-on-movie-reviews\"\n",
        "train = pd.read_csv(DATA_ROOT / 'train.tsv.zip', sep=\"\\t\")\n",
        "test = pd.read_csv(DATA_ROOT / 'test.tsv.zip', sep=\"\\t\")\n",
        "print(train.shape,test.shape)\n",
        "train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(156060, 4) (66292, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wNb0V7atDSl"
      },
      "source": [
        "It is worth noting that in the dataset there are no individual movie reviews but rather phrases taken out of context and split into smaller parts, each with an assigned sentiment label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VLEkIZ4tDSm"
      },
      "source": [
        "## Main transformers classes\n",
        "In ``transformers``, each model architecture is associated with 3 main types of classes:\n",
        "* A **model class** to load/store a particular pre-train model.\n",
        "* A **tokenizer class** to pre-process the data and make it compatible with a particular model.\n",
        "* A **configuration class** to load/store the configuration of a particular model.\n",
        "\n",
        "For example, if you want to use the Bert architecture for text classification, you would use [``BertForSequenceClassification``](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification) for the **model class**, [``BertTokenizer``](https://huggingface.co/transformers/model_doc/bert.html#berttokenizer) for the **tokenizer class** and [``BertConfig``](https://huggingface.co/transformers/model_doc/bert.html#bertconfig) for the **configuration class**.Â \n",
        "\n",
        "In order to switch easily between classes â€Š-â€Š each related to a specific model type â€Š-â€Š I created a dictionary that allows loading the correct classes by just specifying the correct model type name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shQV2DQitDSn"
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
        "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
        "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAHN-e3itDSs"
      },
      "source": [
        "You will see later, that those classes share a common class method ``from_pretrained(pretrained_model_name,Â ...)``. In our case, the parameter ``pretrained_model_name`` is a string with the shortcut name of a pre-trained model/tokenizer/configuration to load, e.g ``'bert-base-uncased'``. We can find all the shortcut names in the transformers documentation [here](https://huggingface.co/transformers/pretrained_models.html#pretrained-models)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXKtucSutDSt"
      },
      "source": [
        "# Parameters\n",
        "seed = 42\n",
        "use_fp16 = False\n",
        "bs = 16\n",
        "\n",
        "model_type = 'roberta'\n",
        "pretrained_model_name = 'roberta-base'\n",
        "\n",
        "# model_type = 'bert'\n",
        "# pretrained_model_name='bert-base-uncased'\n",
        "\n",
        "# model_type = 'distilbert'\n",
        "# pretrained_model_name = 'distilbert-base-uncased'\n",
        "\n",
        "#model_type = 'xlm'\n",
        "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
        "\n",
        "# model_type = 'xlnet'\n",
        "# pretrained_model_name = 'xlnet-base-cased'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqo7ITB_tDSx"
      },
      "source": [
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_msuwI4ytDS0"
      },
      "source": [
        "Print the available values for ``pretrained_model_name`` (shortcut names) corresponding to the ``model_type`` used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtJD-Gv3tDS0",
        "outputId": "82825d38-7976-43ae-8715-8b473a6eba61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_class.pretrained_model_archive_map.keys()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['roberta-base', 'roberta-large', 'roberta-large-mnli', 'distilroberta-base', 'roberta-base-openai-detector', 'roberta-large-openai-detector'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGRmwPwQtDS3"
      },
      "source": [
        "It is worth noting that in this case, we use the ``transformers`` library only for a multi-class text classification task. For that reason, this tutorial integrates only the transformer architectures that have a model for sequence classification implemented. These model types areÂ :\n",
        "* BERT (from Google)\n",
        "* XLNet (from Google/CMU)\n",
        "* XLM (from Facebook)\n",
        "* RoBERTa (from Facebook)\n",
        "* DistilBERT (from HuggingFace)\n",
        "\n",
        "However, if you want to go furtherâ€Š-â€Šby implementing another type of model or NLP taskâ€Š-â€Šthis tutorial still an excellent starter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luhkLogAtDS4"
      },
      "source": [
        "## Util function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytP2q9FAtDS4"
      },
      "source": [
        "Function to set the seed for generating random numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNb1r0cptDS5"
      },
      "source": [
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value) # Python\n",
        "    np.random.seed(seed_value) # cpu vars\n",
        "    torch.manual_seed(seed_value) # cpu  vars\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
        "        torch.backends.cudnn.deterministic = True  #needed\n",
        "        torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFs888OltDS9"
      },
      "source": [
        "seed_all(seed)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCiCzpYCtDTA"
      },
      "source": [
        "## Data pre-processing\n",
        "\n",
        "To match pre-training, we have to format the model input sequence in a specific format.\n",
        "To do so, you have to first **tokenize** and then **numericalize** the texts correctly.\n",
        "The difficulty here is that each pre-trained model, that we will fine-tune, requires exactly the same specific pre-processâ€Š-â€Š**tokenization** & **numericalization**â€Š-â€Šthan the pre-process used during the pre-train part.\n",
        "Fortunately, the **tokenizer class** from ``transformers`` provides the correct pre-process tools that correspond to each pre-trained model.\n",
        "\n",
        "In the ``fastai`` library, data pre-processing is done automatically during the creation of the ``DataBunch``. \n",
        "As you will see in the ``DataBunch`` implementation, the **tokenizer** and **numericalizer** are passed in the processor argument under the following format :\n",
        "\n",
        "``processor = [TokenizeProcessor(tokenizer=tokenizer,...), NumericalizeProcessor(vocab=vocab,...)]``\n",
        "\n",
        "Let's first analyse how we can integrate the ``transformers`` **tokenizer** within the ``TokenizeProcessor`` function.\n",
        "\n",
        "### Custom Tokenizer\n",
        "This part can be a little bit confusing because a lot of classes are wrapped in each other and with similar names.\n",
        "To resume, if we look attentively at the ``fastai`` implementation, we notice thatÂ :\n",
        "1. The [``TokenizeProcessor`` object](https://docs.fast.ai/text.data.html#TokenizeProcessor) takes as ``tokenizer`` argument a ``Tokenizer`` object.\n",
        "2. The [``Tokenizer`` object](https://docs.fast.ai/text.transform.html#Tokenizer) takes as ``tok_func`` argument a ``BaseTokenizer`` object.\n",
        "3. The [``BaseTokenizer`` object](https://docs.fast.ai/text.transform.html#BaseTokenizer) implement the function ``tokenizer(t:str) â†’ List[str]`` that take a text ``t`` and returns the list of its tokens.\n",
        "\n",
        "Therefore, we can simply create a new class ``TransformersBaseTokenizer`` that inherits from ``BaseTokenizer`` and overwrite a new ``tokenizer`` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsvrDlPCtDTA"
      },
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type in ['roberta']:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
        "            tokens = [CLS] + tokens + [SEP]\n",
        "        else:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
        "            if self.model_type in ['xlnet']:\n",
        "                tokens = tokens + [SEP] +  [CLS]\n",
        "            else:\n",
        "                tokens = [CLS] + tokens + [SEP]\n",
        "        return tokens"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK1QszFCtDTD",
        "outputId": "b3ca1f38-2387-4333-eda8-bbe0e1dffe35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "ad9f9fa2098c418db796754ba426aee5",
            "162ec182002949c996a13bece9e69792",
            "42fd2f0612bf4ba5b4bd40b7e95e36da",
            "a007f63f66374ef18694c40efe5ad825",
            "8de47aa928164cf488755ce592cfdd3c",
            "f60bb2ab062d44e787ef7a62437d17a7",
            "111c8b1bd5a548e78c3b4fd4943af55d",
            "fc70c306bd794693b865e15418c31d1c",
            "228cb30c960a44539f4957675b3b22f8",
            "4331f0360a1f47b7861435a2e995bc40",
            "ee0019534a404efbb71b926d160cfd5d",
            "dd9b82d3e2da4215a8ed2a9231904373",
            "d682e4300a6f4508a4b9d7e807e88277",
            "25dea491556a47b1a2844e0e27f63625",
            "1ecf43bf9550411583c0a0210c2c2905",
            "5b8e4991dd934f068c8b786393388aba"
          ]
        }
      },
      "source": [
        "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad9f9fa2098c418db796754ba426aee5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "228cb30c960a44539f4957675b3b22f8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vYBAue0tDTG"
      },
      "source": [
        "In this implementation, be carefull about 3 things :\n",
        "1. As we are not using RNN, we have to limit the sequence length to the model input size.\n",
        "2. Most of the models require special tokens placed at the beginning and end of the sequences.\n",
        "3. Some models like RoBERTa require a space to start the input string. For those models, the encoding methods should be called with ``add_prefix_space`` set to ``True``.\n",
        "\n",
        "Below, you can find the resume of each pre-process requirement for the 5 model types used in this tutorial. You can also find this information on the [HuggingFace documentation](https://huggingface.co/transformers/) in each model section.\n",
        "\n",
        "    bert:       [CLS] + tokens + [SEP] + padding\n",
        "\n",
        "    roberta:    [CLS] + prefix_space + tokens + [SEP] + padding\n",
        "    \n",
        "    distilbert: [CLS] + tokens + [SEP] + padding\n",
        "\n",
        "    xlm:        [CLS] + tokens + [SEP] + padding\n",
        "\n",
        "    xlnet:      padding + tokens + [SEP] + [CLS]\n",
        "    \n",
        "It is worth noting that we don't add padding in this part of the implementation.Â \n",
        "As we will see later, ``fastai`` manage it automatically during the creation of the ``DataBunch``."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b3n0y3HtDTH"
      },
      "source": [
        "### Custom Numericalizer\n",
        "\n",
        "In ``fastai``, [``NumericalizeProcessor``  object](https://docs.fast.ai/text.data.html#NumericalizeProcessor) takes as ``vocab`` argument a [``Vocab`` object](https://docs.fast.ai/text.transform.html#Vocab). \n",
        "From this analyse, we suggest two ways to adapt the fastai numericalizer:\n",
        "1. You can, like decribed in the [Dev Sharma's article](https://medium.com/analytics-vidhya/using-roberta-with-fastai-for-nlp-7ed3fed21f6c) (Section *1. Setting Up the Tokenizer*), retreive the list of tokens and create a ``Vocab`` object.\n",
        "2. Create a new class ``TransformersVocab`` that inherits from ``Vocab`` and overwrite ``numericalize`` and ``textify`` functions.\n",
        "\n",
        "Even if the first solution seems to be simpler, ``Transformers`` does not provide, for all models, a straightforward way to retreive his list of tokens. \n",
        "Therefore, I implemented the second solution, which runs for each model type.\n",
        "It consists of using the functions ``convert_tokens_to_ids`` and ``convert_ids_to_tokens`` in respectively ``numericalize`` and ``textify``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPn0Io7JtDTH"
      },
      "source": [
        "class TransformersVocab(Vocab):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "        super(TransformersVocab, self).__init__(itos = [])\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
        "        \"Convert a list of tokens `t` to their ids.\"\n",
        "        return self.tokenizer.convert_tokens_to_ids(t)\n",
        "        #return self.tokenizer.encode(t)\n",
        "\n",
        "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
        "        \"Convert a list of `nums` to their tokens.\"\n",
        "        nums = np.array(nums).tolist()\n",
        "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
        "    \n",
        "    def __getstate__(self):\n",
        "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
        "\n",
        "    def __setstate__(self, state:dict):\n",
        "        self.itos = state['itos']\n",
        "        self.tokenizer = state['tokenizer']\n",
        "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi3JkKSstDTJ"
      },
      "source": [
        "NB: The functions ``__gestate__`` and ``__setstate__`` allow the functions [export](https://docs.fast.ai/basic_train.html#Learner.export) and [load_learner](https://docs.fast.ai/basic_train.html#load_learner) to work correctly with ``TransformersVocab``."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rECF4LcWtDTK"
      },
      "source": [
        "### Custom processor\n",
        "Now that we have our custom **tokenizer** and **numericalizer**, we can create the custom **processor**. Notice we are passing the ``include_bos = False`` and ``include_eos = False`` options. This is because ``fastai`` adds its own special tokens by default which interferes with the ``[CLS]`` and ``[SEP]`` tokens added by our custom tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNdd-QJPtDTK"
      },
      "source": [
        "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
        "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
        "\n",
        "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "transformer_processor = [tokenize_processor, numericalize_processor]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CM70_wMtDTO"
      },
      "source": [
        "## Setting up the Databunch\n",
        "For the DataBunch creation, you have to pay attention to set the processor argument to our new custom processor ``transformer_processor`` and manage correctly the padding.\n",
        "\n",
        "As mentioned in the HuggingFace documentation, BERT, RoBERTa, XLM and DistilBERT are models with absolute position embeddings, so it's usually advised to pad the inputs on the right rather than the left. Regarding XLNET, it is a model with relative position embeddings, therefore, you can either pad the inputs on the right or on the left."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw1Sza5DtDTO"
      },
      "source": [
        "pad_first = bool(model_type in ['xlnet'])\n",
        "pad_idx = transformer_tokenizer.pad_token_id"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXxdJ5rttDTR",
        "outputId": "18bdcf2e-6eee-41e4-a59e-69837df3012b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokens = transformer_tokenizer.tokenize('Salut c est moi, Hello it s me')\n",
        "print(tokens)\n",
        "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)\n",
        "transformer_tokenizer.convert_ids_to_tokens(ids)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sal', 'ut', 'Ä c', 'Ä est', 'Ä mo', 'i', ',', 'Ä Hello', 'Ä it', 'Ä s', 'Ä me']\n",
            "[18111, 1182, 740, 3304, 7458, 118, 6, 20920, 24, 579, 162]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sal', 'ut', 'Ä c', 'Ä est', 'Ä mo', 'i', ',', 'Ä Hello', 'Ä it', 'Ä s', 'Ä me']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3naUiIRtDTT"
      },
      "source": [
        "There is multible ways to create a DataBunch, in our implementation, we use [the data block API](https://docs.fast.ai/data_block.html#The-data-block-API), which gives more flexibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpaEJYDJtDTT",
        "outputId": "c3697474-adc0-49ae-b37a-c0659bf42a38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "databunch = (TextList.from_df(train, cols='Phrase', processor=transformer_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols= 'Sentiment')\n",
        "             .add_test(test)\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcxhKuOltDTX"
      },
      "source": [
        "Check batch and tokenizer :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNtWiLEjtDTY",
        "outputId": "4704f3b9-3bc4-454a-b9d8-816d7ec818af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
        "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
        "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
        "databunch.show_batch()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] token : <s>\n",
            "[SEP] token : </s>\n",
            "[PAD] token : <pad>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/text/data.py:339: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  idx_min = (t != self.pad_idx).nonzero().min()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; Ä - L RB - Ä City Ä - RR B - Ä reminds Ä us Ä how Ä realistically Ä nuanced Ä a Ä Robert Ä De Ä N iro Ä performance Ä can Ä be Ä when Ä he Ä is Ä not Ä more Ä luc r atively Ä engaged Ä in Ä the Ä shameless Ä self - car ic ature Ä of Ä ` Ä Analy ze Ä This Ä ' Ä - L RB - Ä 1999 Ä - RR B - Ä and Ä ` Ä Analy ze Ä That Ä , Ä ' Ä promised Ä - L RB - Ä or Ä threatened Ä -</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; Ä The Ä real Ä triumph s Ä in Ä Ig by Ä come Ä from Ä Philippe Ä , Ä who Ä makes Ä Oliver Ä far Ä more Ä interesting Ä than Ä the Ä character Ä ' s Ä lines Ä would Ä suggest Ä , Ä and Ä Sar andon Ä , Ä who Ä could Ä n 't Ä be Ä better Ä as Ä a Ä cruel Ä but Ä weird ly Ä lik able Ä WAS P Ä mat ron Ä . &lt;/s&gt;</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; Ä Parker Ä should Ä be Ä comm ended Ä for Ä taking Ä a Ä fresh Ä approach Ä to Ä familiar Ä material Ä , Ä but Ä his Ä determination Ä to Ä remain Ä true Ä to Ä the Ä original Ä text Ä leads Ä him Ä to Ä adopt Ä a Ä somewhat Ä man nered Ä tone Ä ... Ä that Ä ultimately Ä dull s Ä the Ä human Ä tragedy Ä at Ä the Ä story Ä ' s Ä core &lt;/s&gt;</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; Ä It Ä ' s Ä a Ä long Ä way Ä from Ä Orwell Ä ' s Ä dark Ä , Ä intelligent Ä warning Ä cry Ä - L RB - Ä 1984 Ä - RR B - Ä to Ä the Ä empty Ä stud Ä knock about Ä of Ä Equ ilibrium Ä , Ä and Ä what Ä once Ä was Ä conviction Ä is Ä now Ä affect ation Ä . &lt;/s&gt;</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; Ä A Ä different Ä and Ä emotionally Ä reserved Ä type Ä of Ä survival Ä story Ä -- Ä a Ä film Ä less Ä about Ä ref ract ing Ä all Ä of Ä World Ä War Ä II Ä through Ä the Ä specific Ä conditions Ä of Ä one Ä man Ä , Ä and Ä more Ä about Ä that Ä man Ä lost Ä in Ä its Ä midst Ä . &lt;/s&gt;</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXSHX8QPtDTa"
      },
      "source": [
        "Check batch and numericalizer :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABPlre3qtDTa",
        "outputId": "c30f4057-e569-4f7e-d494-ebffc52f3b20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
        "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
        "print('[PAD] id :', pad_idx)\n",
        "test_one_batch = databunch.one_batch()[0]\n",
        "print('Batch shape : ',test_one_batch.shape)\n",
        "print(test_one_batch)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] id : 0\n",
            "[SEP] id : 2\n",
            "[PAD] id : 1\n",
            "Batch shape :  torch.Size([16, 79])\n",
            "tensor([[    0,   111,   574,  ...,    76,   479,     2],\n",
            "        [    0,    33,     7,  ...,     1,     1,     1],\n",
            "        [    0,   318,    47,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0,     5,  2156,  ...,     1,     1,     1],\n",
            "        [    0,    33, 30291,  ...,     1,     1,     1],\n",
            "        [    0, 45518, 10730,  ...,     1,     1,     1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwL2014CtDTe"
      },
      "source": [
        "### Custom model\n",
        "As mentioned [here](https://github.com/huggingface/transformers#models-always-output-tuples), every model's forward method always outputs a ``tuple`` with various elements depending on the model and the configuration parameters. In our case, we are interested to access only to the logits.Â \n",
        "One way to access them is to create a custom model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTky76-vtDTe"
      },
      "source": [
        "# defining our model architecture \n",
        "class CustomTransformerModel(nn.Module):\n",
        "    def __init__(self, transformer_model: PreTrainedModel):\n",
        "        super(CustomTransformerModel,self).__init__()\n",
        "        self.transformer = transformer_model\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        \n",
        "        # attention_mask\n",
        "        # Mask to avoid performing attention on padding token indices.\n",
        "        # Mask values selected in ``[0, 1]``:\n",
        "        # ``1`` for tokens that are NOT MASKED, ``0`` for MASKED tokens.\n",
        "        attention_mask = (input_ids!=pad_idx).type(input_ids.type()) \n",
        "        \n",
        "        logits = self.transformer(input_ids,\n",
        "                                  attention_mask = attention_mask)[0]   \n",
        "        return logits"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFS_x0PttDTh"
      },
      "source": [
        "To make our transformers adapted to multiclass classification, before loading the pre-trained model, we need to precise the number of labels. To do so, you can modify the config instance or either modify like in [Keita Kurita's article](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/) (Section: *Initializing the Learner*) the ``num_labels`` argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOJGa7cVtDTi",
        "outputId": "48e02bec-5d24-427d-97fb-c5fa169dd5ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899,
          "referenced_widgets": [
            "8171f292265e423f82ed521ebb564d88",
            "ed37fb829b434a79a2637184be46b8ea",
            "5279cfe0b2204d75babadb856b20f6f7",
            "899a10016b024b40904d0a4c9a201e18",
            "659bdb3155974348bd9051ded4a0e0e4",
            "01f0acdb50c041b8993aad30dade4a34",
            "08a47c95565f4fccb647c5efd2c919e1",
            "e58b74e744d44802be32044f5d14e390"
          ]
        }
      },
      "source": [
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "config.num_labels = 5\n",
        "config.use_bfloat16 = use_fp16\n",
        "print(config)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8171f292265e423f82ed521ebb564d88",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 5,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9ZFM3oCD8Gm",
        "outputId": "62bc71cb-c24d-4985-8c30-8abad5a524cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "1bf168827d36444a811962d56487858e",
            "0d6fcb08c3b549dd9a671075e0a08f50",
            "d1be5c7de14741daaf3b68ccf17e216a",
            "217d4f27224d4c2081acb7fda7331a5b",
            "7a85d6b816cc43c498290a00858faf39",
            "4b2c07e985fa437d84d85e1bcbcd4cc0",
            "fbe274e5286e48f9a96a99caeabea434",
            "2153f4283f994af58e287150ceae1e5a"
          ]
        }
      },
      "source": [
        "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
        "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
        "\n",
        "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bf168827d36444a811962d56487858e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQh3sG3SEFpj"
      },
      "source": [
        "from fastai.callbacks import *\n",
        "from transformers import AdamW\n",
        "from functools import partial\n",
        "\n",
        "CustomAdamW = partial(AdamW, correct_bias=False)\n",
        "\n",
        "learner = Learner(databunch, \n",
        "                  custom_transformer_model, \n",
        "                  opt_func = CustomAdamW, \n",
        "                  metrics=[accuracy, error_rate])\n",
        "\n",
        "# Show graph of learner stats and metrics after each epoch.\n",
        "learner.callbacks.append(ShowGraph(learner))\n",
        "\n",
        "# Put learn in FP16 precision mode. --> Seems to not working\n",
        "if use_fp16: learner = learner.to_fp16()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MwPnHCVzH98"
      },
      "source": [
        "# Show graph of learner stats and metrics after each epoch.\n",
        "learner.callbacks.append(ShowGraph(learner))\n",
        "\n",
        "# Put learn in FP16 precision mode. --> Not working in the tutorial\n",
        "if use_fp16: learner = learner.to_fp16()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-sAy1RmtDTo"
      },
      "source": [
        "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
        "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
        "\n",
        "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSFwOrIuD7DJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnd9nzsPtDTt"
      },
      "source": [
        "## LearnerÂ : Custom Optimizer / CustomÂ Metric\n",
        "In ``pytorch-transformers``, HuggingFace had implemented two specific optimizers â€Š-â€Š BertAdam and OpenAIAdam â€Š-â€Š that have been replaced by a single AdamW optimizer.\n",
        "This optimizer matches Pytorch Adam optimizer Api, therefore, it becomes straightforward to integrate it within ``fastai``.\n",
        "It is worth noting that for reproducing BertAdam specific behavior, you have to set ``correct_bias = False``.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfXjBlyStDTu"
      },
      "source": [
        "from fastai.callbacks import *\n",
        "from transformers import AdamW\n",
        "from functools import partial\n",
        "\n",
        "CustomAdamW = partial(AdamW, correct_bias=False)\n",
        "\n",
        "learner = Learner(databunch, \n",
        "                  custom_transformer_model, \n",
        "                  opt_func = CustomAdamW, \n",
        "                  metrics=[accuracy, error_rate])\n",
        "\n",
        "# Show graph of learner stats and metrics after each epoch.\n",
        "learner.callbacks.append(ShowGraph(learner))\n",
        "\n",
        "# Put learn in FP16 precision mode. --> Seems to not working\n",
        "if use_fp16: learner = learner.to_fp16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMMU3kN3tDT0"
      },
      "source": [
        "## Discriminative Fine-tuning and Gradual unfreezing (Optional)\n",
        "To use **discriminative layer training** and **gradual unfreezing**, ``fastai`` provides one tool that allows to \"split\" the structure model into groups. An instruction to perform that \"split\" is described in the fastai documentation [here](https://docs.fast.ai/basic_train.html#Discriminative-layer-training).\n",
        "\n",
        "Unfortunately,  the model architectures are too different to create a unique generic function that can \"split\" all the model types in a convenient way. Thereby, you will have to implement a custom \"split\" for each different model architecture.\n",
        "\n",
        "For example, if we use the RobBERTa model and that we observe his architecture by making ``print(learner.model)``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujH8KI5stDT1",
        "outputId": "2f502d3f-bd31-43de-dce7-e0ef4897bae3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(learner.model)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CustomTransformerModel(\n",
            "  (transformer): RobertaForSequenceClassification(\n",
            "    (roberta): RobertaModel(\n",
            "      (embeddings): RobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "        (token_type_embeddings): Embedding(1, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (classifier): RobertaClassificationHead(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (out_proj): Linear(in_features=768, out_features=5, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OZiDewPtDT7"
      },
      "source": [
        "We can decide to divide the model in 14 blocksÂ :\n",
        "* 1 Embedding\n",
        "* 12 transformer\n",
        "* 1 classifier\n",
        "\n",
        "In this case, we can split our model in this wayÂ :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ-Ln-5VzRGy",
        "outputId": "11d2a6df-3763-4512-f538-85cacf246242",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num_groups = len(learner.layer_groups)\n",
        "print('Learner split in',num_groups,'groups')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learner split in 1 groups\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGY5QD4VtDT8"
      },
      "source": [
        "# For DistilBERT\n",
        "# list_layers = [learner.model.transformer.distilbert.embeddings,\n",
        "#                learner.model.transformer.distilbert.transformer.layer[0],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[1],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[2],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[3],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[4],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[5],\n",
        "#                learner.model.transformer.pre_classifier]\n",
        "\n",
        "# For xlnet-base-cased\n",
        "# list_layers = [learner.model.transformer.transformer.word_embedding,\n",
        "#               learner.model.transformer.transformer.layer[0],\n",
        "#               learner.model.transformer.transformer.layer[1],\n",
        "#               learner.model.transformer.transformer.layer[2],\n",
        "#               learner.model.transformer.transformer.layer[3],\n",
        "#               learner.model.transformer.transformer.layer[4],\n",
        "#               learner.model.transformer.transformer.layer[5],\n",
        "#               learner.model.transformer.transformer.layer[6],\n",
        "#               learner.model.transformer.transformer.layer[7],\n",
        "#               learner.model.transformer.transformer.layer[8],\n",
        "#               learner.model.transformer.transformer.layer[9],\n",
        "#               learner.model.transformer.transformer.layer[10],\n",
        "#               learner.model.transformer.transformer.layer[11],\n",
        "#               learner.model.transformer.sequence_summary]\n",
        "\n",
        "# For roberta-base\n",
        "list_layers = [learner.model.transformer.roberta.embeddings,\n",
        "              learner.model.transformer.roberta.encoder.layer[0],\n",
        "              learner.model.transformer.roberta.encoder.layer[1],\n",
        "              learner.model.transformer.roberta.encoder.layer[2],\n",
        "              learner.model.transformer.roberta.encoder.layer[3],\n",
        "              learner.model.transformer.roberta.encoder.layer[4],\n",
        "              learner.model.transformer.roberta.encoder.layer[5],\n",
        "              learner.model.transformer.roberta.encoder.layer[6],\n",
        "              learner.model.transformer.roberta.encoder.layer[7],\n",
        "              learner.model.transformer.roberta.encoder.layer[8],\n",
        "              learner.model.transformer.roberta.encoder.layer[9],\n",
        "              learner.model.transformer.roberta.encoder.layer[10],\n",
        "              learner.model.transformer.roberta.encoder.layer[11],\n",
        "              learner.model.transformer.roberta.pooler]\n",
        "\n",
        "learner.split(list_layers);"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VtbfWkztDUF"
      },
      "source": [
        "Check groups : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDTK8dUYtDUG",
        "outputId": "7f2f3224-53b1-455e-ade5-6997cbceb242",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "learner.split(list_layers)\n",
        "# learner.split(list_layers)\n",
        "# num_groups = len(learner.layer_groups)\n",
        "# print('Learner split in',num_groups,'groups')\n",
        "# print(learner.layer_groups)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Learner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (140454 items)\n",
              "x: TextList\n",
              "<s> Ä A Ä series Ä of Ä esc ap ades Ä demonstrating Ä the Ä ad age Ä that Ä what Ä is Ä good Ä for Ä the Ä goose </s>,<s> Ä A Ä series </s>,<s> Ä A </s>,<s> Ä series </s>,<s> Ä of Ä esc ap ades Ä demonstrating Ä the Ä ad age Ä that Ä what Ä is Ä good Ä for Ä the Ä goose </s>\n",
              "y: CategoryList\n",
              "2,2,2,2,2\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (15606 items)\n",
              "x: TextList\n",
              "<s> Ä ' s Ä as Ä sorry </s>,<s> Ä Romantic Ä comedy Ä and Ä Dog me Ä 95 Ä filmmaking Ä may Ä seem Ä odd Ä bed fell ows Ä , Ä but Ä they Ä turn Ä out Ä to Ä be Ä delight fully Ä compatible Ä here </s>,<s> Ä of Ä these Ä days </s>,<s> Ä fl inch Ä from Ä its Ä unsettling Ä prog nosis </s>,<s> Ä are Ä clinically Ä depressed </s>\n",
              "y: CategoryList\n",
              "2,4,2,2,1\n",
              "Path: .;\n",
              "\n",
              "Test: LabelList (66292 items)\n",
              "x: TextList\n",
              "<s> Ä 15 60 61 Ä 85 45 Ä An Ä intermitt ently Ä pleasing Ä but Ä mostly Ä routine Ä effort Ä . </s>,<s> Ä 15 60 62 Ä 85 45 Ä An Ä intermitt ently Ä pleasing Ä but Ä mostly Ä routine Ä effort </s>,<s> Ä 15 60 63 Ä 85 45 Ä An </s>,<s> Ä 15 60 64 Ä 85 45 Ä intermitt ently Ä pleasing Ä but Ä mostly Ä routine Ä effort </s>,<s> Ä 15 60 65 Ä 85 45 Ä intermitt ently Ä pleasing Ä but Ä mostly Ä routine </s>\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: ., model=CustomTransformerModel(\n",
              "  (transformer): RobertaForSequenceClassification(\n",
              "    (roberta): RobertaModel(\n",
              "      (embeddings): RobertaEmbeddings(\n",
              "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "        (token_type_embeddings): Embedding(1, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "    (classifier): RobertaClassificationHead(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (out_proj): Linear(in_features=768, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'transformers.optimization.AdamW'>, correct_bias=False), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fab4bd59048>, <function error_rate at 0x7fab4bd59268>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[ShowGraph\n",
              "learn: Learner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (140454 items)\n",
              "x: TextList\n",
              "<s> Ä A Ä series Ä of Ä esc ap ades Ä demonstrating Ä the Ä ad age Ä that Ä what Ä is Ä good Ä for Ä the Ä goose </s>,<s> Ä A Ä series </s>,<s> Ä A </s>,<s> Ä series </s>,<s> Ä of Ä esc ap ades Ä demonstrating Ä the Ä ad age Ä that Ä what Ä is Ä good Ä for Ä the Ä goose </s>\n",
              "y: CategoryList\n",
              "2,2,2,2,2\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (15606 items)\n",
              "x: TextList\n",
              "<s> Ä ' s Ä as Ä sorry </s>,<s> Ä Romantic Ä comedy Ä and Ä Dog me Ä 95 Ä filmmaking Ä may Ä seem Ä odd Ä bed fell ows Ä , Ä but Ä they Ä turn Ä out Ä to Ä be Ä delight fully Ä compatible Ä here </s>,<s> Ä of Ä these Ä days </s>,<s> Ä fl inch Ä from Ä its Ä unsettling Ä prog nosis </s>,<s> Ä are Ä clinically Ä depressed </s>\n",
              "y: CategoryList\n",
              "2,4,2,2,1\n",
              "Path: .;\n",
              "\n",
              "Test: LabelList (66292 items)\n",
              "x: TextList\n",
              "<s> Ä 15 60 61 Ä 85 45 Ä An Ä intermitt ently Ä pleasing Ä but Ä mostly Ä routine Ä effort Ä . </s>,<s> Ä 15 60 62 Ä 85 45 Ä An Ä intermitt ently Ä pleasing Ä but Ä mostly Ä routine Ä effort </s>,<s> Ä 15 60 63 Ä 85 45 Ä An </s>,<s> Ä 15 60 64 Ä 85 45 Ä intermitt ently Ä pleasing Ä but Ä mostly Ä routine Ä effort </s>,<s> Ä 15 60 65 Ä 85 45 Ä intermitt ently Ä pleasing Ä but Ä mostly Ä routine </s>\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: ., model=CustomTransformerModel(\n",
              "  (transformer): RobertaForSequenceClassification(\n",
              "    (roberta): RobertaModel(\n",
              "      (embeddings): RobertaEmbeddings(\n",
              "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "        (token_type_embeddings): Embedding(1, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "    (classifier): RobertaClassificationHead(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (out_proj): Linear(in_features=768, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'transformers.optimization.AdamW'>, correct_bias=False), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fab4bd59048>, <function error_rate at 0x7fab4bd59268>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(50265, 768, padding_idx=1)\n",
              "  (1): Embedding(514, 768, padding_idx=1)\n",
              "  (2): Embedding(1, 768)\n",
              "  (3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (4): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Tanh()\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=5, bias=True)\n",
              ")], add_time=True, silent=False), ShowGraph\n",
              "learn: Learner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (140454 items)\n",
              "x: TextList\n",
              "<s> Ä A Ä series Ä of Ä esc ap ades Ä demonstrating Ä the Ä ad age Ä that Ä what Ä is Ä good Ä for Ä the Ä goose </s>,<s> Ä A Ä series </s>,<s> Ä A </s>,<s> Ä series </s>,<s> Ä of Ä esc ap ades Ä demonstrating Ä the Ä ad age Ä that Ä what Ä is Ä good Ä for Ä the Ä goose </s>\n",
              "y: CategoryList\n",
              "2,2,2,2,2\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (15606 items)\n",
              "x: TextList\n",
              "<s> Ä ' s Ä as Ä sorry </s>,<s> Ä Romantic Ä comedy Ä and Ä Dog me Ä 95 Ä filmmaking Ä may Ä seem Ä odd Ä bed fell ows Ä , Ä but Ä they Ä turn Ä out Ä to Ä be Ä delight fully Ä compatible Ä here </s>,<s> Ä of Ä these Ä days </s>,<s> Ä fl inch Ä from Ä its Ä unsettling Ä prog nosis </s>,<s> Ä are Ä clinically Ä depressed </s>\n",
              "y: CategoryList\n",
              "2,4,2,2,1\n",
              "Path: .;\n",
              "\n",
              "Test: LabelList (66292 items)\n",
              "x: TextList\n",
              "<s> Ä 15 60 61 Ä 85 45 Ä An Ä intermitt ently Ä pleasing Ä but Ä mostly Ä routine Ä effort Ä . </s>,<s> Ä 15 60 62 Ä 85 45 Ä An Ä intermitt ently Ä pleasing Ä but Ä mostly Ä routine Ä effort </s>,<s> Ä 15 60 63 Ä 85 45 Ä An </s>,<s> Ä 15 60 64 Ä 85 45 Ä intermitt ently Ä pleasing Ä but Ä mostly Ä routine Ä effort </s>,<s> Ä 15 60 65 Ä 85 45 Ä intermitt ently Ä pleasing Ä but Ä mostly Ä routine </s>\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: ., model=CustomTransformerModel(\n",
              "  (transformer): RobertaForSequenceClassification(\n",
              "    (roberta): RobertaModel(\n",
              "      (embeddings): RobertaEmbeddings(\n",
              "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "        (token_type_embeddings): Embedding(1, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "    (classifier): RobertaClassificationHead(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (out_proj): Linear(in_features=768, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'transformers.optimization.AdamW'>, correct_bias=False), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fab4bd59048>, <function error_rate at 0x7fab4bd59268>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(50265, 768, padding_idx=1)\n",
              "  (1): Embedding(514, 768, padding_idx=1)\n",
              "  (2): Embedding(1, 768)\n",
              "  (3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (4): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Tanh()\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=5, bias=True)\n",
              ")], add_time=True, silent=False)], layer_groups=[Sequential(\n",
              "  (0): Embedding(50265, 768, padding_idx=1)\n",
              "  (1): Embedding(514, 768, padding_idx=1)\n",
              "  (2): Embedding(1, 768)\n",
              "  (3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (4): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Tanh()\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=5, bias=True)\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2bkHpsPtDUL"
      },
      "source": [
        "Note that I didn't found any document that has studied the influence of **Discriminative Fine-tuning** and **Gradual unfreezing** or even **Slanted Triangular Learning Rates** with transformers. Therefore, using these tools does not guarantee better results. If you found any interesting documents, please let us know in the comment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeTTTRf9tDUM"
      },
      "source": [
        "## Train\n",
        "Now we can finally use all the fastai build-in features to train our model. Like the ULMFiT method, we will use **Slanted Triangular Learning Rates**, **Discriminate Learning Rate** and **gradually unfreeze the model**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfEUIFr9tDUN"
      },
      "source": [
        "learner.save('untrain')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5zX17E-tDUS"
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('untrain');"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYjCWN6YtDUV"
      },
      "source": [
        "Therefore, we first freeze all the groups but the classifier withÂ :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnRHuu-9tDUW"
      },
      "source": [
        "learner.freeze_to(-1)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB4ClDhotDUc"
      },
      "source": [
        "We check which layer are trainable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06RGLF4LtDUg",
        "outputId": "f21bc345-542d-4dcb-f849-66ca61d00649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learner.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CustomTransformerModel\n",
              "======================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "======================================================================\n",
              "Embedding            [79, 768]            38,603,520 False     \n",
              "______________________________________________________________________\n",
              "Embedding            [79, 768]            394,752    False     \n",
              "______________________________________________________________________\n",
              "Embedding            [79, 768]            768        False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 79, 79]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 79, 79]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 79, 79]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 79, 79]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 79, 79]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 79, 79]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 79, 79]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 79, 79]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 79, 79]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 79, 79]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 79, 79]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 79, 79]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [79, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [79, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [79, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [768]                590,592    True      \n",
              "______________________________________________________________________\n",
              "Tanh                 [768]                0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [768]                590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [768]                0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [5]                  3,845      True      \n",
              "______________________________________________________________________\n",
              "\n",
              "Total params: 125,240,069\n",
              "Total trainable params: 1,185,029\n",
              "Total non-trainable params: 124,055,040\n",
              "Optimized with 'transformers.optimization.AdamW', correct_bias=False\n",
              "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
              "Loss function : FlattenedLoss\n",
              "======================================================================\n",
              "Callbacks functions applied \n",
              "    ShowGraph\n",
              "    ShowGraph"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC0zJ2cHtDUk"
      },
      "source": [
        "For **Slanted Triangular Learning Rates** you have to use the function ``one_cycle``. For more information please check the fastai documentation [here](https://docs.fast.ai/callbacks.one_cycle.html).Â \n",
        "\n",
        "To use our ``one_cycle`` we will need an optimum learning rate. We can find this learning rate by using a learning rate finder which can be called by using ``lr_find``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f0D_SoDtDUk",
        "outputId": "1b950f58-dd7e-4be4-bef4-0d72c860eeaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "learner.lr_find()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='72' class='' max='8778' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.82% [72/8778 00:05<12:00 5.6271]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVUO_PgGtDUo",
        "outputId": "10e3444c-3a41-4097-eecc-006b06bdedc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "learner.recorder.plot(skip_end=10,suggestion=True)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min numerical gradient: 9.12E-05\n",
            "Min loss divided by 10: 4.37E-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkfBpqeItDUs"
      },
      "source": [
        "We will pick a value a bit before the minimum, where the loss still improves. Here 2x10^-3 seems to be a good value.\n",
        "\n",
        "Next we will use ``fit_one_cycle`` with the chosen learning rate as the maximum learning rate. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5phSbt5AtDUt",
        "outputId": "1e077f3a-9527-40f6-d371-14e7aba1f310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "learner.fit_one_cycle(1,max_lr=2e-03,moms=(0.8,0.7))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.002275</td>\n",
              "      <td>0.986149</td>\n",
              "      <td>0.599000</td>\n",
              "      <td>0.401000</td>\n",
              "      <td>03:39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocBh_1HLtDUz"
      },
      "source": [
        "learner.save('first_cycle')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVROi-yJtDU_"
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('first_cycle');"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZo3L87LtDVD"
      },
      "source": [
        "We then unfreeze the second group of layers and repeat the operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kUlC47etDVE"
      },
      "source": [
        "learner.freeze_to(-2)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSqUekk6tDVJ"
      },
      "source": [
        "lr = 1e-5"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iltApzEgtDVM"
      },
      "source": [
        "Note here that we use slice to create separate learning rate for each group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEmo6INPtDVN",
        "outputId": "1b8bc80f-f04c-431c-c232-e16d787fcdeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.919810</td>\n",
              "      <td>0.899031</td>\n",
              "      <td>0.636230</td>\n",
              "      <td>0.363770</td>\n",
              "      <td>04:35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4WQOsJItDVV"
      },
      "source": [
        "learner.save('second_cycle')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO_9rBxftDVX"
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('second_cycle');"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wTaxEIvtDVb"
      },
      "source": [
        "learner.freeze_to(-3)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8I9hRjktDVf",
        "outputId": "8b6523d2-40e0-432c-de01-75926388056b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.881620</td>\n",
              "      <td>0.867503</td>\n",
              "      <td>0.648340</td>\n",
              "      <td>0.351660</td>\n",
              "      <td>05:12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXGrX_EstDVj"
      },
      "source": [
        "learner.save('third_cycle')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYe8TJQDtDVm"
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('third_cycle');"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2N5mxAStDVp"
      },
      "source": [
        "Here, we unfreeze all the groups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN-iulGatDVq"
      },
      "source": [
        "learner.unfreeze()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG1VmcYmtDVu",
        "outputId": "ebc5e705-e2e7-4e95-9723-2610f2b3372a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.709351</td>\n",
              "      <td>0.718610</td>\n",
              "      <td>0.700500</td>\n",
              "      <td>0.299500</td>\n",
              "      <td>14:58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.651286</td>\n",
              "      <td>0.697563</td>\n",
              "      <td>0.709407</td>\n",
              "      <td>0.290593</td>\n",
              "      <td>14:26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-w9ALFgtDV1"
      },
      "source": [
        "Now, you can predict examples with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGA8JGXttDV3",
        "outputId": "264a11a5-fd39-4f56-f915-482b8eaba51a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "learner.predict('This is the best movie of 2020')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category 4,\n",
              " tensor(4),\n",
              " tensor([7.5244e-06, 6.5012e-06, 7.5402e-05, 1.8518e-02, 9.8139e-01]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6zDUwzhtDV6",
        "outputId": "7397ece0-95cf-4b1e-c490-2b15e2323112",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "learner.predict('This is the worst movie of 2020')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category 0,\n",
              " tensor(0),\n",
              " tensor([9.6383e-01, 3.3977e-02, 1.2203e-03, 1.8969e-04, 7.8354e-04]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9NQHUFgtDV-"
      },
      "source": [
        "## Export Learner\n",
        "In order to export and load the learner you can do these operations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hKS0wl8tDV_"
      },
      "source": [
        "learner.export(file = 'transformer.pkl');"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hh89k25tDWC",
        "outputId": "2e8450ae-85df-4d28-f57e-6e049b24322e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "path = './'\n",
        "export_learner = load_learner(path, file = 'transformer.pkl')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIV3GbmitDWE"
      },
      "source": [
        "As mentioned [here](https://docs.fast.ai/basic_train.html#load_learner), you have to be careful that each custom classes - like ``TransformersVocab`` - are first defined before executing ``load_learner``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOyIFdI1tDWF",
        "outputId": "4ef87745-eb1d-4f0f-c4fa-6269e880c80b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "export_learner.predict('This is the worst movie of 2020')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category 0,\n",
              " tensor(0),\n",
              " tensor([9.6383e-01, 3.3977e-02, 1.2203e-03, 1.8969e-04, 7.8354e-04]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cPVfm-etDWI"
      },
      "source": [
        "## Creating prediction\n",
        "Now that the model is trained, we want to generate predictions from the test dataset.\n",
        "\n",
        "As specified in Keita Kurita's [article](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/), as the function ``get_preds`` does not return elements in order by default, you will have to resort the elements into their correct order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxAOTr6ntDWJ",
        "outputId": "b4b09c6c-7005-4ed0-f4ef-f7b7890f8da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    the get_preds method does not yield the elements in order by default\n",
        "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
        "    \"\"\"\n",
        "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
        "    sampler = [i for i in databunch.dl(ds_type).sampler]\n",
        "    reverse_sampler = np.argsort(sampler)\n",
        "    return preds[reverse_sampler, :]\n",
        "\n",
        "test_preds = get_preds_as_nparray(DatasetType.Test)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEgPpJZvRqCp",
        "outputId": "b6532ffa-29e4-4d3e-d381-ea61989af03e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<enum 'DatasetType'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aBstwsItDWM",
        "outputId": "4340d5d8-5421-4e82-ab69-b9f9cf943192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "sample_submission = pd.read_csv('sampleSubmission.csv')\n",
        "sample_submission['Sentiment'] = np.argmax(test_preds,axis=1)\n",
        "sample_submission.to_csv(\"predictions.csv\", index=False)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-7392dceb0e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sampleSubmission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictions.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sampleSubmission.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctmDJmvbtDWP"
      },
      "source": [
        "We check the order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc98RPuFtDWQ",
        "outputId": "06c25213-8a10-450d-96d2-4db94c8b5e16"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>8545</td>\n",
              "      <td>An</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine effort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  SentenceId                                             Phrase\n",
              "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
              "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
              "2    156063        8545                                                 An\n",
              "3    156064        8545  intermittently pleasing but mostly routine effort\n",
              "4    156065        8545         intermittently pleasing but mostly routine"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVTNa0nitDWT",
        "outputId": "b2aaf830-3994-4d5d-99f8-f25a2e769d03"
      },
      "source": [
        "sample_submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  Sentiment\n",
              "0    156061          2\n",
              "1    156062          2\n",
              "2    156063          2\n",
              "3    156064          2\n",
              "4    156065          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIlucxAUtDWX",
        "outputId": "b48b69f4-678d-4c82-bcd8-45a6ed791b84"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "def create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n",
        "    html = '<a href={filename}>{title}</a>'\n",
        "    html = html.format(title=title,filename=filename)\n",
        "    return HTML(html)\n",
        "\n",
        "# create a link to download the dataframe which was saved with .to_csv method\n",
        "create_download_link(filename='predictions.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<a href=predictions.csv>Download CSV file</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_TJA84sUQxs",
        "outputId": "8d3d9c72-28ce-4995-93d1-f5dcdb3ddd1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "TextList.from_df()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-a64f343f0693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlanguage_model_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: language_model_learner() missing 2 required positional arguments: 'data' and 'arch'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cREB0iPWUQ8p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtBjoeI7UQ6g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIUufl83UQ4t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLz_Lp_ytDWa"
      },
      "source": [
        "We can now submit our predictions to Kaggle !  In our example, without playing too much with the parameters, we get a score of 0.70059, which leads us to the 5th position on the leaderboard! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XrnhXDQtDWa"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "In this NoteBook, I explain how to combine the ``transformers`` library with the beloved ``fastai`` library. It aims to make you understand where to look and modify both libraries to make them work together. Likely, it allows you to use **Slanted Triangular Learning Rates**, **Discriminate Learning Rate** and even **Gradual Unfreezing**. As a result, without even tunning the parameters, you can obtain rapidly state-of-the-art results.\n",
        "\n",
        "This year, the transformers became an essential tool to NLP. Because of that, I think that pre-trained transformers architectures will be integrated soon to future versions of fastai. Meanwhile, this tutorial is a good starter.\n",
        "\n",
        "I hope you enjoyed this first article and found it useful.Â \n",
        "Thanks for reading and don't hesitate in leaving questions or suggestions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTHSa9PbtDWb"
      },
      "source": [
        "# References\n",
        "* Hugging Face, Transformers GitHub (Nov 2019), [https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)\n",
        "* Fast.ai, Fastai documentation (Nov 2019), [https://docs.fast.ai/text.html](https://docs.fast.ai/text.html)\n",
        "* Jeremy Howard & Sebastian Ruder, Universal Language Model Fine-tuning for Text Classification (May 2018), [https://arxiv.org/abs/1801.06146](https://arxiv.org/abs/1801.06146)\n",
        "* Keita Kurita's articleÂ : [A Tutorial to Fine-Tuning BERT with Fast AI](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/)Â (May 2019)\n",
        "* Dev Sharma's articleÂ : [Using RoBERTa with Fastai for NLP](https://medium.com/analytics-vidhya/using-roberta-with-fastai-for-nlp-7ed3fed21f6c) (Sep 2019)"
      ]
    }
  ]
}