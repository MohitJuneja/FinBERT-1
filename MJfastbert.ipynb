{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a550d0bca9845a18344d6ef714bef60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b5817fe0ffc848269115964b5953068e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_710f4f6f2a3249599787bb60c9667e4a",
              "IPY_MODEL_33811aed95834bf596c2328905cb33c3"
            ]
          }
        },
        "b5817fe0ffc848269115964b5953068e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "710f4f6f2a3249599787bb60c9667e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_71f31bbe7893426ca389206777b61b4e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c89fe541b164dfbabc1593513ae3d65"
          }
        },
        "33811aed95834bf596c2328905cb33c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_18fa2f20fdde4fb9bd2992b1b76e42a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/? [00:08&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53960f84e9a44f30b1975aaae155ee74"
          }
        },
        "71f31bbe7893426ca389206777b61b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c89fe541b164dfbabc1593513ae3d65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18fa2f20fdde4fb9bd2992b1b76e42a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53960f84e9a44f30b1975aaae155ee74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4df16002a9234a5faea822711974ac49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ffb2d16ba25f4750bde99093ccb4f3c0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b475e8f9443947acb0827f221c2cd88a",
              "IPY_MODEL_0fe6d8403911428a9618cd7abd0ff9cc"
            ]
          }
        },
        "ffb2d16ba25f4750bde99093ccb4f3c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b475e8f9443947acb0827f221c2cd88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3e354062e9dd44ca8121bd0672ee052d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2264,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2264,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb5d5a6fa80d4ac08f1becefa4179f12"
          }
        },
        "0fe6d8403911428a9618cd7abd0ff9cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_53d2a995bf8a4f1e84928c762c3a0397",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2264/2264 [01:35&lt;00:00, 23.70it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_509e1ced2ec14a3b8087519ade59b8c0"
          }
        },
        "3e354062e9dd44ca8121bd0672ee052d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb5d5a6fa80d4ac08f1becefa4179f12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53d2a995bf8a4f1e84928c762c3a0397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "509e1ced2ec14a3b8087519ade59b8c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2f990626d79432492377d63ee625583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d5980879a35d4b99a0e6183772836f99",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2338eae2314f4e3e8433ac62ae7843d9",
              "IPY_MODEL_b17b9e485b50428bad0efcec801479a9"
            ]
          }
        },
        "d5980879a35d4b99a0e6183772836f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2338eae2314f4e3e8433ac62ae7843d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e942354fa649447c972eed09cbc06f1e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 436,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 436,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b8a5dd1533d42c68c820babb0eedb51"
          }
        },
        "b17b9e485b50428bad0efcec801479a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bbdbd8f554a04d3baddd82574ea213cb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436/436 [01:24&lt;00:00,  5.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3ae97253c4e4f3a8e291f11e230abf9"
          }
        },
        "e942354fa649447c972eed09cbc06f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b8a5dd1533d42c68c820babb0eedb51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bbdbd8f554a04d3baddd82574ea213cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a3ae97253c4e4f3a8e291f11e230abf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cb9042e69784d478e88f35e63aa49e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_159f239f07c6489988969f8b7725eb64",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ccdb0405eb5c49c6b3f4b99372472c8b",
              "IPY_MODEL_bcf1344f8b7a429c86f777d5f9217102"
            ]
          }
        },
        "159f239f07c6489988969f8b7725eb64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ccdb0405eb5c49c6b3f4b99372472c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_536c9de55c5c4bf587638362e72ab152",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 675,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 675,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c68a320eb0b4aff9f300e67cd37ba8b"
          }
        },
        "bcf1344f8b7a429c86f777d5f9217102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_234b549b5a76411c8a8c9b7559eb185e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 675/675 [00:16&lt;00:00, 40.76it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b390092b8d6b497bb63216d2b5b6b975"
          }
        },
        "536c9de55c5c4bf587638362e72ab152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c68a320eb0b4aff9f300e67cd37ba8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "234b549b5a76411c8a8c9b7559eb185e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b390092b8d6b497bb63216d2b5b6b975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "colab": {
      "name": "MJfastbert.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6cPVfm-etDWI"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohitJuneja/FinBERT-1/blob/master/MJfastbert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT-5eulWtDSH"
      },
      "source": [
        "# Fastai with HuggingFace 🤗Transformers (BERT, RoBERTa, XLNet, XLM, DistilBERT)\n",
        "\n",
        "![fastai + Transformers](https://i.ibb.co/qspmrcm/fastai-transformers-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxqWmoQltDSN"
      },
      "source": [
        "N.B. This implementation is a supplement of the Medium article [\"Fastai with 🤗Transformers (BERT, RoBERTa, XLNet, XLM, DistilBERT)\"](https://medium.com/p/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2?source=email-29c8f5cf1dc4--writer.postDistributed&sk=119c3e5d748b2827af3ea863faae6376).\n",
        "\n",
        "**Also, remember the upvote button is next to the fork button, and it's free too!** 😉"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ4cQo0ztDSP"
      },
      "source": [
        "# Introduction : Story of transfer learning in NLP\n",
        "In early 2018, Jeremy Howard (co-founder of fast.ai) and Sebastian Ruder introduced the  [Universal Language Model Fine-tuning for Text Classification](https://medium.com/r/?url=https%3A%2F%2Farxiv.org%2Fpdf%2F1801.06146.pdf) (ULMFiT) method. ULMFiT was the first **Transfer Learning** method applied to NLP. As a result, besides significantly outperforming many state-of-the-art tasks, it allowed, with only 100 labeled examples, to match performances equivalent to models trained on 100×  more data.\n",
        "\n",
        "The first time I heard about ULMFiT was during a [fast.ai course](https://course.fast.ai/videos/?lesson=4) given by Jeremy Howard. He demonstrated how it was easy  -  thanks to the ``fastai`` library  -  to implement the complete ULMFit method with only a few lines of codes. In his demo, he used an AWD-LSTM neural network pre-trained on Wikitext-103 and get rapidly state-of-the-art results. He also explained key techniques - also demonstrated in ULMFiT - to fine-tune the models like **Discriminate Learning Rate**, **Gradual Unfreezing** or **Slanted Triangular Learning Rates**.\n",
        "\n",
        "Since the introduction of ULMFiT, **Transfer Learning** became very popular in NLP and yet Google (BERT, Transformer-XL, XLNet), Facebook (RoBERTa, XLM) or even OpenAI (GPT, GPT-2) begin to pre-train their own model on very large corpora. This time, instead of using the AWD-LSTM neural network, they all used a more powerful architecture based on the Transformer (cf. [Attention is all you need](https://arxiv.org/abs/1706.03762)).\n",
        "\n",
        "Although these models are powerful, ``fastai`` do not integrate all of them. Fortunately, [HuggingFace](https://huggingface.co/) 🤗 created the well know [transformers library](https://github.com/huggingface/transformers). Formerly knew as ``pytorch-transformers`` or ``pytorch-pretrained-bert``, this library brings together over 40 state-of-the-art pre-trained NLP models (BERT, GPT-2, RoBERTa, CTRL…). The implementation gives interesting additional utilities like tokenizer, optimizer or scheduler.\n",
        "\n",
        "The ``transformers`` library can be self-sufficient but incorporating it within the ``fastai`` library provides simpler implementation compatible with powerful fastai tools like  **Discriminate Learning Rate**, **Gradual Unfreezing** or **Slanted Triangular Learning Rates**. The point here is to allow anyone — expert or non-expert — to get easily state-of-the-art results and to “make NLP uncool again”.\n",
        "\n",
        "It worth noting that the integration of the HuggingFace ``transformers`` library in ``fastai`` has already been demonstrated in:\n",
        "* Keita Kurita's article [A Tutorial to Fine-Tuning BERT with Fast AI](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/) which makes ``pytorch_pretrained_bert`` library compatible with ``fastai``.\n",
        "* Dev Sharma's article [Using RoBERTa with Fastai for NLP](https://medium.com/analytics-vidhya/using-roberta-with-fastai-for-nlp-7ed3fed21f6c) which makes ``pytorch_transformers`` library compatible with ``fastai``.\n",
        "\n",
        "Although these articles are of high quality, some part of their demonstration is not anymore compatible with the last version of ``transformers``.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8wlAAnDtDSP"
      },
      "source": [
        "# 🛠 Integrating transformers with fastai for multiclass classification\n",
        "Before beginning the implementation, note that integrating ``transformers`` within ``fastai`` can be done in multiple different ways. For that reason, I decided to bring simple solutions, that are the most generic and flexible. More precisely, I try to make the minimum of modification in both libraries while making them compatible with the maximum amount of transformer architectures.\n",
        "\n",
        "Note that in addition to this NoteBook and the [Medium article](https://medium.com/p/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2?source=email-29c8f5cf1dc4--writer.postDistributed&sk=119c3e5d748b2827af3ea863faae6376), I made another version available on my GitHub(TODO add link)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_moOKeIatDSQ"
      },
      "source": [
        "## Libraries Installation\n",
        "Before starting the implementation, you will need to install the ``fastai`` and ``transformers`` libraries. To do so, just follow the instructions [here](https://github.com/fastai/fastai/blob/master/README.md#installation) and [here](https://github.com/huggingface/transformers#installation).\n",
        "\n",
        "In Kaggle, the ``fastai`` library is already installed. So you just have to instal ``transformers`` with :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbjAszKrtDSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58537538-c3fd-4695-deef-7f13298410a5"
      },
      "source": [
        "#%%bash\n",
        "!pip install transformers==2.5.1\n",
        "!pip install fastai==1.0.58"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\r\u001b[K     |▋                               | 10kB 20.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 26.6MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 25.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 22.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 19.6MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 15.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 15.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 15.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 15.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 51.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 47.8MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/7f/4ade91fbb684c6f28a6e56028d9f9d2de4297761850d083579779f07c0de/boto3-1.16.25-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (4.41.1)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 49.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.1) (0.17.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (2020.11.8)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.6MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.20.0,>=1.19.25\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/d5/c0c33ca15e31062220ac5964f3492409eaf90a5cf5399503cd8264f2f8e9/botocore-1.19.25-py2.py3-none-any.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.25->boto3->transformers==2.5.1) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=3a1bd14e3aa23d0c2db08604d14c9fdc3708ea9cdab6a9fcd9744a2bc5ae46fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "\u001b[31mERROR: botocore 1.19.25 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sacremoses, sentencepiece, jmespath, botocore, s3transfer, boto3, tokenizers, transformers\n",
            "Successfully installed boto3-1.16.25 botocore-1.19.25 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.5.2 transformers-2.5.1\n",
            "Collecting fastai==1.0.58\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/88/386289f6926a59cbd2765b033f5fe8414d6ff89ab27044dffe740cc1a5f3/fastai-1.0.58-py3-none-any.whl (236kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (1.18.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (1.7.0+cu101)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (7.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (4.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (1.4.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (0.8.1+cu101)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (20.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (3.2.2)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (7.352.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (2.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (0.8)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (1.1.4)\n",
            "Requirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (1.0.0)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.58) (2.2.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai==1.0.58) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai==1.0.58) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastai==1.0.58) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastai==1.0.58) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.58) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.58) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.58) (0.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.58) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.58) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.58) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.58) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai==1.0.58) (2018.9)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (2.0.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (50.3.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (0.8.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.58) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.58) (3.4.0)\n",
            "Installing collected packages: fastai\n",
            "  Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "Successfully installed fastai-1.0.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG0FBBokzDae",
        "outputId": "7fd96573-f2e6-4955-a10c-3a2e8797e0f0"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Nov 27 21:08:37 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "HlB6EnvFtDSU"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from pathlib import Path \n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "import random \n",
        "\n",
        "# fastai\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "\n",
        "# transformers\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
        "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoaL7vartDSZ"
      },
      "source": [
        "The current versions of the fastai and transformers libraries are respectively 1.0.58 and 2.5.1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niiPL5jstDSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c4ab31-248b-448c-f85a-9111bde56395"
      },
      "source": [
        "import fastai\n",
        "import transformers\n",
        "print('fastai version :', fastai.__version__)\n",
        "print('transformers version :', transformers.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fastai version : 1.0.58\n",
            "transformers version : 2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v50y5n-hVeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d4d375-aa9f-4d00-e33a-a3d8d8855c2b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd /content/gdrive/My\\ Drive/source/mjfastbert/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/source/mjfastbert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4qTjlumhYtz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzDHgmK35cLV",
        "outputId": "f88a9c2b-a508-4958-9ccb-ccba387ce433"
      },
      "source": [
        "import sys\n",
        "!test -d '/content/gdrive/My Drive/source/mjfastbert/data/' && echo \"FYI: mjfastbert/data directory already exists.\"\n",
        "!test -d '/content/gdrive/My Drive/source/mjfastbert/models/' && echo \"FYI: mjfastbert/models directory already exists.\"\n",
        "#!curl 'https://gohkust-my.sharepoint.com/personal/imyiyang_ust_hk/_layouts/15/download.aspx?SourceUrl=%2Fpersonal%2Fimyiyang%5Fust%5Fhk%2FDocuments%2FFinBERT%2FFinVocab%2DUncased%2Etxt' -H 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0' -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' -H 'Accept-Language: en-US,en;q=0.5' --compressed -H 'Referer: https://gohkust-my.sharepoint.com/personal/imyiyang_ust_hk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fimyiyang%5Fust%5Fhk%2FDocuments%2FFinBERT%2FFinVocab%2DUncased%2Etxt&parent=%2Fpersonal%2Fimyiyang%5Fust%5Fhk%2FDocuments%2FFinBERT&originalPath=aHR0cHM6Ly9nb2hrdXN0LW15LnNoYXJlcG9pbnQuY29tLzp0Oi9nL3BlcnNvbmFsL2lteWl5YW5nX3VzdF9oay9FWDNDLUtNOWJUeE9qZHR0c1BzbExaVUJ3X21oOUpkaDhQQjBXVHY2YjJ0RUlBP3J0aW1lPU52TkItRmVTMkVn' -H 'Upgrade-Insecure-Requests: 1' -H 'Connection: keep-alive' -H 'Cookie: RpsContextCookie=U291cmNlPSUyRnBlcnNvbmFsJTJGaW15aXlhbmclNUZ1c3QlNUZoayUyRiU1RmxheW91dHMlMkYxNSUyRm9uZWRyaXZlJTJFYXNweCUzRm9yaWdpbmFsUGF0aCUzRGFIUjBjSE02THk5bmIyaHJkWE4wTFcxNUxuTm9ZWEpsY0c5cGJuUXVZMjl0THpwbU9pOW5MM0JsY25OdmJtRnNMMmx0ZVdsNVlXNW5YM1Z6ZEY5b2F5OUZhM05LWTJGdFNuQmpiRXBzWWsxM1pVWm1RalZFVVVJeFdISnplRlZTV1U0MVIxTnhXbmN6YW0xVFpWTjNQM0owYVcxbFBYZHNPV1Z1VFZOUk1rVm4lMjZpZCUzRCUyNTJGcGVyc29uYWwlMjUyRmlteWl5YW5nJTI1NUZ1c3QlMjU1RmhrJTI1MkZEb2N1bWVudHMlMjUyRkZpbkJFUlQmUHJldmlvdXNSZXF1ZXN0Q29ycmVsYXRpb25JZD03NThjOTE5ZiUyRDYwNGMlMkQwMDAwJTJENTM0NiUyRDUzMzgxMGFmNGIxOCZSZXR1cm5Vcmw9JTJGcGVyc29uYWwlMkZpbXlpeWFuZyU1RnVzdCU1RmhrJTJGJTVGbGF5b3V0cyUyRjE1JTJGQXV0aGVudGljYXRlJTJFYXNweCUzRlNvdXJjZSUzRCUyNTJGcGVyc29uYWwlMjUyRmlteWl5YW5nJTI1NUZ1c3QlMjU1RmhrJTI1MkYlMjU1RmxheW91dHMlMjUyRjE1JTI1MkZvbmVkcml2ZSUyNTJFYXNweCUyNTNGb3JpZ2luYWxQYXRoJTI1M0RhSFIwY0hNNkx5OW5iMmhyZFhOMExXMTVMbk5vWVhKbGNHOXBiblF1WTI5dEx6cG1PaTluTDNCbGNuTnZibUZzTDJsdGVXbDVZVzVuWDNWemRGOW9heTlGYTNOS1kyRnRTbkJqYkVwc1lrMTNaVVptUWpWRVVVSXhXSEp6ZUZWU1dVNDFSMU54V25jemFtMVRaVk4zUDNKMGFXMWxQWGRzT1dWdVRWTlJNa1ZuJTI1MjZpZCUyNTNEJTI1MjUyRnBlcnNvbmFsJTI1MjUyRmlteWl5YW5nJTI1MjU1RnVzdCUyNTI1NUZoayUyNTI1MkZEb2N1bWVudHMlMjUyNTJGRmluQkVSVA==; nSGt-49EA76940FABD3ECFFB5A89FA79CE11D642F18837C21EE16=gYEwQjk1Q0U0MDEyMjQzQTFBOUJCREFFRDlBRUJDQTczNTczREJFRkIxNkFBOEZDODM0MDQ5RUE3Njk0MEZBQkQzRUNGRkI1QTg5RkE3OUNFMTFENjQyRjE4ODM3QzIxRUUxNhIxMzI1MDkwMjc1NjExODcwODkZZ29oa3VzdC1teS5zaGFyZXBvaW50LmNvbWdSMbHYgBfMGNvR1HkV97SlbxRnYmNzA09DJrFreEJ2uLolVdvqD5DfH/bYODRyssejwyTvAQZ7NtD0TPee2/Xoqa3LPx1Yx6Q/V2O+IZPQWDKD981Gv911hxlLLrn3cfww42WkPx5UHZFkesCtHLcHftBcIuBA1NGWkuMCmYh5HlosWNCrjTsD61NCIxBb3+8yU65gnO9Fo9OiB4v8qKStxHOihXzOfxLt1aA/Cn5jzC6A5Il8GjZLprTPfR8ki2vzv2tQ6VUwhKWmK9rlXLpqXwnwKv/p+w2VL47Wm1qjWshtcxXAuhYkGT8GIAfm40TT9J9dty/q2V+7f63ahH6RAAAA; nSGt-40940BBAD85342668D5B3D26B7C11C96906752EE6196B7EB=gYEwQkVGNzRDQzkzMzMyRDNCRTYwQTE0QTE5QTUzQjZDRDJERThDQzhGQTU0OUMzRTFCMDQwOTQwQkJBRDg1MzQyNjY4RDVCM0QyNkI3QzExQzk2OTA2NzUyRUU2MTk2QjdFQhIxMzI1MDkwMjc1NjUwOTI3NDMZZ29oa3VzdC1teS5zaGFyZXBvaW50LmNvbVhC+pzT5+bV9WVIGHb0lUlnim+Fa/k1pga3JNPjyXoITtB0Xnh7rjBtgAPL1ARRYgg4+64Ejmh3b1sIIgyJCT9+fbaB95FZNlXORzWav4+owqiF5RDyUsm2jaM2elYkfuAtNy1DSGo7yhqpyTnMofze8m/JCsYHTvQHv3d2lKFgHMinFb+dzJorydsuUh4lnICzm55ZlRw2D87UvxtbDfjRnmYPOKNSbJoolfawZbJLMdpXkkxsl8ZfBD0x+JHBSveTQEWlF1JWpSA+HxSdL5Fv2bsRYW22oiAgFApBMtlxtPlXZvsxCXV5F2DoF/C3c5MOLUuRPgMqQEC5cQ14NJuRAAAA; nSGt-9768EDACC0BA3F628D5A2C49E49CEC0D9A8D622FBDA14BB8=gYEwMkJERUEzMjkzMkM2NTcyOUM1MjlFNURCQUMyQkM5MzU3NkI1MzBDQkZDODZGN0VCMDk3NjhFREFDQzBCQTNGNjI4RDVBMkM0OUU0OUNFQzBEOUE4RDYyMkZCREExNEJCOBIxMzI1MDkwMjc1NjUwMjUyMTcZZ29oa3VzdC1teS5zaGFyZXBvaW50LmNvbVHHxxf3ooZyji9QyUobyBEoniZTmVSt2rKh1eqTl4HQQY8ao9eByEZuC+pvQ5boXvbwZhYob8QIzhaXyKgSP+haOwwm84oQvfuEKgwnmRQQNESIeALVj5i5vi7mDx0Ngsz1A8im02T6A6POWtFW0emdGZdNvlqAsCwXC9mwWUgpZDjEP+wT+UMcaPFnb2qIz42vTqdsIuzz/FmAhAhbDoT7DBD2qKLjWsxj02KB3E68PV3dehFDVkE6HxilY8EnyQT27CjNgl0QVVAoSZdRiCAT1xz1ImZ1LVftPkzgmLvNQC6qW3umCn7AzhhCSFzhZA4UH5etb/MbAe6K74U7xJyRAAAA; FedAuth=77u/PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz48U1A+VjgsMGguZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNWQ1ZjNkNWFkMTU5ZjlkNzA1MWQwOGM2NDE4ZTVjNGM0YjY0NjhmZmJkZTI4MTNkNzkyMGI1YWNlNzljZjg4YywwIy5mfG1lbWJlcnNoaXB8dXJuJTNhc3BvJTNhYW5vbiM1ZDVmM2Q1YWQxNTlmOWQ3MDUxZDA4YzY0MThlNWM0YzRiNjQ2OGZmYmRlMjgxM2Q3OTIwYjVhY2U3OWNmODhjLDEzMjUwOTAyNDc5MDAwMDAwMCwwLDEzMjUwOTg4NTc5NzQ5NDM3MiwwLjAuMC4wLDI1OCxjOTE3ZjNlMi05MzIyLTQ5MjYtOWJiMy1kYWNhNzMwNDEzY2EsLCw3YThjOTE5Zi05MGVlLTAwMDAtNTM0Ni01ZDcxNmFkODY2NGQsN2E4YzkxOWYtOTBlZS0wMDAwLTUzNDYtNWQ3MTZhZDg2NjRkLFdnenM2VjVYKzBHYlZVdmMrcGpIUVEsMCwwLDAsLCwsMjY1MDQ2Nzc0Mzk5OTk5OTk5OSwwLCxkMDU5a3dSUUc3UzVnK0RWampzTFNBWUxFWEtJTmZCcDMzQzVNd25LVDQ3QWNqOHdlVTc0NHlSU2xIUytQYk1kUmVVdnZkU2dXSHE2cHgrck5TR2FMTXRDT3FWVklWU0dVOFJ2WXFpMzN3czBvTVd4bk5XUlkreEpjbVJ2QmZGTEhMQkFoL2hEYUxkUWwxNk1uWDdQKy8vMDhmOGZVeHdSaURZbmZtOVdBS3poWGIzTFNtTGQ1aFZkUW5rM0N5dHpGUytKOHZtcXJCNWNHS3pqWENyZXh0dlRvMERWb05hTSt2SDhMSkVpbXQ2NXEwaHg1WTRCSHpjZC9mNVp1VzVHZ3ExTXlQL2NWdXJMeWpxRktDNUljV0c0M2VTVUNDYlkvbDh5U0xFMmNFYWZ4ZGlKdTZ6T2crTlo1cWZNbXQvTXlHYjBLUk1sb1IyaER6a1BEY3MrV3c9PTwvU1A+' -o /content/gdrive/My\\ Drive/source/mjfastbert/models/FinVocab-Uncased.txt\n",
        "#!curl 'https://southeastasia1-mediap.svc.ms/transform/zip?cs=fFNQTw' -H 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0' -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' -H 'Accept-Language: en-US,en;q=0.5' --compressed -H 'Content-Type: application/x-www-form-urlencoded' -H 'Origin: https://gohkust-my.sharepoint.com' -H 'Connection: keep-alive' -H 'Cookie: spo_access_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJub25lIn0.eyJhdWQiOiIwMDAwMDAwMy0wMDAwLTBmZjEtY2UwMC0wMDAwMDAwMDAwMDAvZ29oa3VzdC1teS5zaGFyZXBvaW50LmNvbUBjOTE3ZjNlMi05MzIyLTQ5MjYtOWJiMy1kYWNhNzMwNDEzY2EiLCJpc3MiOiIwMDAwMDAwMy0wMDAwLTBmZjEtY2UwMC0wMDAwMDAwMDAwMDAiLCJuYmYiOiIxNjA2NDI0NDAwIiwiZXhwIjoiMTYwNjQ0NjAwMCIsImVuZHBvaW50dXJsIjoiMzJJUGdxTGxpRDZ4MXUrelRDd3Y1cXBZTE42cTQzTWdCWUs3S1hEbGkyOD0iLCJlbmRwb2ludHVybExlbmd0aCI6IjExNyIsImlzbG9vcGJhY2siOiJUcnVlIiwidmVyIjoiaGFzaGVkcHJvb2Z0b2tlbiIsInNpdGVpZCI6Ik1qRXdaV0kwTjJJdFlXRm1aUzAwWWpGbUxXSm1Nemt0WVRNeFltWXhNVGhsWVdZNSIsIm5hbWVpZCI6IjAjLmZ8bWVtYmVyc2hpcHx1cm4lM2FzcG8lM2Fhbm9uIzVkNWYzZDVhZDE1OWY5ZDcwNTFkMDhjNjQxOGU1YzRjNGI2NDY4ZmZiZGUyODEzZDc5MjBiNWFjZTc5Y2Y4OGMiLCJuaWkiOiJtaWNyb3NvZnQuc2hhcmVwb2ludCIsImlzdXNlciI6InRydWUiLCJjYWNoZWtleSI6IjBoLmZ8bWVtYmVyc2hpcHx1cm4lM2FzcG8lM2Fhbm9uIzVkNWYzZDVhZDE1OWY5ZDcwNTFkMDhjNjQxOGU1YzRjNGI2NDY4ZmZiZGUyODEzZDc5MjBiNWFjZTc5Y2Y4OGMiLCJzaGFyaW5naWQiOiJXZ3pzNlY1WCswR2JWVXZjK3BqSFFRIiwidHQiOiIwIiwidXNlUGVyc2lzdGVudENvb2tpZSI6IjIifQ.RVhMUDg4bUxiVk96b3Z1aUZ2c3g1N0ZoNi91MHFLYnYvdGl1bm05aS94TT0' -H 'Upgrade-Insecure-Requests: 1' -H 'TE: Trailers' --data-raw 'zipFileName=FinBERT-FinVocab-Uncased.zip&guid=b31eb5e6-8b83-4616-8818-c6afdfeb03d0&provider=spo&files=%7B%22items%22%3A%5B%7B%22name%22%3A%22FinBERT-FinVocab-Uncased%22%2C%22size%22%3A0%2C%22docId%22%3A%22https%3A%2F%2Fgohkust-my.sharepoint.com%3A443%2F_api%2Fv2.0%2Fdrives%2Fb%21e7QOIf6qH0u_OaMb8Rjq-QJg83SR8yNKjflQjpTy9pTjTVk0qRxlS4H5uoBBYdDT%2Fitems%2F01DM5DGZKLBFY2TCNFZFEZLMZQPBL4DZBU%3Fversion%3DPublished%26access_token%3DeyJ0eXAiOiJKV1QiLCJhbGciOiJub25lIn0.eyJhdWQiOiIwMDAwMDAwMy0wMDAwLTBmZjEtY2UwMC0wMDAwMDAwMDAwMDAvZ29oa3VzdC1teS5zaGFyZXBvaW50LmNvbUBjOTE3ZjNlMi05MzIyLTQ5MjYtOWJiMy1kYWNhNzMwNDEzY2EiLCJpc3MiOiIwMDAwMDAwMy0wMDAwLTBmZjEtY2UwMC0wMDAwMDAwMDAwMDAiLCJuYmYiOiIxNjA2NDI0NDAwIiwiZXhwIjoiMTYwNjQ0NjAwMCIsImVuZHBvaW50dXJsIjoiMzJJUGdxTGxpRDZ4MXUrelRDd3Y1cXBZTE42cTQzTWdCWUs3S1hEbGkyOD0iLCJlbmRwb2ludHVybExlbmd0aCI6IjExNyIsImlzbG9vcGJhY2siOiJUcnVlIiwidmVyIjoiaGFzaGVkcHJvb2Z0b2tlbiIsInNpdGVpZCI6Ik1qRXdaV0kwTjJJdFlXRm1aUzAwWWpGbUxXSm1Nemt0WVRNeFltWXhNVGhsWVdZNSIsIm5hbWVpZCI6IjAjLmZ8bWVtYmVyc2hpcHx1cm4lM2FzcG8lM2Fhbm9uIzVkNWYzZDVhZDE1OWY5ZDcwNTFkMDhjNjQxOGU1YzRjNGI2NDY4ZmZiZGUyODEzZDc5MjBiNWFjZTc5Y2Y4OGMiLCJuaWkiOiJtaWNyb3NvZnQuc2hhcmVwb2ludCIsImlzdXNlciI6InRydWUiLCJjYWNoZWtleSI6IjBoLmZ8bWVtYmVyc2hpcHx1cm4lM2FzcG8lM2Fhbm9uIzVkNWYzZDVhZDE1OWY5ZDcwNTFkMDhjNjQxOGU1YzRjNGI2NDY4ZmZiZGUyODEzZDc5MjBiNWFjZTc5Y2Y4OGMiLCJzaGFyaW5naWQiOiJXZ3pzNlY1WCswR2JWVXZjK3BqSFFRIiwidHQiOiIwIiwidXNlUGVyc2lzdGVudENvb2tpZSI6IjIifQ.RVhMUDg4bUxiVk96b3Z1aUZ2c3g1N0ZoNi91MHFLYnYvdGl1bm05aS94TT0%22%2C%22isFolder%22%3Atrue%7D%5D%7D&oAuthToken=' -o /content/gdrive/My\\ Drive/source/mjfastbert/models/model.zip\n",
        "#!cd /content/gdrive/My\\ Drive/source/mjfastbert/models/ && unzip model.zip\n",
        "#!cd /content/gdrive/My\\ Drive/source/mjfastbert/data/ && wget https://github.com/MohitJuneja/FinBERT-1/raw/master/FinancialPhraseBank-v1.0.zip\n",
        "#!cd /content/gdrive/My\\ Drive/source/mjfastbert/data/ && unzip FinancialPhraseBank-v1.0.zip\n",
        "# # !rm -r text-topics # Uncomment if you need a clean pull from repo\n",
        "# !test -d \"/content/gdrive/My Drive/source/mjfastbert/data/\" || git clone https://mj-colab:MJDLabxk48267@gitlab.com/hodlpal/text-topics.git '/content/gdrive/My Drive/source/mjfastbert/data/'\n",
        "# if not '/content/gdrive/My Drive/git/mj/text-topics' in sys.path:\n",
        "#   sys.path += ['/content/gdrive/My Drive/git/mj/text-topics']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FYI: mjfastbert/data directory already exists.\n",
            "FYI: mjfastbert/models directory already exists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhXyanMSnX0t",
        "outputId": "a3c7ccc0-de47-419c-b310-082f4f2fa859"
      },
      "source": [
        "!cd /content/gdrive/My\\ Drive/source/mjfastbert/data/fiqa && ls -ltr"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 35700\n",
            "-rw------- 1 root root   226930 Feb  6  2018 task1_post_ABSA_train.json\n",
            "-rw------- 1 root root   147690 Feb  7  2018 task1_headline_ABSA_train.json\n",
            "-rw------- 1 root root    90021 Feb  8  2018 Readme.pdf\n",
            "-rw------- 1 root root    21219 Feb 17  2018 task1_headline_ABSA_test.json\n",
            "-rw------- 1 root root    22626 Feb 17  2018 task1_post_ABSA_test.json\n",
            "-rw------- 1 root root   147681 Nov 27 12:58 FiQA_ABSA_task1.zip\n",
            "-rw------- 1 root root 18552011 Nov 27 12:58 FiQA_train_task2.zip\n",
            "-rw------- 1 root root     9995 Nov 27 12:59 FIQA_ABSA_task1_test.zip\n",
            "-rw------- 1 root root 17335816 Nov 27 12:59 FiQA_test_task2.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "TsmyQIcstDSi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "5781ca25-8b31-4439-8673-0dd59ed87305"
      },
      "source": [
        "DATA_ROOT = Path(\".\") / \"/content/gdrive/MyDrive/source/mjfastbert/data/FinancialPhraseBank-v1.0\"\n",
        "train = pd.read_csv(DATA_ROOT / 'Sentences_50Agree.txt', sep=\".@\", header=None)\n",
        "test = pd.read_csv(DATA_ROOT / 'Sentences_AllAgree.txt', sep=\".@\", header=None)\n",
        "train.columns = ['statement', 'label']\n",
        "test.columns = ['statement', 'label']\n",
        "print(train.shape,test.shape)\n",
        "train.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(4846, 2) (2264, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           statement     label\n",
              "0  According to Gran , the company has no plans t...   neutral\n",
              "1  Technopolis plans to develop in stages an area...   neutral\n",
              "2  The international electronic industry company ...  negative\n",
              "3  With the new production plant the company woul...  positive\n",
              "4  According to the company 's updated strategy f...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "8bGK13zcz6Sq",
        "outputId": "9abc8e01-0140-411b-cd7a-58586c064399"
      },
      "source": [
        "fiqa_path = Path(\".\") / \"/content/gdrive/MyDrive/source/mjfastbert/data/fiqa\"\n",
        "fiqa_post = pd.read_json(fiqa_path / \"task1_post_ABSA_train.json\",orient='index')\n",
        "fiqa_post"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>info</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14860</th>\n",
              "      <td>Slowly adding some $FIO here but gotta be care...</td>\n",
              "      <td>[{'snippets': '['Slowly adding some $FIO here ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14864</th>\n",
              "      <td>$TRX http://stks.co/1KkK Long setup. MACD cross.</td>\n",
              "      <td>[{'snippets': '['Long setup. MACD cross.']', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14867</th>\n",
              "      <td>I am not optimistic about $amzn both fundement...</td>\n",
              "      <td>[{'snippets': '['both fundementals and charts ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14875</th>\n",
              "      <td>$GRPN might be selling off ahead of $P earning...</td>\n",
              "      <td>[{'snippets': '['might be selling off ahead']'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14876</th>\n",
              "      <td>$IACI http://stks.co/tJU Looks good on the wee...</td>\n",
              "      <td>[{'snippets': '['Looks good on the weekly char...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19130</th>\n",
              "      <td>Facebook $FB received a Buy rating from Wells ...</td>\n",
              "      <td>[{'snippets': '['received a Buy rating']', 'se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19149</th>\n",
              "      <td>$TSLA Wish had my puts back but see if we can ...</td>\n",
              "      <td>[{'snippets': '['if we can find support around...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19161</th>\n",
              "      <td>Citrix Systems Inc $CTXS Position Increased by...</td>\n",
              "      <td>[{'snippets': '['Position Increased by Mizuho'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19163</th>\n",
              "      <td>Notable gainers among liquid option names this...</td>\n",
              "      <td>[{'snippets': '['Notable gainers among liquid ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19167</th>\n",
              "      <td>Is #Facebook's user engagement falling? https:...</td>\n",
              "      <td>[{'snippets': '[\"Is #Facebook's user engagemen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>675 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence                                               info\n",
              "14860  Slowly adding some $FIO here but gotta be care...  [{'snippets': '['Slowly adding some $FIO here ...\n",
              "14864   $TRX http://stks.co/1KkK Long setup. MACD cross.  [{'snippets': '['Long setup. MACD cross.']', '...\n",
              "14867  I am not optimistic about $amzn both fundement...  [{'snippets': '['both fundementals and charts ...\n",
              "14875  $GRPN might be selling off ahead of $P earning...  [{'snippets': '['might be selling off ahead']'...\n",
              "14876  $IACI http://stks.co/tJU Looks good on the wee...  [{'snippets': '['Looks good on the weekly char...\n",
              "...                                                  ...                                                ...\n",
              "19130  Facebook $FB received a Buy rating from Wells ...  [{'snippets': '['received a Buy rating']', 'se...\n",
              "19149  $TSLA Wish had my puts back but see if we can ...  [{'snippets': '['if we can find support around...\n",
              "19161  Citrix Systems Inc $CTXS Position Increased by...  [{'snippets': '['Position Increased by Mizuho'...\n",
              "19163  Notable gainers among liquid option names this...  [{'snippets': '['Notable gainers among liquid ...\n",
              "19167  Is #Facebook's user engagement falling? https:...  [{'snippets': '[\"Is #Facebook's user engagemen...\n",
              "\n",
              "[675 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdbasEPu23Lu",
        "outputId": "ed3db188-6b96-4be4-897a-eaf513b9d610"
      },
      "source": [
        "fiqa_post.head(1)['info'].values"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([{'snippets': \"['Slowly adding some $FIO here but gotta be careful']\", 'sentiment_score': '0.459', 'target': 'FIO', 'aspects': \"['Stock/Price Action/Bullish/Bull Position']\"}])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzRZNgM21XHv"
      },
      "source": [
        "fiqa_post['snippets'] = list(map(lambda x: x[0]['snippets'], fiqa_post['info'].values))\n",
        "fiqa_post['sentiment_score'] = list(map(lambda x: x[0]['sentiment_score'], fiqa_post['info'].values))\n",
        "fiqa_post['target'] = list(map(lambda x: x[0]['target'], fiqa_post['info'].values))\n",
        "fiqa_post['aspects'] = list(map(lambda x: x[0]['aspects'], fiqa_post['info'].values))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "sMTe8VJE4ErQ",
        "outputId": "b87e16be-3b13-4efe-e18f-e31548532b0a"
      },
      "source": [
        "# fiqa_path = Path(\".\") / \"/content/gdrive/MyDrive/source/mjfastbert/data/fiqa\"\n",
        "fiqa_headline = pd.read_json(fiqa_path / \"task1_headline_ABSA_train.json\",orient='index')\n",
        "fiqa_headline"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>info</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Royal Mail chairman Donald Brydon set to step ...</td>\n",
              "      <td>[{'snippets': '['set to step down']', 'target'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Stakes High for AstraZeneca Heart Drug Facing ...</td>\n",
              "      <td>[{'snippets': '['Facing Tough Competition']', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>UPDATE 1-Dairy Crest loses a third of Morrison...</td>\n",
              "      <td>[{'snippets': '['Crest loses a third of Morris...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Insight hires Aviva's David Hillier for multi-...</td>\n",
              "      <td>[{'snippets': '['hires Aviva's David Hillier f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Primark racks up a happy Christmas after stron...</td>\n",
              "      <td>[{'snippets': '['after strong sales']', 'targe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1750</th>\n",
              "      <td>Aviva, M&amp;G suspend property funds as investors...</td>\n",
              "      <td>[{'snippets': '['M&amp;G suspend property funds as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1754</th>\n",
              "      <td>UK housing market steadies after Brexit dip, P...</td>\n",
              "      <td>[{'snippets': '['housing market']', 'target': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1755</th>\n",
              "      <td>BRIEF-Aviva aims to increase dividend pay-out ...</td>\n",
              "      <td>[{'snippets': '['increase dividend pay-out']',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1764</th>\n",
              "      <td>Builder Persimmon hails 6% rise in house sales</td>\n",
              "      <td>[{'snippets': '['6% rise in house sales']', 't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1779</th>\n",
              "      <td>EasyJet attracts more passengers in June but s...</td>\n",
              "      <td>[{'snippets': '['attracts more passengers']', ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>436 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence                                               info\n",
              "1     Royal Mail chairman Donald Brydon set to step ...  [{'snippets': '['set to step down']', 'target'...\n",
              "7     Stakes High for AstraZeneca Heart Drug Facing ...  [{'snippets': '['Facing Tough Competition']', ...\n",
              "8     UPDATE 1-Dairy Crest loses a third of Morrison...  [{'snippets': '['Crest loses a third of Morris...\n",
              "22    Insight hires Aviva's David Hillier for multi-...  [{'snippets': '['hires Aviva's David Hillier f...\n",
              "30    Primark racks up a happy Christmas after stron...  [{'snippets': '['after strong sales']', 'targe...\n",
              "...                                                 ...                                                ...\n",
              "1750  Aviva, M&G suspend property funds as investors...  [{'snippets': '['M&G suspend property funds as...\n",
              "1754  UK housing market steadies after Brexit dip, P...  [{'snippets': '['housing market']', 'target': ...\n",
              "1755  BRIEF-Aviva aims to increase dividend pay-out ...  [{'snippets': '['increase dividend pay-out']',...\n",
              "1764     Builder Persimmon hails 6% rise in house sales  [{'snippets': '['6% rise in house sales']', 't...\n",
              "1779  EasyJet attracts more passengers in June but s...  [{'snippets': '['attracts more passengers']', ...\n",
              "\n",
              "[436 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-jUMAGg4RHR",
        "outputId": "e96687b7-9c30-4604-89d2-ca930dd1e9f0"
      },
      "source": [
        "fiqa_headline.head(1)['info'].values"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([{'snippets': \"['set to step down']\", 'target': 'Royal Mail', 'sentiment_score': '-0.374', 'aspects': \"['Corporate/Appointment']\"}])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNJ7zt_j4pqL"
      },
      "source": [
        "fiqa_headline['snippets'] = list(map(lambda x: x[0]['snippets'], fiqa_headline['info'].values))\n",
        "fiqa_headline['sentiment_score'] = list(map(lambda x: x[0]['sentiment_score'], fiqa_headline['info'].values))\n",
        "fiqa_headline['target'] = list(map(lambda x: x[0]['target'], fiqa_headline['info'].values))\n",
        "fiqa_headline['aspects'] = list(map(lambda x: x[0]['aspects'], fiqa_headline['info'].values))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "yFDLOimj4xdi",
        "outputId": "a2fef0b9-cb7d-4803-deb4-5b4daf77ad6e"
      },
      "source": [
        "fiqa_headline"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>info</th>\n",
              "      <th>snippets</th>\n",
              "      <th>sentiment_score</th>\n",
              "      <th>target</th>\n",
              "      <th>aspects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Royal Mail chairman Donald Brydon set to step ...</td>\n",
              "      <td>[{'snippets': '['set to step down']', 'target'...</td>\n",
              "      <td>['set to step down']</td>\n",
              "      <td>-0.374</td>\n",
              "      <td>Royal Mail</td>\n",
              "      <td>['Corporate/Appointment']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Stakes High for AstraZeneca Heart Drug Facing ...</td>\n",
              "      <td>[{'snippets': '['Facing Tough Competition']', ...</td>\n",
              "      <td>['Facing Tough Competition']</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>AstraZeneca</td>\n",
              "      <td>['Corporate/Risks']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>UPDATE 1-Dairy Crest loses a third of Morrison...</td>\n",
              "      <td>[{'snippets': '['Crest loses a third of Morris...</td>\n",
              "      <td>['Crest loses a third of Morrisons milk contra...</td>\n",
              "      <td>-0.161</td>\n",
              "      <td>Morrisons</td>\n",
              "      <td>['Corporate/Sales/Failed Contract Discussion']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Insight hires Aviva's David Hillier for multi-...</td>\n",
              "      <td>[{'snippets': '['hires Aviva's David Hillier f...</td>\n",
              "      <td>['hires Aviva's David Hillier for multi-asset ...</td>\n",
              "      <td>0.137</td>\n",
              "      <td>Insight</td>\n",
              "      <td>['Corporate/Appointment/Executive Appointment']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Primark racks up a happy Christmas after stron...</td>\n",
              "      <td>[{'snippets': '['after strong sales']', 'targe...</td>\n",
              "      <td>['after strong sales']</td>\n",
              "      <td>0.704</td>\n",
              "      <td>Primark</td>\n",
              "      <td>['Corporate/Sales']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1750</th>\n",
              "      <td>Aviva, M&amp;G suspend property funds as investors...</td>\n",
              "      <td>[{'snippets': '['M&amp;G suspend property funds as...</td>\n",
              "      <td>['M&amp;G suspend property funds as investors panic']</td>\n",
              "      <td>-0.807</td>\n",
              "      <td>M&amp;G</td>\n",
              "      <td>['Corporate/Risks']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1754</th>\n",
              "      <td>UK housing market steadies after Brexit dip, P...</td>\n",
              "      <td>[{'snippets': '['housing market']', 'target': ...</td>\n",
              "      <td>['housing market']</td>\n",
              "      <td>0.339</td>\n",
              "      <td>Perssimon</td>\n",
              "      <td>['Market/Market']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1755</th>\n",
              "      <td>BRIEF-Aviva aims to increase dividend pay-out ...</td>\n",
              "      <td>[{'snippets': '['increase dividend pay-out']',...</td>\n",
              "      <td>['increase dividend pay-out']</td>\n",
              "      <td>0.439</td>\n",
              "      <td>Aviva</td>\n",
              "      <td>['Corporate/Dividend Policy']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1764</th>\n",
              "      <td>Builder Persimmon hails 6% rise in house sales</td>\n",
              "      <td>[{'snippets': '['6% rise in house sales']', 't...</td>\n",
              "      <td>['6% rise in house sales']</td>\n",
              "      <td>0.435</td>\n",
              "      <td>Persimmon</td>\n",
              "      <td>['Corporate/Sales']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1779</th>\n",
              "      <td>EasyJet attracts more passengers in June but s...</td>\n",
              "      <td>[{'snippets': '['attracts more passengers']', ...</td>\n",
              "      <td>['attracts more passengers']</td>\n",
              "      <td>0.259</td>\n",
              "      <td>Ryanair</td>\n",
              "      <td>['Corporate/Sales/Sales']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>436 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  ...                                          aspects\n",
              "1     Royal Mail chairman Donald Brydon set to step ...  ...                        ['Corporate/Appointment']\n",
              "7     Stakes High for AstraZeneca Heart Drug Facing ...  ...                              ['Corporate/Risks']\n",
              "8     UPDATE 1-Dairy Crest loses a third of Morrison...  ...   ['Corporate/Sales/Failed Contract Discussion']\n",
              "22    Insight hires Aviva's David Hillier for multi-...  ...  ['Corporate/Appointment/Executive Appointment']\n",
              "30    Primark racks up a happy Christmas after stron...  ...                              ['Corporate/Sales']\n",
              "...                                                 ...  ...                                              ...\n",
              "1750  Aviva, M&G suspend property funds as investors...  ...                              ['Corporate/Risks']\n",
              "1754  UK housing market steadies after Brexit dip, P...  ...                                ['Market/Market']\n",
              "1755  BRIEF-Aviva aims to increase dividend pay-out ...  ...                    ['Corporate/Dividend Policy']\n",
              "1764     Builder Persimmon hails 6% rise in house sales  ...                              ['Corporate/Sales']\n",
              "1779  EasyJet attracts more passengers in June but s...  ...                        ['Corporate/Sales/Sales']\n",
              "\n",
              "[436 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9EBfaas441H"
      },
      "source": [
        "fiqa_headline['sentiment'] = np.where(fiqa_headline['sentiment_score'].astype(float)>0.1 ,'positive', np.where(fiqa_headline['sentiment_score'].astype(float)<-0.1, 'negative', 'neutral'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3FVkMuw7JfD"
      },
      "source": [
        "fiqa_post['sentiment'] = np.where(fiqa_post['sentiment_score'].astype(float)>0.1 ,'positive', np.where(fiqa_post['sentiment_score'].astype(float)<-0.1, 'negative', 'neutral'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6Y951f87R38"
      },
      "source": [
        "fiqa_post_sentiment = fiqa_post[['sentence','sentiment']]\n",
        "fiqa_post_sentiment.columns = ['statement', 'label']\n",
        "\n",
        "fiqa_headline_sentiment = fiqa_headline[['sentence','sentiment']]\n",
        "fiqa_headline_sentiment.columns = ['statement', 'label']"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygGE2yJRlgNQ"
      },
      "source": [
        "train = pd.concat([train,fiqa_headline_sentiment,fiqa_post_sentiment] )"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "5GRPSXVllvZn",
        "outputId": "5e1866ec-f987-4060-f6a6-4bacbe43aec7"
      },
      "source": [
        "train"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19130</th>\n",
              "      <td>Facebook $FB received a Buy rating from Wells ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19149</th>\n",
              "      <td>$TSLA Wish had my puts back but see if we can ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19161</th>\n",
              "      <td>Citrix Systems Inc $CTXS Position Increased by...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19163</th>\n",
              "      <td>Notable gainers among liquid option names this...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19167</th>\n",
              "      <td>Is #Facebook's user engagement falling? https:...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5957 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               statement     label\n",
              "0      According to Gran , the company has no plans t...   neutral\n",
              "1      Technopolis plans to develop in stages an area...   neutral\n",
              "2      The international electronic industry company ...  negative\n",
              "3      With the new production plant the company woul...  positive\n",
              "4      According to the company 's updated strategy f...  positive\n",
              "...                                                  ...       ...\n",
              "19130  Facebook $FB received a Buy rating from Wells ...  positive\n",
              "19149  $TSLA Wish had my puts back but see if we can ...  negative\n",
              "19161  Citrix Systems Inc $CTXS Position Increased by...  positive\n",
              "19163  Notable gainers among liquid option names this...  positive\n",
              "19167  Is #Facebook's user engagement falling? https:...  negative\n",
              "\n",
              "[5957 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wNb0V7atDSl"
      },
      "source": [
        "It is worth noting that in the dataset there are no individual movie reviews but rather phrases taken out of context and split into smaller parts, each with an assigned sentiment label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VLEkIZ4tDSm"
      },
      "source": [
        "## Main transformers classes\n",
        "In ``transformers``, each model architecture is associated with 3 main types of classes:\n",
        "* A **model class** to load/store a particular pre-train model.\n",
        "* A **tokenizer class** to pre-process the data and make it compatible with a particular model.\n",
        "* A **configuration class** to load/store the configuration of a particular model.\n",
        "\n",
        "For example, if you want to use the Bert architecture for text classification, you would use [``BertForSequenceClassification``](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification) for the **model class**, [``BertTokenizer``](https://huggingface.co/transformers/model_doc/bert.html#berttokenizer) for the **tokenizer class** and [``BertConfig``](https://huggingface.co/transformers/model_doc/bert.html#bertconfig) for the **configuration class**. \n",
        "\n",
        "In order to switch easily between classes  -  each related to a specific model type  -  I created a dictionary that allows loading the correct classes by just specifying the correct model type name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shQV2DQitDSn"
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
        "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
        "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
        "}"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAHN-e3itDSs"
      },
      "source": [
        "You will see later, that those classes share a common class method ``from_pretrained(pretrained_model_name, ...)``. In our case, the parameter ``pretrained_model_name`` is a string with the shortcut name of a pre-trained model/tokenizer/configuration to load, e.g ``'bert-base-uncased'``. We can find all the shortcut names in the transformers documentation [here](https://huggingface.co/transformers/pretrained_models.html#pretrained-models)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXKtucSutDSt"
      },
      "source": [
        "# Parameters\n",
        "seed = 42\n",
        "use_fp16 = False\n",
        "bs = 16\n",
        "\n",
        "# model_type = 'roberta'\n",
        "# pretrained_model_name = 'roberta-base'\n",
        "\n",
        "model_type = 'bert'\n",
        "pretrained_model_name='bert-base-uncased'\n",
        "\n",
        "# model_type = 'distilbert'\n",
        "# pretrained_model_name = 'distilbert-base-uncased'\n",
        "\n",
        "#model_type = 'xlm'\n",
        "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
        "\n",
        "# model_type = 'xlnet'\n",
        "# pretrained_model_name = 'xlnet-base-cased'"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqo7ITB_tDSx"
      },
      "source": [
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_msuwI4ytDS0"
      },
      "source": [
        "Print the available values for ``pretrained_model_name`` (shortcut names) corresponding to the ``model_type`` used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtJD-Gv3tDS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6beba5e0-566a-4451-ddfd-15c7a2e550d9"
      },
      "source": [
        "model_class.pretrained_model_archive_map.keys()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['bert-base-uncased', 'bert-large-uncased', 'bert-base-cased', 'bert-large-cased', 'bert-base-multilingual-uncased', 'bert-base-multilingual-cased', 'bert-base-chinese', 'bert-base-german-cased', 'bert-large-uncased-whole-word-masking', 'bert-large-cased-whole-word-masking', 'bert-large-uncased-whole-word-masking-finetuned-squad', 'bert-large-cased-whole-word-masking-finetuned-squad', 'bert-base-cased-finetuned-mrpc', 'bert-base-german-dbmdz-cased', 'bert-base-german-dbmdz-uncased', 'bert-base-japanese', 'bert-base-japanese-whole-word-masking', 'bert-base-japanese-char', 'bert-base-japanese-char-whole-word-masking', 'bert-base-finnish-cased-v1', 'bert-base-finnish-uncased-v1', 'bert-base-dutch-cased'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGRmwPwQtDS3"
      },
      "source": [
        "It is worth noting that in this case, we use the ``transformers`` library only for a multi-class text classification task. For that reason, this tutorial integrates only the transformer architectures that have a model for sequence classification implemented. These model types are :\n",
        "* BERT (from Google)\n",
        "* XLNet (from Google/CMU)\n",
        "* XLM (from Facebook)\n",
        "* RoBERTa (from Facebook)\n",
        "* DistilBERT (from HuggingFace)\n",
        "\n",
        "However, if you want to go further - by implementing another type of model or NLP task - this tutorial still an excellent starter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luhkLogAtDS4"
      },
      "source": [
        "## Util function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytP2q9FAtDS4"
      },
      "source": [
        "Function to set the seed for generating random numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNb1r0cptDS5"
      },
      "source": [
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value) # Python\n",
        "    np.random.seed(seed_value) # cpu vars\n",
        "    torch.manual_seed(seed_value) # cpu  vars\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
        "        torch.backends.cudnn.deterministic = True  #needed\n",
        "        torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFs888OltDS9"
      },
      "source": [
        "seed_all(seed)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCiCzpYCtDTA"
      },
      "source": [
        "## Data pre-processing\n",
        "\n",
        "To match pre-training, we have to format the model input sequence in a specific format.\n",
        "To do so, you have to first **tokenize** and then **numericalize** the texts correctly.\n",
        "The difficulty here is that each pre-trained model, that we will fine-tune, requires exactly the same specific pre-process - **tokenization** & **numericalization** - than the pre-process used during the pre-train part.\n",
        "Fortunately, the **tokenizer class** from ``transformers`` provides the correct pre-process tools that correspond to each pre-trained model.\n",
        "\n",
        "In the ``fastai`` library, data pre-processing is done automatically during the creation of the ``DataBunch``. \n",
        "As you will see in the ``DataBunch`` implementation, the **tokenizer** and **numericalizer** are passed in the processor argument under the following format :\n",
        "\n",
        "``processor = [TokenizeProcessor(tokenizer=tokenizer,...), NumericalizeProcessor(vocab=vocab,...)]``\n",
        "\n",
        "Let's first analyse how we can integrate the ``transformers`` **tokenizer** within the ``TokenizeProcessor`` function.\n",
        "\n",
        "### Custom Tokenizer\n",
        "This part can be a little bit confusing because a lot of classes are wrapped in each other and with similar names.\n",
        "To resume, if we look attentively at the ``fastai`` implementation, we notice that :\n",
        "1. The [``TokenizeProcessor`` object](https://docs.fast.ai/text.data.html#TokenizeProcessor) takes as ``tokenizer`` argument a ``Tokenizer`` object.\n",
        "2. The [``Tokenizer`` object](https://docs.fast.ai/text.transform.html#Tokenizer) takes as ``tok_func`` argument a ``BaseTokenizer`` object.\n",
        "3. The [``BaseTokenizer`` object](https://docs.fast.ai/text.transform.html#BaseTokenizer) implement the function ``tokenizer(t:str) → List[str]`` that take a text ``t`` and returns the list of its tokens.\n",
        "\n",
        "Therefore, we can simply create a new class ``TransformersBaseTokenizer`` that inherits from ``BaseTokenizer`` and overwrite a new ``tokenizer`` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsvrDlPCtDTA"
      },
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = model_type, **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type in ['roberta']:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
        "            tokens = [CLS] + tokens + [SEP]\n",
        "        else:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
        "            if self.model_type in ['xlnet']:\n",
        "                tokens = tokens + [SEP] +  [CLS]\n",
        "            else:\n",
        "                tokens = [CLS] + tokens + [SEP]\n",
        "        return tokens"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q10DJs3RBXmz"
      },
      "source": [
        "vocab_path = Path(\".\")  / \"/content/gdrive/MyDrive/source/mjfastbert/models/FinVocab-Uncased.txt\""
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK1QszFCtDTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "358a93e8-be86-43f8-f930-7403c2664603"
      },
      "source": [
        "transformer_tokenizer = tokenizer_class.from_pretrained(vocab_path)\n",
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN3levaQ720W",
        "outputId": "d5331635-6d2a-4749-a93f-27d9c1452503"
      },
      "source": [
        "transformer_tokenizer.vocab_size"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30873"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vYBAue0tDTG"
      },
      "source": [
        "In this implementation, be carefull about 3 things :\n",
        "1. As we are not using RNN, we have to limit the sequence length to the model input size.\n",
        "2. Most of the models require special tokens placed at the beginning and end of the sequences.\n",
        "3. Some models like RoBERTa require a space to start the input string. For those models, the encoding methods should be called with ``add_prefix_space`` set to ``True``.\n",
        "\n",
        "Below, you can find the resume of each pre-process requirement for the 5 model types used in this tutorial. You can also find this information on the [HuggingFace documentation](https://huggingface.co/transformers/) in each model section.\n",
        "\n",
        "    bert:       [CLS] + tokens + [SEP] + padding\n",
        "\n",
        "    roberta:    [CLS] + prefix_space + tokens + [SEP] + padding\n",
        "    \n",
        "    distilbert: [CLS] + tokens + [SEP] + padding\n",
        "\n",
        "    xlm:        [CLS] + tokens + [SEP] + padding\n",
        "\n",
        "    xlnet:      padding + tokens + [SEP] + [CLS]\n",
        "    \n",
        "It is worth noting that we don't add padding in this part of the implementation. \n",
        "As we will see later, ``fastai`` manage it automatically during the creation of the ``DataBunch``."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b3n0y3HtDTH"
      },
      "source": [
        "### Custom Numericalizer\n",
        "\n",
        "In ``fastai``, [``NumericalizeProcessor``  object](https://docs.fast.ai/text.data.html#NumericalizeProcessor) takes as ``vocab`` argument a [``Vocab`` object](https://docs.fast.ai/text.transform.html#Vocab). \n",
        "From this analyse, we suggest two ways to adapt the fastai numericalizer:\n",
        "1. You can, like decribed in the [Dev Sharma's article](https://medium.com/analytics-vidhya/using-roberta-with-fastai-for-nlp-7ed3fed21f6c) (Section *1. Setting Up the Tokenizer*), retreive the list of tokens and create a ``Vocab`` object.\n",
        "2. Create a new class ``TransformersVocab`` that inherits from ``Vocab`` and overwrite ``numericalize`` and ``textify`` functions.\n",
        "\n",
        "Even if the first solution seems to be simpler, ``Transformers`` does not provide, for all models, a straightforward way to retreive his list of tokens. \n",
        "Therefore, I implemented the second solution, which runs for each model type.\n",
        "It consists of using the functions ``convert_tokens_to_ids`` and ``convert_ids_to_tokens`` in respectively ``numericalize`` and ``textify``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPn0Io7JtDTH"
      },
      "source": [
        "class TransformersVocab(Vocab):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "        super(TransformersVocab, self).__init__(itos = [])\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
        "        \"Convert a list of tokens `t` to their ids.\"\n",
        "        return self.tokenizer.convert_tokens_to_ids(t)\n",
        "        #return self.tokenizer.encode(t)\n",
        "\n",
        "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
        "        \"Convert a list of `nums` to their tokens.\"\n",
        "        nums = np.array(nums).tolist()\n",
        "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
        "    \n",
        "    def __getstate__(self):\n",
        "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
        "\n",
        "    def __setstate__(self, state:dict):\n",
        "        self.itos = state['itos']\n",
        "        self.tokenizer = state['tokenizer']\n",
        "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi3JkKSstDTJ"
      },
      "source": [
        "NB: The functions ``__gestate__`` and ``__setstate__`` allow the functions [export](https://docs.fast.ai/basic_train.html#Learner.export) and [load_learner](https://docs.fast.ai/basic_train.html#load_learner) to work correctly with ``TransformersVocab``."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rECF4LcWtDTK"
      },
      "source": [
        "### Custom processor\n",
        "Now that we have our custom **tokenizer** and **numericalizer**, we can create the custom **processor**. Notice we are passing the ``include_bos = False`` and ``include_eos = False`` options. This is because ``fastai`` adds its own special tokens by default which interferes with the ``[CLS]`` and ``[SEP]`` tokens added by our custom tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNdd-QJPtDTK"
      },
      "source": [
        "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
        "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
        "\n",
        "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "transformer_processor = [tokenize_processor, numericalize_processor]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CM70_wMtDTO"
      },
      "source": [
        "## Setting up the Databunch\n",
        "For the DataBunch creation, you have to pay attention to set the processor argument to our new custom processor ``transformer_processor`` and manage correctly the padding.\n",
        "\n",
        "As mentioned in the HuggingFace documentation, BERT, RoBERTa, XLM and DistilBERT are models with absolute position embeddings, so it's usually advised to pad the inputs on the right rather than the left. Regarding XLNET, it is a model with relative position embeddings, therefore, you can either pad the inputs on the right or on the left."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw1Sza5DtDTO"
      },
      "source": [
        "pad_first = bool(model_type in ['xlnet'])\n",
        "pad_idx = transformer_tokenizer.pad_token_id"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXxdJ5rttDTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d4a4dff-c7a6-4595-fc36-9d953d3ecf12"
      },
      "source": [
        "tokens = transformer_tokenizer.tokenize('Salut c est moi, Hello it s me')\n",
        "print(tokens)\n",
        "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)\n",
        "transformer_tokenizer.convert_ids_to_tokens(ids)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sal', '##ut', 'c', 'est', 'moi', ',', 'hello', 'it', 's', 'me']\n",
            "[10014, 5175, 2435, 5561, 20171, 585, 23738, 41, 58, 914]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sal', '##ut', 'c', 'est', 'moi', ',', 'hello', 'it', 's', 'me']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3naUiIRtDTT"
      },
      "source": [
        "There is multible ways to create a DataBunch, in our implementation, we use [the data block API](https://docs.fast.ai/data_block.html#The-data-block-API), which gives more flexibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpaEJYDJtDTT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "881aaa7d-acb3-4934-fc24-b5d708fe3da9"
      },
      "source": [
        "databunch = (TextList.from_df(train, cols='statement', processor=transformer_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols= 'label')\n",
        "             .add_test(test)\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQZ9OCD88mtR"
      },
      "source": [
        "model_path = Path(\".\") / \"/content/gdrive/MyDrive/source/mjfastbert/models\""
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Gr-EY-S8aRN"
      },
      "source": [
        "databunch.save(model_path / \"databunch.pkl\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcxhKuOltDTX"
      },
      "source": [
        "Check batch and tokenizer :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNtWiLEjtDTY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "c2f50357-a1c4-4b48-ba5a-3bf07635fce6"
      },
      "source": [
        "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
        "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
        "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
        "databunch.show_batch()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] token : [CLS]\n",
            "[SEP] token : [SEP]\n",
            "[PAD] token : [PAD]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/text/data.py:339: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  idx_min = (t != self.pad_idx).nonzero().min()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>[CLS] supported nokia phones include : n ##96 , n ##95 - 8 ##gb , n ##95 , n ##93 - n ##93 ##1 , n ##92 , n ##85 , n ##82 , n ##81 , n ##80 , n ##79 , n ##78 , n ##77 , n ##76 , n ##75 , n ##73 , n ##72 , n ##71 , e ##90 , e ##71 ,</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] 3 january 2011 - scand ##ina ##vian lenders sam ##po bank ( hel : sam ##as ) , po ##h ##jo ##la bank ( hel : po ##h ##1 ##s ) and sve ##nsk ##a hand ##els ##bank ##en ( sto : sh ##b a ) have provided a eur ##16 ##0m ( usd ##21 ##3m ) line of credit to le ##mmi ##nk ##aine ##n o ##y ##j</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] 1 p . m . central office of nord ##ea bank 19 3 - ya ul ##its ##a ya ##ms ##ko ##go poly ##a , building 1 telephone : 495 777 - 34 - 77 ex ##t . 393 ##2 , 393 ##1 03 . 02 . 2011 uni ##mil ##k - eg ##m 03 - 04 . 02 . 2011 x ##vi international business - summit food business</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] narrow ##s to eur ##2 . 8 m 9 - mo ' 09 29 october 2009 - fin ##nish software and hardware developer ele ##kt ##ro ##bit o ##y ##j hel : eb ##g ##1 ##v , or eb , said today that its net loss narrowed to eur ##2 . 8 m for the first nine months of 2009 from eur ##35 . 6 m for the same</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXSHX8QPtDTa"
      },
      "source": [
        "Check batch and numericalizer :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABPlre3qtDTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449aa53b-a837-4a36-854d-5fd18671cb69"
      },
      "source": [
        "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
        "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
        "print('[PAD] id :', pad_idx)\n",
        "test_one_batch = databunch.one_batch()[0]\n",
        "print('Batch shape : ',test_one_batch.shape)\n",
        "print(test_one_batch)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] id : 3\n",
            "[SEP] id : 4\n",
            "[PAD] id : 0\n",
            "Batch shape :  torch.Size([16, 133])\n",
            "tensor([[    3,  2948,  8827,  ...,   456,   505,     4],\n",
            "        [    3,     6,   125,  ...,     0,     0,     0],\n",
            "        [    3,     6,  4415,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [    3, 11206,  1239,  ...,     0,     0,     0],\n",
            "        [    3, 15631,  2083,  ...,     0,     0,     0],\n",
            "        [    3, 10250,  1859,  ...,     0,     0,     0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwL2014CtDTe"
      },
      "source": [
        "### Custom model\n",
        "As mentioned [here](https://github.com/huggingface/transformers#models-always-output-tuples), every model's forward method always outputs a ``tuple`` with various elements depending on the model and the configuration parameters. In our case, we are interested to access only to the logits. \n",
        "One way to access them is to create a custom model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTky76-vtDTe"
      },
      "source": [
        "# defining our model architecture \n",
        "class CustomTransformerModel(nn.Module):\n",
        "    def __init__(self, transformer_model: PreTrainedModel, num_labels=3):\n",
        "        super(CustomTransformerModel,self).__init__()\n",
        "        self.config = BertConfig(vocab_size_or_config_json_file=30873, hidden_size=768, num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "        self.transformer = transformer_model\n",
        "        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(self.config.hidden_size, num_labels)\n",
        "        nn.init.xavier_normal_(self.classifier.weight)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        \n",
        "        # attention_mask\n",
        "        # Mask to avoid performing attention on padding token indices.\n",
        "        # Mask values selected in ``[0, 1]``:\n",
        "        # ``1`` for tokens that are NOT MASKED, ``0`` for MASKED tokens.\n",
        "        attention_mask = (input_ids!=pad_idx).type(input_ids.type()) \n",
        "        \n",
        "        logits = self.transformer(input_ids,\n",
        "                                  attention_mask = attention_mask)[0]   \n",
        "        return logits"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFS_x0PttDTh"
      },
      "source": [
        "To make our transformers adapted to multiclass classification, before loading the pre-trained model, we need to precise the number of labels. To do so, you can modify the config instance or either modify like in [Keita Kurita's article](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/) (Section: *Initializing the Learner*) the ``num_labels`` argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dLyyVjdDPCs"
      },
      "source": [
        "pretrained_language_model_path = Path(\".\") / \"/content/gdrive/MyDrive/source/mjfastbert/models/FinBERT-FinVocab-Uncased/\""
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOJGa7cVtDTi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd92f65-e2a0-4378-b3fd-5c2829a65a90"
      },
      "source": [
        "config = config_class.from_pretrained(pretrained_language_model_path)\n",
        "config.num_labels = 3\n",
        "config.use_bfloat16 = use_fp16\n",
        "print(config)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertConfig {\n",
            "  \"architectures\": null,\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 3,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30873\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9ZFM3oCD8Gm"
      },
      "source": [
        "transformer_model = model_class.from_pretrained(pretrained_language_model_path, config = config)\n",
        "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
        "\n",
        "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQh3sG3SEFpj"
      },
      "source": [
        "from fastai.callbacks import *\n",
        "from transformers import AdamW\n",
        "from functools import partial\n",
        "\n",
        "CustomAdamW = partial(AdamW, correct_bias=False)\n",
        "\n",
        "learner = Learner(databunch, \n",
        "                  custom_transformer_model, \n",
        "                  opt_func = CustomAdamW, \n",
        "                  metrics=[accuracy, error_rate])\n",
        "\n",
        "# Show graph of learner stats and metrics after each epoch.\n",
        "learner.callbacks.append(ShowGraph(learner))\n",
        "\n",
        "# Put learn in FP16 precision mode. --> Seems to not working\n",
        "if use_fp16: learner = learner.to_fp16()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MwPnHCVzH98"
      },
      "source": [
        "# Show graph of learner stats and metrics after each epoch.\n",
        "learner.callbacks.append(ShowGraph(learner))\n",
        "\n",
        "# Put learn in FP16 precision mode. --> Not working in the tutorial\n",
        "if use_fp16: learner = learner.to_fp16()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSFwOrIuD7DJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnd9nzsPtDTt"
      },
      "source": [
        "## Learner : Custom Optimizer / Custom Metric\n",
        "In ``pytorch-transformers``, HuggingFace had implemented two specific optimizers  -  BertAdam and OpenAIAdam  -  that have been replaced by a single AdamW optimizer.\n",
        "This optimizer matches Pytorch Adam optimizer Api, therefore, it becomes straightforward to integrate it within ``fastai``.\n",
        "It is worth noting that for reproducing BertAdam specific behavior, you have to set ``correct_bias = False``.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfXjBlyStDTu"
      },
      "source": [
        "from fastai.callbacks import *\n",
        "from transformers import AdamW\n",
        "from functools import partial\n",
        "\n",
        "CustomAdamW = partial(AdamW, correct_bias=False)\n",
        "\n",
        "learner = Learner(databunch, \n",
        "                  custom_transformer_model, \n",
        "                  opt_func = CustomAdamW, \n",
        "                  metrics=[accuracy, error_rate])\n",
        "\n",
        "# Show graph of learner stats and metrics after each epoch.\n",
        "learner.callbacks.append(ShowGraph(learner))\n",
        "\n",
        "# Put learn in FP16 precision mode. --> Seems to not working\n",
        "if use_fp16: learner = learner.to_fp16()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMMU3kN3tDT0"
      },
      "source": [
        "## Discriminative Fine-tuning and Gradual unfreezing (Optional)\n",
        "To use **discriminative layer training** and **gradual unfreezing**, ``fastai`` provides one tool that allows to \"split\" the structure model into groups. An instruction to perform that \"split\" is described in the fastai documentation [here](https://docs.fast.ai/basic_train.html#Discriminative-layer-training).\n",
        "\n",
        "Unfortunately,  the model architectures are too different to create a unique generic function that can \"split\" all the model types in a convenient way. Thereby, you will have to implement a custom \"split\" for each different model architecture.\n",
        "\n",
        "For example, if we use the RobBERTa model and that we observe his architecture by making ``print(learner.model)``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujH8KI5stDT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04372a26-03fe-423e-9b7e-5810621419c5"
      },
      "source": [
        "print(learner.model)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CustomTransformerModel(\n",
            "  (transformer): BertForSequenceClassification(\n",
            "    (bert): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(30873, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OZiDewPtDT7"
      },
      "source": [
        "We can decide to divide the model in 14 blocks :\n",
        "* 1 Embedding\n",
        "* 12 transformer\n",
        "* 1 classifier\n",
        "\n",
        "In this case, we can split our model in this way :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ-Ln-5VzRGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c139f6f-83b0-4fda-e4d7-07181014ccf6"
      },
      "source": [
        "num_groups = len(learner.layer_groups)\n",
        "print('Learner split in',num_groups,'groups')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learner split in 1 groups\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGY5QD4VtDT8"
      },
      "source": [
        "# For DistilBERT\n",
        "# list_layers = [learner.model.transformer.distilbert.embeddings,\n",
        "#                learner.model.transformer.distilbert.transformer.layer[0],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[1],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[2],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[3],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[4],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[5],\n",
        "#                learner.model.transformer.pre_classifier]\n",
        "\n",
        "# For xlnet-base-cased\n",
        "# list_layers = [learner.model.transformer.transformer.word_embedding,\n",
        "#               learner.model.transformer.transformer.layer[0],\n",
        "#               learner.model.transformer.transformer.layer[1],\n",
        "#               learner.model.transformer.transformer.layer[2],\n",
        "#               learner.model.transformer.transformer.layer[3],\n",
        "#               learner.model.transformer.transformer.layer[4],\n",
        "#               learner.model.transformer.transformer.layer[5],\n",
        "#               learner.model.transformer.transformer.layer[6],\n",
        "#               learner.model.transformer.transformer.layer[7],\n",
        "#               learner.model.transformer.transformer.layer[8],\n",
        "#               learner.model.transformer.transformer.layer[9],\n",
        "#               learner.model.transformer.transformer.layer[10],\n",
        "#               learner.model.transformer.transformer.layer[11],\n",
        "#               learner.model.transformer.sequence_summary]\n",
        "\n",
        "# For roberta-base\n",
        "# list_layers = [learner.model.transformer.roberta.embeddings,\n",
        "#               learner.model.transformer.roberta.encoder.layer[0],\n",
        "#               learner.model.transformer.roberta.encoder.layer[1],\n",
        "#               learner.model.transformer.roberta.encoder.layer[2],\n",
        "#               learner.model.transformer.roberta.encoder.layer[3],\n",
        "#               learner.model.transformer.roberta.encoder.layer[4],\n",
        "#               learner.model.transformer.roberta.encoder.layer[5],\n",
        "#               learner.model.transformer.roberta.encoder.layer[6],\n",
        "#               learner.model.transformer.roberta.encoder.layer[7],\n",
        "#               learner.model.transformer.roberta.encoder.layer[8],\n",
        "#               learner.model.transformer.roberta.encoder.layer[9],\n",
        "#               learner.model.transformer.roberta.encoder.layer[10],\n",
        "#               learner.model.transformer.roberta.encoder.layer[11],\n",
        "#               learner.model.transformer.roberta.pooler]\n",
        "\n",
        "# For bert-base-uncased\n",
        "list_layers = [learner.model.transformer.bert.embeddings,\n",
        "              learner.model.transformer.bert.encoder.layer[0],\n",
        "              learner.model.transformer.bert.encoder.layer[1],\n",
        "              learner.model.transformer.bert.encoder.layer[2],\n",
        "              learner.model.transformer.bert.encoder.layer[3],\n",
        "              learner.model.transformer.bert.encoder.layer[4],\n",
        "              learner.model.transformer.bert.encoder.layer[5],\n",
        "              learner.model.transformer.bert.encoder.layer[6],\n",
        "              learner.model.transformer.bert.encoder.layer[7],\n",
        "              learner.model.transformer.bert.encoder.layer[8],\n",
        "              learner.model.transformer.bert.encoder.layer[9],\n",
        "              learner.model.transformer.bert.encoder.layer[10],\n",
        "              learner.model.transformer.bert.encoder.layer[11],\n",
        "              learner.model.transformer.bert.pooler]\n",
        "\n",
        "learner.split(list_layers);"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmJ5v_3SEBah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40806c5f-7c21-4950-9745-9a2b7e1cb1b3"
      },
      "source": [
        "num_groups = len(learner.layer_groups)\n",
        "print('Learner split in',num_groups,'groups')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learner split in 14 groups\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VtbfWkztDUF"
      },
      "source": [
        "Check groups : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDTK8dUYtDUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fd99404-45a0-4afb-ee85-b206759307ee"
      },
      "source": [
        "learner.split(list_layers)\n",
        "# learner.split(list_layers)\n",
        "# num_groups = len(learner.layer_groups)\n",
        "# print('Learner split in',num_groups,'groups')\n",
        "# print(learner.layer_groups)\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Learner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (5362 items)\n",
              "x: TextList\n",
              "[CLS] according to gran , the company has no plans to move all production to russia , although that is where the company is growing [SEP],[CLS] techno ##poli ##s plans to develop in stages an area of no less than 100 , 000 square meters in order to host companies working in computer technologies and telecommunications , the statement said [SEP],[CLS] the international electronic industry company el ##co ##te ##q has laid off tens of employees from its tall ##inn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily post ##ime ##es reported [SEP],[CLS] with the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability [SEP],[CLS] according to the company ' s updated strategy for the years 2009 - 2012 , bas ##ware targets a long - term net sales growth in the range of 20 % - 40 % with an operating profit margin of 10 % - 20 % of net sales [SEP]\n",
              "y: CategoryList\n",
              "neutral,neutral,negative,positive,positive\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (595 items)\n",
              "x: TextList\n",
              "[CLS] swedish , fin ##nish and dani ##sh listed companies are organized in three market cap segments , nordic large cap , mid cap and small cap [SEP],[CLS] ` ` ix ##ono ##s has a rich heritage in developing leadership experiences in the smartphone segment [SEP],[CLS] the trade is in accordance with the agreement announced on 26 march 2008 [SEP],[CLS] the group ' s consolidated net sales for 2008 totaled 3 . 4 billion euros and it employs approximately 13 , 000 persons [SEP],[CLS] in the video above mari ##me ##kk ##o ' s design manager , noo ##ra nii ##ini ##nos ##ki , explains that the brands are a natural fit for each other because they both have a time ##less style [SEP]\n",
              "y: CategoryList\n",
              "neutral,positive,neutral,neutral,neutral\n",
              "Path: .;\n",
              "\n",
              "Test: LabelList (2264 items)\n",
              "x: TextList\n",
              "[CLS] according to gran , the company has no plans to move all production to russia , although that is where the company is growing neutral [SEP],[CLS] for the last quarter of 2010 , component ##a ' s net sales doubled to eur ##13 ##1m from eur ##76 ##m for the same period a year earlier , while it moved to a zero pre - tax profit from a pre - tax loss of eur ##7m positive [SEP],[CLS] in the third quarter of 2010 , net sales increased by 5 . 2 % to eur 205 . 5 mn , and operating profit by 34 . 9 % to eur 23 . 5 mn positive [SEP],[CLS] operating profit rose to eur 13 . 1 mn from eur 8 . 7 mn in the corresponding period in 2007 representing 7 . 7 % of net sales positive [SEP],[CLS] operating profit totall ##ed eur 21 . 1 mn , up from eur 18 . 6 mn in 2007 , representing 9 . 7 % of net sales positive [SEP]\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: ., model=CustomTransformerModel(\n",
              "  (transformer): BertForSequenceClassification(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30873, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              "), opt_func=functools.partial(<class 'transformers.optimization.AdamW'>, correct_bias=False), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fee64e53158>, <function error_rate at 0x7fee64e53378>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[ShowGraph\n",
              "learn: Learner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (5362 items)\n",
              "x: TextList\n",
              "[CLS] according to gran , the company has no plans to move all production to russia , although that is where the company is growing [SEP],[CLS] techno ##poli ##s plans to develop in stages an area of no less than 100 , 000 square meters in order to host companies working in computer technologies and telecommunications , the statement said [SEP],[CLS] the international electronic industry company el ##co ##te ##q has laid off tens of employees from its tall ##inn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily post ##ime ##es reported [SEP],[CLS] with the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability [SEP],[CLS] according to the company ' s updated strategy for the years 2009 - 2012 , bas ##ware targets a long - term net sales growth in the range of 20 % - 40 % with an operating profit margin of 10 % - 20 % of net sales [SEP]\n",
              "y: CategoryList\n",
              "neutral,neutral,negative,positive,positive\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (595 items)\n",
              "x: TextList\n",
              "[CLS] swedish , fin ##nish and dani ##sh listed companies are organized in three market cap segments , nordic large cap , mid cap and small cap [SEP],[CLS] ` ` ix ##ono ##s has a rich heritage in developing leadership experiences in the smartphone segment [SEP],[CLS] the trade is in accordance with the agreement announced on 26 march 2008 [SEP],[CLS] the group ' s consolidated net sales for 2008 totaled 3 . 4 billion euros and it employs approximately 13 , 000 persons [SEP],[CLS] in the video above mari ##me ##kk ##o ' s design manager , noo ##ra nii ##ini ##nos ##ki , explains that the brands are a natural fit for each other because they both have a time ##less style [SEP]\n",
              "y: CategoryList\n",
              "neutral,positive,neutral,neutral,neutral\n",
              "Path: .;\n",
              "\n",
              "Test: LabelList (2264 items)\n",
              "x: TextList\n",
              "[CLS] according to gran , the company has no plans to move all production to russia , although that is where the company is growing neutral [SEP],[CLS] for the last quarter of 2010 , component ##a ' s net sales doubled to eur ##13 ##1m from eur ##76 ##m for the same period a year earlier , while it moved to a zero pre - tax profit from a pre - tax loss of eur ##7m positive [SEP],[CLS] in the third quarter of 2010 , net sales increased by 5 . 2 % to eur 205 . 5 mn , and operating profit by 34 . 9 % to eur 23 . 5 mn positive [SEP],[CLS] operating profit rose to eur 13 . 1 mn from eur 8 . 7 mn in the corresponding period in 2007 representing 7 . 7 % of net sales positive [SEP],[CLS] operating profit totall ##ed eur 21 . 1 mn , up from eur 18 . 6 mn in 2007 , representing 9 . 7 % of net sales positive [SEP]\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: ., model=CustomTransformerModel(\n",
              "  (transformer): BertForSequenceClassification(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30873, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              "), opt_func=functools.partial(<class 'transformers.optimization.AdamW'>, correct_bias=False), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fee64e53158>, <function error_rate at 0x7fee64e53378>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(30873, 768, padding_idx=0)\n",
              "  (1): Embedding(512, 768)\n",
              "  (2): Embedding(2, 768)\n",
              "  (3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (4): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Tanh()\n",
              "  (2): Dropout(p=0.1, inplace=False)\n",
              "  (3): Linear(in_features=768, out_features=3, bias=True)\n",
              "  (4): Dropout(p=0.1, inplace=False)\n",
              "  (5): Linear(in_features=768, out_features=3, bias=True)\n",
              ")], add_time=True, silent=False)], layer_groups=[Sequential(\n",
              "  (0): Embedding(30873, 768, padding_idx=0)\n",
              "  (1): Embedding(512, 768)\n",
              "  (2): Embedding(2, 768)\n",
              "  (3): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (4): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (3): Dropout(p=0.1, inplace=False)\n",
              "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (5): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (6): Dropout(p=0.1, inplace=False)\n",
              "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (9): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "), Sequential(\n",
              "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (1): Tanh()\n",
              "  (2): Dropout(p=0.1, inplace=False)\n",
              "  (3): Linear(in_features=768, out_features=3, bias=True)\n",
              "  (4): Dropout(p=0.1, inplace=False)\n",
              "  (5): Linear(in_features=768, out_features=3, bias=True)\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2bkHpsPtDUL"
      },
      "source": [
        "Note that I didn't found any document that has studied the influence of **Discriminative Fine-tuning** and **Gradual unfreezing** or even **Slanted Triangular Learning Rates** with transformers. Therefore, using these tools does not guarantee better results. If you found any interesting documents, please let us know in the comment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeTTTRf9tDUM"
      },
      "source": [
        "## Train\n",
        "Now we can finally use all the fastai build-in features to train our model. Like the ULMFiT method, we will use **Slanted Triangular Learning Rates**, **Discriminate Learning Rate** and **gradually unfreeze the model**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X2YLqMFohX2"
      },
      "source": [
        "models_path = Path(\".\")  / \"/content/gdrive/MyDrive/source/mjfastbert/models/\""
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfEUIFr9tDUN"
      },
      "source": [
        "learner.save(models_path / 'untrain')"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5zX17E-tDUS"
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load(models_path /'untrain');"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYjCWN6YtDUV"
      },
      "source": [
        "Therefore, we first freeze all the groups but the classifier with :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnRHuu-9tDUW"
      },
      "source": [
        "learner.freeze_to(-1)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB4ClDhotDUc"
      },
      "source": [
        "We check which layer are trainable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06RGLF4LtDUg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "527a93fa-7ea6-459e-c619-113195308569"
      },
      "source": [
        "learner.summary()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CustomTransformerModel\n",
              "======================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "======================================================================\n",
              "Embedding            [133, 768]           23,710,464 False     \n",
              "______________________________________________________________________\n",
              "Embedding            [133, 768]           393,216    False     \n",
              "______________________________________________________________________\n",
              "Embedding            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 133, 133]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 3072]          2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 133, 133]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 3072]          2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 133, 133]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 3072]          2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 133, 133]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 3072]          2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 133, 133]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 3072]          2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 133, 133]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 3072]          2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 133, 133]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 3072]          2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 133, 133]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 3072]          2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 133, 133]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 3072]          2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 133, 133]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 3072]          2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 133, 133]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 3072]          2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 133, 133]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 3072]          2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [133, 768]           2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [133, 768]           1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [133, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [768]                590,592    True      \n",
              "______________________________________________________________________\n",
              "Tanh                 [768]                0          False     \n",
              "______________________________________________________________________\n",
              "Dropout              [768]                0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [3]                  2,307      True      \n",
              "______________________________________________________________________\n",
              "\n",
              "Total params: 109,754,115\n",
              "Total trainable params: 592,899\n",
              "Total non-trainable params: 109,161,216\n",
              "Optimized with 'transformers.optimization.AdamW', correct_bias=False\n",
              "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
              "Loss function : FlattenedLoss\n",
              "======================================================================\n",
              "Callbacks functions applied \n",
              "    ShowGraph"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC0zJ2cHtDUk"
      },
      "source": [
        "For **Slanted Triangular Learning Rates** you have to use the function ``one_cycle``. For more information please check the fastai documentation [here](https://docs.fast.ai/callbacks.one_cycle.html). \n",
        "\n",
        "To use our ``one_cycle`` we will need an optimum learning rate. We can find this learning rate by using a learning rate finder which can be called by using ``lr_find``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f0D_SoDtDUk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "aced727d-85cc-408b-b1d0-a3595fdaa5a1"
      },
      "source": [
        "learner.lr_find()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='69' class='' max='335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      20.60% [69/335 00:02<00:10 2.0999]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVUO_PgGtDUo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "6c3b8de0-e9d5-492f-b774-c1229270572e"
      },
      "source": [
        "learner.recorder.plot(skip_end=10,suggestion=True)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min numerical gradient: 7.59E-05\n",
            "Min loss divided by 10: 8.32E-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkfBpqeItDUs"
      },
      "source": [
        "We will pick a value a bit before the minimum, where the loss still improves. Here 2x10^-3 seems to be a good value.\n",
        "\n",
        "Next we will use ``fit_one_cycle`` with the chosen learning rate as the maximum learning rate. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5phSbt5AtDUt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "683a9d21-ccbf-43cb-d305-08005ee2d6b1"
      },
      "source": [
        "learner.fit_one_cycle(10,max_lr=8e-05,moms=(0.8,0.7))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.758317</td>\n",
              "      <td>0.721377</td>\n",
              "      <td>0.695798</td>\n",
              "      <td>0.304202</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.618663</td>\n",
              "      <td>0.612023</td>\n",
              "      <td>0.719328</td>\n",
              "      <td>0.280672</td>\n",
              "      <td>00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.561295</td>\n",
              "      <td>0.547636</td>\n",
              "      <td>0.744538</td>\n",
              "      <td>0.255462</td>\n",
              "      <td>00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.553940</td>\n",
              "      <td>0.531771</td>\n",
              "      <td>0.761345</td>\n",
              "      <td>0.238655</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.550661</td>\n",
              "      <td>0.526338</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.527633</td>\n",
              "      <td>0.516897</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.221849</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.518169</td>\n",
              "      <td>0.516829</td>\n",
              "      <td>0.776471</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.503006</td>\n",
              "      <td>0.513352</td>\n",
              "      <td>0.779832</td>\n",
              "      <td>0.220168</td>\n",
              "      <td>00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.516107</td>\n",
              "      <td>0.511056</td>\n",
              "      <td>0.776471</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.495147</td>\n",
              "      <td>0.511696</td>\n",
              "      <td>0.783193</td>\n",
              "      <td>0.216807</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocBh_1HLtDUz"
      },
      "source": [
        "learner.save(pretrained_language_model_path / 'first_cycle')"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVROi-yJtDU_"
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load(pretrained_language_model_path / 'first_cycle');"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZo3L87LtDVD"
      },
      "source": [
        "We then unfreeze the second group of layers and repeat the operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kUlC47etDVE"
      },
      "source": [
        "learner.freeze_to(-2)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSqUekk6tDVJ"
      },
      "source": [
        "lr = 8e-5"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iltApzEgtDVM"
      },
      "source": [
        "Note here that we use slice to create separate learning rate for each group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEmo6INPtDVN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "f001bc46-0f99-408d-e7e9-de7193fd7462"
      },
      "source": [
        "learner.fit_one_cycle(4, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.552783</td>\n",
              "      <td>0.532139</td>\n",
              "      <td>0.784874</td>\n",
              "      <td>0.215126</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.455158</td>\n",
              "      <td>0.494971</td>\n",
              "      <td>0.798319</td>\n",
              "      <td>0.201681</td>\n",
              "      <td>00:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.314669</td>\n",
              "      <td>0.451268</td>\n",
              "      <td>0.831933</td>\n",
              "      <td>0.168067</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.229764</td>\n",
              "      <td>0.464016</td>\n",
              "      <td>0.840336</td>\n",
              "      <td>0.159664</td>\n",
              "      <td>00:16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4WQOsJItDVV"
      },
      "source": [
        "learner.save(pretrained_language_model_path / 'second_cycle')"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO_9rBxftDVX"
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load(pretrained_language_model_path / 'second_cycle');"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wTaxEIvtDVb"
      },
      "source": [
        "learner.freeze_to(-3)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8I9hRjktDVf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "b2211243-8f78-4256-aab6-e5ecf4d9439b"
      },
      "source": [
        "learner.fit_one_cycle(4, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.290015</td>\n",
              "      <td>0.565515</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.237882</td>\n",
              "      <td>0.671332</td>\n",
              "      <td>0.776471</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.095293</td>\n",
              "      <td>0.636604</td>\n",
              "      <td>0.818487</td>\n",
              "      <td>0.181513</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.055539</td>\n",
              "      <td>0.655476</td>\n",
              "      <td>0.810084</td>\n",
              "      <td>0.189916</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXGrX_EstDVj"
      },
      "source": [
        "learner.save(pretrained_language_model_path / 'third_cycle')"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYe8TJQDtDVm"
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load(pretrained_language_model_path / 'third_cycle');"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2N5mxAStDVp"
      },
      "source": [
        "Here, we unfreeze all the groups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN-iulGatDVq"
      },
      "source": [
        "learner.unfreeze()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG1VmcYmtDVu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "21ad3af2-1abd-4a99-ca67-431cb2e19286"
      },
      "source": [
        "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.306472</td>\n",
              "      <td>0.556194</td>\n",
              "      <td>0.811765</td>\n",
              "      <td>0.188235</td>\n",
              "      <td>00:46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.085392</td>\n",
              "      <td>0.543332</td>\n",
              "      <td>0.836975</td>\n",
              "      <td>0.163025</td>\n",
              "      <td>00:45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-w9ALFgtDV1"
      },
      "source": [
        "Now, you can predict examples with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "agXEgNXgs9sX",
        "outputId": "535849fc-a9e2-46eb-8c52-bd7e41109e64"
      },
      "source": [
        "test"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In the third quarter of 2010 , net sales incre...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2259</th>\n",
              "      <td>Operating result for the 12-month period decre...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2260</th>\n",
              "      <td>HELSINKI Thomson Financial - Shares in Cargote...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261</th>\n",
              "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262</th>\n",
              "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2263</th>\n",
              "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2264 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              statement     label\n",
              "0     According to Gran , the company has no plans t...   neutral\n",
              "1     For the last quarter of 2010 , Componenta 's n...  positive\n",
              "2     In the third quarter of 2010 , net sales incre...  positive\n",
              "3     Operating profit rose to EUR 13.1 mn from EUR ...  positive\n",
              "4     Operating profit totalled EUR 21.1 mn , up fro...  positive\n",
              "...                                                 ...       ...\n",
              "2259  Operating result for the 12-month period decre...  negative\n",
              "2260  HELSINKI Thomson Financial - Shares in Cargote...  negative\n",
              "2261  LONDON MarketWatch -- Share prices ended lower...  negative\n",
              "2262  Operating profit fell to EUR 35.4 mn from EUR ...  negative\n",
              "2263  Sales in Finland decreased by 10.5 % in Januar...  negative\n",
              "\n",
              "[2264 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "1a550d0bca9845a18344d6ef714bef60",
            "b5817fe0ffc848269115964b5953068e",
            "710f4f6f2a3249599787bb60c9667e4a",
            "33811aed95834bf596c2328905cb33c3",
            "71f31bbe7893426ca389206777b61b4e",
            "7c89fe541b164dfbabc1593513ae3d65",
            "18fa2f20fdde4fb9bd2992b1b76e42a7",
            "53960f84e9a44f30b1975aaae155ee74"
          ]
        },
        "id": "_zT0bM4Ps_6o",
        "outputId": "c2e09012-c9df-48b7-e273-8e5feeacdf30"
      },
      "source": [
        "from tqdm import tqdm, tqdm_notebook\n",
        "tqdm_notebook().pandas()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a550d0bca9845a18344d6ef714bef60",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "4df16002a9234a5faea822711974ac49",
            "ffb2d16ba25f4750bde99093ccb4f3c0",
            "b475e8f9443947acb0827f221c2cd88a",
            "0fe6d8403911428a9618cd7abd0ff9cc",
            "3e354062e9dd44ca8121bd0672ee052d",
            "eb5d5a6fa80d4ac08f1becefa4179f12",
            "53d2a995bf8a4f1e84928c762c3a0397",
            "509e1ced2ec14a3b8087519ade59b8c0"
          ]
        },
        "id": "jYeal1LTtCnp",
        "outputId": "96a720b2-a0d8-44ad-882c-1cad5af6a90a"
      },
      "source": [
        "test['prediction'] = test['statement'].progress_apply(lambda x:str(learner.predict(x)[0]))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4df16002a9234a5faea822711974ac49",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2264.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "LNueQylwvd1-",
        "outputId": "5e9ffedb-bfb9-41e4-9a7a-ebd1e380e7b8"
      },
      "source": [
        "test[test['prediction'].astype(str).str.lower() != test['label'].astype(str).str.lower()]"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>11 August 2010 - Finnish measuring equipment m...</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>ADP News - Apr 22 , 2009 - Finnish business in...</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>Finnish flexible packaging manufacturer Suomin...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>The company also said that in Poland a profita...</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>These moderate but significant changes resulte...</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>According to Finnair Technical Services , the ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>Symphony Services provides development service...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>620</th>\n",
              "      <td>The office space will rise above the remodeled...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783</th>\n",
              "      <td>Investors will continue being interested in th...</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>819</th>\n",
              "      <td>For Q2 2010 , consolidated earnings before tax...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>834</th>\n",
              "      <td>Net interest income totaled EUR 15.9 mn , comp...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>838</th>\n",
              "      <td>Operating profit was EUR 9.8 mn , compared to ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>Pretax profit totalled EUR 2.0 mn , compared t...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841</th>\n",
              "      <td>Previously , EB delivered a custom solution fo...</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>861</th>\n",
              "      <td>EBIT totalled EUR 14.4 mn , compared to a loss...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>873</th>\n",
              "      <td>Mformation and Nokia noted they have establish...</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876</th>\n",
              "      <td>Operating profit totaled EUR 17.7 mn compared ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>877</th>\n",
              "      <td>Profit after taxes was EUR 0.1 mn , compared t...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1157</th>\n",
              "      <td>After the restructuring , UPM 's average paper...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1600</th>\n",
              "      <td>As part of the transaction , the +�+�nekoski p...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1727</th>\n",
              "      <td>The business area 's net sales were slightly o...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1873</th>\n",
              "      <td>Diluted earnings per share ( EPS ) stood at EU...</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1897</th>\n",
              "      <td>Finnish textiles and clothing group Marimekko ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1913</th>\n",
              "      <td>Cost cutting measures , which have produced ar...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1926</th>\n",
              "      <td>The company reported a profit of 800,000 euro ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1975</th>\n",
              "      <td>The mill 's raw material need will increase by...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2071</th>\n",
              "      <td>`` Adjustment to the fall in price level , in ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2137</th>\n",
              "      <td>Finnish business software group AffectoGenimap...</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              statement     label prediction\n",
              "370   11 August 2010 - Finnish measuring equipment m...  negative   positive\n",
              "372   ADP News - Apr 22 , 2009 - Finnish business in...  negative   positive\n",
              "416   Finnish flexible packaging manufacturer Suomin...  positive   negative\n",
              "447   The company also said that in Poland a profita...  positive    neutral\n",
              "480   These moderate but significant changes resulte...  positive    neutral\n",
              "533   According to Finnair Technical Services , the ...   neutral   positive\n",
              "598   Symphony Services provides development service...   neutral   positive\n",
              "620   The office space will rise above the remodeled...   neutral   positive\n",
              "783   Investors will continue being interested in th...  positive    neutral\n",
              "819   For Q2 2010 , consolidated earnings before tax...  positive   negative\n",
              "834   Net interest income totaled EUR 15.9 mn , comp...  positive   negative\n",
              "838   Operating profit was EUR 9.8 mn , compared to ...  positive   negative\n",
              "840   Pretax profit totalled EUR 2.0 mn , compared t...  positive   negative\n",
              "841   Previously , EB delivered a custom solution fo...  positive    neutral\n",
              "861   EBIT totalled EUR 14.4 mn , compared to a loss...  positive   negative\n",
              "873   Mformation and Nokia noted they have establish...  positive    neutral\n",
              "876   Operating profit totaled EUR 17.7 mn compared ...  positive   negative\n",
              "877   Profit after taxes was EUR 0.1 mn , compared t...  positive   negative\n",
              "1157  After the restructuring , UPM 's average paper...   neutral   positive\n",
              "1600  As part of the transaction , the +�+�nekoski p...   neutral   positive\n",
              "1727  The business area 's net sales were slightly o...   neutral   positive\n",
              "1873  Diluted earnings per share ( EPS ) stood at EU...  negative   positive\n",
              "1897  Finnish textiles and clothing group Marimekko ...  negative   positive\n",
              "1913  Cost cutting measures , which have produced ar...  positive   negative\n",
              "1926  The company reported a profit of 800,000 euro ...   neutral   negative\n",
              "1975  The mill 's raw material need will increase by...   neutral   positive\n",
              "2071  `` Adjustment to the fall in price level , in ...  negative    neutral\n",
              "2137  Finnish business software group AffectoGenimap...  negative   positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dEFyc327pGPF",
        "outputId": "f297fd62-3a87-42f7-be61-348d126b0baa"
      },
      "source": [
        "test.iloc[861]['statement']"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'EBIT totalled EUR 14.4 mn , compared to a loss of EUR 0.3 mn in the corresponding period in 2009 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "G5yzO57Ytyr9",
        "outputId": "ed97eaa4-c49e-4350-fa1a-a5f745e10288"
      },
      "source": [
        "test[test['prediction'].astype(str).str.lower() != test['label'].astype(str).str.lower()]"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>label</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>At this growth rate , paying off the national ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>An  of the invention , released by the Patent ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>807</th>\n",
              "      <td>Return on investment was 16.6 % compared to 15...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>The company 's net profit amounted to EE 55.5 ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Neste Shipping is the most likely to remain Fi...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>Aldata Solution , a global company engaged in ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1647</th>\n",
              "      <td>In 2008 Stockmann earned 3.398 million lats in...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1892</th>\n",
              "      <td>The company reported today an operating loss o...</td>\n",
              "      <td>negative</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1897</th>\n",
              "      <td>Finnish textiles and clothing group Marimekko ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1898</th>\n",
              "      <td>In January-June 2010 , diluted loss per share ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023</th>\n",
              "      <td>Frost sold shares for $ 19 million at $ 6.06-7...</td>\n",
              "      <td>negative</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2071</th>\n",
              "      <td>`` Adjustment to the fall in price level , in ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              statement     label prediction\n",
              "396   At this growth rate , paying off the national ...  negative    neutral\n",
              "540   An  of the invention , released by the Patent ...   neutral   negative\n",
              "807   Return on investment was 16.6 % compared to 15...  positive   negative\n",
              "884   The company 's net profit amounted to EE 55.5 ...  positive   negative\n",
              "998   Neste Shipping is the most likely to remain Fi...   neutral   negative\n",
              "1594  Aldata Solution , a global company engaged in ...   neutral   positive\n",
              "1647  In 2008 Stockmann earned 3.398 million lats in...   neutral   positive\n",
              "1892  The company reported today an operating loss o...  negative    neutral\n",
              "1897  Finnish textiles and clothing group Marimekko ...  negative   positive\n",
              "1898  In January-June 2010 , diluted loss per share ...  negative   positive\n",
              "2023  Frost sold shares for $ 19 million at $ 6.06-7...  negative    neutral\n",
              "2071  `` Adjustment to the fall in price level , in ...  negative    neutral"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "5IMqNpR_-Kko",
        "outputId": "1387e74b-75dc-4875-a302-9eed171f88b3"
      },
      "source": [
        "fiqa_headline.describe()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>info</th>\n",
              "      <th>snippets</th>\n",
              "      <th>sentiment_score</th>\n",
              "      <th>target</th>\n",
              "      <th>aspects</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>436</td>\n",
              "      <td>436</td>\n",
              "      <td>436</td>\n",
              "      <td>436</td>\n",
              "      <td>436</td>\n",
              "      <td>436</td>\n",
              "      <td>436</td>\n",
              "      <td>436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>436</td>\n",
              "      <td>436</td>\n",
              "      <td>432</td>\n",
              "      <td>364</td>\n",
              "      <td>200</td>\n",
              "      <td>79</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Aspen to Buy Anaesthetics From AstraZeneca for...</td>\n",
              "      <td>[{'snippets': '['to Withdraw Staff From']', 't...</td>\n",
              "      <td>['debt fears grow']</td>\n",
              "      <td>0</td>\n",
              "      <td>Tesco</td>\n",
              "      <td>['Corporate/M&amp;A/M&amp;A']</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>38</td>\n",
              "      <td>256</td>\n",
              "      <td>244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 sentence  ... prediction\n",
              "count                                                 436  ...        436\n",
              "unique                                                436  ...          3\n",
              "top     Aspen to Buy Anaesthetics From AstraZeneca for...  ...    neutral\n",
              "freq                                                    1  ...        244\n",
              "\n",
              "[4 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGA8JGXttDV3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "d2f990626d79432492377d63ee625583",
            "d5980879a35d4b99a0e6183772836f99",
            "2338eae2314f4e3e8433ac62ae7843d9",
            "b17b9e485b50428bad0efcec801479a9",
            "e942354fa649447c972eed09cbc06f1e",
            "7b8a5dd1533d42c68c820babb0eedb51",
            "bbdbd8f554a04d3baddd82574ea213cb",
            "a3ae97253c4e4f3a8e291f11e230abf9"
          ]
        },
        "outputId": "7c99f411-fd9f-45c7-f60f-840daf535fea"
      },
      "source": [
        "fiqa_headline['prediction'] = fiqa_headline['sentence'].progress_apply(lambda x:str(learner.predict(x)[0]))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2f990626d79432492377d63ee625583",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=436.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uYjuh0wyjC_e",
        "outputId": "447359fc-c3da-43ca-bfcd-4c8a04ba1a8b"
      },
      "source": [
        "fiqa_headline['sentence'].head(1).values[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Royal Mail chairman Donald Brydon set to step down'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "fQQEenWMN9l6",
        "outputId": "e8ffbba1-0dbe-4702-b321-cae4a95f0d77"
      },
      "source": [
        "fiqa_headline[fiqa_headline['prediction'].astype(str).str.lower() != fiqa_headline['sentiment'].astype(str).str.lower()]"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>info</th>\n",
              "      <th>snippets</th>\n",
              "      <th>sentiment_score</th>\n",
              "      <th>target</th>\n",
              "      <th>aspects</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>Analyst Views: Astrazeneca shares have seen re...</td>\n",
              "      <td>[{'snippets': '['shares have seen recent volat...</td>\n",
              "      <td>['shares have seen recent volatility']</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>Astrazeneca</td>\n",
              "      <td>['Market/Volatility']</td>\n",
              "      <td>negative</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>ConAgra Names Former Hillshire Farms CEO Conno...</td>\n",
              "      <td>[{'snippets': '['Farms CEO Connolly to Top Pos...</td>\n",
              "      <td>['Farms CEO Connolly to Top Pos']</td>\n",
              "      <td>0.101</td>\n",
              "      <td>ConAgra</td>\n",
              "      <td>['Corporate/Appointment']</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>Relief for Lewis as Tesco sees sales grow for ...</td>\n",
              "      <td>[{'snippets': '['sees sales grow']', 'target':...</td>\n",
              "      <td>['sees sales grow']</td>\n",
              "      <td>0.42</td>\n",
              "      <td>Tesco</td>\n",
              "      <td>['Corporate/Sales']</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>Credit Suisse poaches Prudential's Thiam for A...</td>\n",
              "      <td>[{'snippets': '['poaches Prudential's Thiam fo...</td>\n",
              "      <td>['poaches Prudential's Thiam for Asian push']</td>\n",
              "      <td>0.125</td>\n",
              "      <td>Credit Suisse</td>\n",
              "      <td>['Corporate/Strategy']</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>Aviva shuts Friends Life head office in rapid ...</td>\n",
              "      <td>[{'snippets': '['shuts Friends Life head offic...</td>\n",
              "      <td>['shuts Friends Life head office in rapid inte...</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>Friends Life</td>\n",
              "      <td>['Corporate/Strategy/Corporate Expansion']</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>Nine banks including Barclays, Citi, agree to ...</td>\n",
              "      <td>[{'snippets': '['agree to pay $2 billion to se...</td>\n",
              "      <td>['agree to pay $2 billion to settle forex .']</td>\n",
              "      <td>-0.647</td>\n",
              "      <td>Citi</td>\n",
              "      <td>['Corporate/Legal/Settlement']</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>AB InBev attacks SABMiller bid rebuffal</td>\n",
              "      <td>[{'snippets': '['attacks SABMiller bid rebuffa...</td>\n",
              "      <td>['attacks SABMiller bid rebuffal']</td>\n",
              "      <td>-0.158</td>\n",
              "      <td>SABMiller</td>\n",
              "      <td>['Corporate/M&amp;A/M&amp;A']</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>HSBC appoints business leaders to board</td>\n",
              "      <td>[{'snippets': '['appoints business leaders to ...</td>\n",
              "      <td>['appoints business leaders to board']</td>\n",
              "      <td>0.154</td>\n",
              "      <td>HSBC</td>\n",
              "      <td>['Corporate/Appointment']</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1112</th>\n",
              "      <td>CompaniesTesco off to a bad start over Xmas â€...</td>\n",
              "      <td>[{'snippets': '['off to a bad start over Xmas'...</td>\n",
              "      <td>['off to a bad start over Xmas']</td>\n",
              "      <td>-0.604</td>\n",
              "      <td>Tesco</td>\n",
              "      <td>['Stock/Price Action']</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1373</th>\n",
              "      <td>Tesco breaks its downward slide by cutting sal...</td>\n",
              "      <td>[{'snippets': '['by cutting sales decline']', ...</td>\n",
              "      <td>['by cutting sales decline']</td>\n",
              "      <td>0.172</td>\n",
              "      <td>Tesco</td>\n",
              "      <td>['Corporate/Sales']</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1381</th>\n",
              "      <td>AB InBev to Sell SABMiller Stake in China's Sn...</td>\n",
              "      <td>[{'snippets': '['to Sell SABMiller Stake in']'...</td>\n",
              "      <td>['to Sell SABMiller Stake in']</td>\n",
              "      <td>-0.045</td>\n",
              "      <td>SABMiller</td>\n",
              "      <td>['Stock/Signal/Sell Signal']</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1581</th>\n",
              "      <td>Berkshire discloses unit's ties to Iran, opens...</td>\n",
              "      <td>[{'snippets': '['discloses unit's ties to Iran...</td>\n",
              "      <td>['discloses unit's ties to Iran, opens probe']</td>\n",
              "      <td>-0.288</td>\n",
              "      <td>Berkshire</td>\n",
              "      <td>['Corporate/Company Communication']</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599</th>\n",
              "      <td>Royal Mail turnaround proving expensive in tou...</td>\n",
              "      <td>[{'snippets': '['in tough UK market']', 'targe...</td>\n",
              "      <td>['in tough UK market']</td>\n",
              "      <td>-0.057</td>\n",
              "      <td>Royal Mail</td>\n",
              "      <td>['Market/Market']</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  ... prediction\n",
              "123   Analyst Views: Astrazeneca shares have seen re...  ...    neutral\n",
              "128   ConAgra Names Former Hillshire Farms CEO Conno...  ...    neutral\n",
              "171   Relief for Lewis as Tesco sees sales grow for ...  ...   negative\n",
              "264   Credit Suisse poaches Prudential's Thiam for A...  ...    neutral\n",
              "405   Aviva shuts Friends Life head office in rapid ...  ...   negative\n",
              "764   Nine banks including Barclays, Citi, agree to ...  ...   positive\n",
              "942             AB InBev attacks SABMiller bid rebuffal  ...   positive\n",
              "991             HSBC appoints business leaders to board  ...    neutral\n",
              "1112  CompaniesTesco off to a bad start over Xmas â€...  ...   positive\n",
              "1373  Tesco breaks its downward slide by cutting sal...  ...   negative\n",
              "1381  AB InBev to Sell SABMiller Stake in China's Sn...  ...   positive\n",
              "1581  Berkshire discloses unit's ties to Iran, opens...  ...   positive\n",
              "1599  Royal Mail turnaround proving expensive in tou...  ...   negative\n",
              "\n",
              "[13 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KKFlqSF-uyDa",
        "outputId": "09b8f3fb-740b-4cf5-efaf-c9d51b213056"
      },
      "source": [
        "fiqa_headline.loc[764].sentence"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Nine banks including Barclays, Citi, agree to pay $2 billion to settle forex ...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "JhkFUTqd96Cv",
        "outputId": "0202df77-54d4-41e0-c81f-b7096ff9196a"
      },
      "source": [
        "fiqa_headline[fiqa_headline['prediction'].astype(str).str.lower() != fiqa_headline['sentiment'].astype(str).str.lower()]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>info</th>\n",
              "      <th>snippets</th>\n",
              "      <th>sentiment_score</th>\n",
              "      <th>target</th>\n",
              "      <th>aspects</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Royal Mail chairman Donald Brydon set to step ...</td>\n",
              "      <td>[{'snippets': '['set to step down']', 'target'...</td>\n",
              "      <td>['set to step down']</td>\n",
              "      <td>-0.374</td>\n",
              "      <td>Royal Mail</td>\n",
              "      <td>['Corporate/Appointment']</td>\n",
              "      <td>negative</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Stakes High for AstraZeneca Heart Drug Facing ...</td>\n",
              "      <td>[{'snippets': '['Facing Tough Competition']', ...</td>\n",
              "      <td>['Facing Tough Competition']</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>AstraZeneca</td>\n",
              "      <td>['Corporate/Risks']</td>\n",
              "      <td>negative</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Insight hires Aviva's David Hillier for multi-...</td>\n",
              "      <td>[{'snippets': '['hires Aviva's David Hillier f...</td>\n",
              "      <td>['hires Aviva's David Hillier for multi-asset ...</td>\n",
              "      <td>0.137</td>\n",
              "      <td>Insight</td>\n",
              "      <td>['Corporate/Appointment/Executive Appointment']</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Tesco sells Blinkbox and broadband service to ...</td>\n",
              "      <td>[{'snippets': '['sells Blinkbox and broadband ...</td>\n",
              "      <td>['sells Blinkbox and broadband service to']</td>\n",
              "      <td>0.136</td>\n",
              "      <td>TalkTalk</td>\n",
              "      <td>['Corporate/Sales/Deal']</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Morning Agenda: Shire's Deal for NPS</td>\n",
              "      <td>[{'snippets': '['Shire's Deal for NPS']', 'tar...</td>\n",
              "      <td>['Shire's Deal for NPS']</td>\n",
              "      <td>0.195</td>\n",
              "      <td>Shire</td>\n",
              "      <td>['Corporate/Sales/Deal']</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1742</th>\n",
              "      <td>London Stock Exchange Shareholders Approve Mer...</td>\n",
              "      <td>[{'snippets': '['Shareholders Approve Merger W...</td>\n",
              "      <td>['Shareholders Approve Merger With']</td>\n",
              "      <td>0.406</td>\n",
              "      <td>London Stock Exchange</td>\n",
              "      <td>['Corporate/M&amp;A/M&amp;A']</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1743</th>\n",
              "      <td>UPDATE 1-Berkshire applies to boost Wells Farg...</td>\n",
              "      <td>[{'snippets': '['applies to boost Wells Fargo ...</td>\n",
              "      <td>['applies to boost Wells Fargo stake above 10 ...</td>\n",
              "      <td>0.432</td>\n",
              "      <td>Wells Fargo</td>\n",
              "      <td>['Stock/Signal/Sell Signal']</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1748</th>\n",
              "      <td>Berkshire applies to boost Wells Fargo stake a...</td>\n",
              "      <td>[{'snippets': '['applies to boost Wells Fargo ...</td>\n",
              "      <td>['applies to boost Wells Fargo stake above 10 ...</td>\n",
              "      <td>0.484</td>\n",
              "      <td>Wells Fargo</td>\n",
              "      <td>['Stock/Signal/Buy Signal']</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1750</th>\n",
              "      <td>Aviva, M&amp;G suspend property funds as investors...</td>\n",
              "      <td>[{'snippets': '['M&amp;G suspend property funds as...</td>\n",
              "      <td>['M&amp;G suspend property funds as investors panic']</td>\n",
              "      <td>-0.807</td>\n",
              "      <td>M&amp;G</td>\n",
              "      <td>['Corporate/Risks']</td>\n",
              "      <td>negative</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1779</th>\n",
              "      <td>EasyJet attracts more passengers in June but s...</td>\n",
              "      <td>[{'snippets': '['attracts more passengers']', ...</td>\n",
              "      <td>['attracts more passengers']</td>\n",
              "      <td>0.259</td>\n",
              "      <td>Ryanair</td>\n",
              "      <td>['Corporate/Sales/Sales']</td>\n",
              "      <td>positive</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>232 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  ... prediction\n",
              "1     Royal Mail chairman Donald Brydon set to step ...  ...    neutral\n",
              "7     Stakes High for AstraZeneca Heart Drug Facing ...  ...    neutral\n",
              "22    Insight hires Aviva's David Hillier for multi-...  ...    neutral\n",
              "32    Tesco sells Blinkbox and broadband service to ...  ...    neutral\n",
              "47                 Morning Agenda: Shire's Deal for NPS  ...    neutral\n",
              "...                                                 ...  ...        ...\n",
              "1742  London Stock Exchange Shareholders Approve Mer...  ...    neutral\n",
              "1743  UPDATE 1-Berkshire applies to boost Wells Farg...  ...    neutral\n",
              "1748  Berkshire applies to boost Wells Fargo stake a...  ...    neutral\n",
              "1750  Aviva, M&G suspend property funds as investors...  ...    neutral\n",
              "1779  EasyJet attracts more passengers in June but s...  ...    neutral\n",
              "\n",
              "[232 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "5cb9042e69784d478e88f35e63aa49e8",
            "159f239f07c6489988969f8b7725eb64",
            "ccdb0405eb5c49c6b3f4b99372472c8b",
            "bcf1344f8b7a429c86f777d5f9217102",
            "536c9de55c5c4bf587638362e72ab152",
            "1c68a320eb0b4aff9f300e67cd37ba8b",
            "234b549b5a76411c8a8c9b7559eb185e",
            "b390092b8d6b497bb63216d2b5b6b975"
          ]
        },
        "id": "RSt7q8FX-1R-",
        "outputId": "89772d78-f610-4832-95cc-da8d79ce135e"
      },
      "source": [
        "fiqa_post['prediction'] = fiqa_post['sentence'].progress_apply(lambda x:str(learner.predict(x)[0]))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5cb9042e69784d478e88f35e63aa49e8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=675.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C4H7Y7PyOGJ8",
        "outputId": "32402a29-2c93-4d67-de21-ece033fb9329"
      },
      "source": [
        "fiqa_post[fiqa_post['prediction'].astype(str).str.lower() != fiqa_post['sentiment'].astype(str).str.lower()]"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>info</th>\n",
              "      <th>snippets</th>\n",
              "      <th>sentiment_score</th>\n",
              "      <th>target</th>\n",
              "      <th>aspects</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15031</th>\n",
              "      <td>stole my tweet. really wouldn't be surprised i...</td>\n",
              "      <td>[{'snippets': '[\"wouldn't be surprised if we t...</td>\n",
              "      <td>[\"wouldn't be surprised if we took out 423\"]</td>\n",
              "      <td>0.142</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>['Stock/Price Action']</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15034</th>\n",
              "      <td>$DPZ broke out now of his bull flag channel an...</td>\n",
              "      <td>[{'snippets': '['broke out now of his bull fla...</td>\n",
              "      <td>['broke out now of his bull flag channel and m...</td>\n",
              "      <td>0.369</td>\n",
              "      <td>DPZ</td>\n",
              "      <td>['Stock/Price Action/Bullish/Bullish Behavior']</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15260</th>\n",
              "      <td>$YELP wayyy overvalued right now IMO. Should b...</td>\n",
              "      <td>[{'snippets': '['wayyy overvalued right now IM...</td>\n",
              "      <td>['wayyy overvalued right now IMO']</td>\n",
              "      <td>-0.451</td>\n",
              "      <td>YELP</td>\n",
              "      <td>['Stock/Price Action/Current Price/Overbought']</td>\n",
              "      <td>negative</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15313</th>\n",
              "      <td>$PRLB hanging tough in down market due to anal...</td>\n",
              "      <td>[{'snippets': '['analyst upgrades last week']'...</td>\n",
              "      <td>['analyst upgrades last week']</td>\n",
              "      <td>0.394</td>\n",
              "      <td>PRLB</td>\n",
              "      <td>['Stock/Coverage/AnalystRatings/Upgrade']</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15329</th>\n",
              "      <td>Surprising to see $JWN and $SKS sales numbers ...</td>\n",
              "      <td>[{'snippets': '['sales numbers still holding u...</td>\n",
              "      <td>['sales numbers still holding up so well']</td>\n",
              "      <td>0.315</td>\n",
              "      <td>SKS</td>\n",
              "      <td>['Corporate/Sales']</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15345</th>\n",
              "      <td>$SPY $MITK fast 56pc dive http://stks.co/3ffN $$</td>\n",
              "      <td>[{'snippets': '['fast 56pc div']', 'sentiment_...</td>\n",
              "      <td>['fast 56pc div']</td>\n",
              "      <td>-0.26</td>\n",
              "      <td>SPY</td>\n",
              "      <td>['Stock/Price Action/Bearish']</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15372</th>\n",
              "      <td>Short interest increases yet again http://stks...</td>\n",
              "      <td>[{'snippets': '['Short interest increases yet ...</td>\n",
              "      <td>['Short interest increases yet again']</td>\n",
              "      <td>-0.342</td>\n",
              "      <td>SPY</td>\n",
              "      <td>['Stock/Fundamentals/Short Interest Rate']</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15462</th>\n",
              "      <td>$GMCR with the way this has been acting, it ma...</td>\n",
              "      <td>[{'snippets': '['horrible action since it hit ...</td>\n",
              "      <td>['horrible action since it hit 70 yesterday']</td>\n",
              "      <td>-0.51</td>\n",
              "      <td>GMCR</td>\n",
              "      <td>['Stock/Price Action/Bearish']</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15648</th>\n",
              "      <td>RT @StockTwits RT @fallondpicks Breadth Consol...</td>\n",
              "      <td>[{'snippets': '['After weeks of steady gains,a...</td>\n",
              "      <td>['After weeks of steady gains,advances in mkt ...</td>\n",
              "      <td>-0.146</td>\n",
              "      <td>QQQ</td>\n",
              "      <td>['Stock/Price Action']</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16200</th>\n",
              "      <td>$PRGN A bottom right here?</td>\n",
              "      <td>[{'snippets': '['A bottom right here?']', 'sen...</td>\n",
              "      <td>['A bottom right here?']</td>\n",
              "      <td>0.041</td>\n",
              "      <td>PRGN</td>\n",
              "      <td>['Stock/Price Action']</td>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16215</th>\n",
              "      <td>$AMZN Trailing 12 months operating cash flow r...</td>\n",
              "      <td>[{'snippets': '['Trailing 12 months operating ...</td>\n",
              "      <td>['Trailing 12 months operating cash flow']</td>\n",
              "      <td>-0.009</td>\n",
              "      <td>AMZN</td>\n",
              "      <td>['Corporate/Financial/Accounting/Cash Flow']</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16270</th>\n",
              "      <td>$RIG whos ever pushing this is crazy, get read...</td>\n",
              "      <td>[{'snippets': '['get ready for suspended divid...</td>\n",
              "      <td>['get ready for suspended dividend']</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>RIG</td>\n",
              "      <td>['Corporate/Dividend Policy']</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16306</th>\n",
              "      <td>@saltwaternurse $INO can test 10 again in next...</td>\n",
              "      <td>[{'snippets': '['time to take some profits her...</td>\n",
              "      <td>['time to take some profits here']</td>\n",
              "      <td>-0.169</td>\n",
              "      <td>INO</td>\n",
              "      <td>['Stock/Price Action/Bearish']</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16403</th>\n",
              "      <td>$PLUG bear raid</td>\n",
              "      <td>[{'snippets': '['bear raid']', 'sentiment_scor...</td>\n",
              "      <td>['bear raid']</td>\n",
              "      <td>-0.48</td>\n",
              "      <td>PLUG</td>\n",
              "      <td>['Stock/Price Action/Bearish']</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16477</th>\n",
              "      <td>$UBNT still having some trouble at the resista...</td>\n",
              "      <td>[{'snippets': '['still having some trouble at ...</td>\n",
              "      <td>['still having some trouble at the resistance ...</td>\n",
              "      <td>0.071</td>\n",
              "      <td>UBNT</td>\n",
              "      <td>['Stock/Price Action']</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16525</th>\n",
              "      <td>$CDTI bounce here on support or H&amp;S setup this...</td>\n",
              "      <td>[{'snippets': '['bounce here on support or H&amp;S...</td>\n",
              "      <td>['bounce here on support or H&amp;S setup this are...</td>\n",
              "      <td>0.374</td>\n",
              "      <td>CDTI</td>\n",
              "      <td>['Stock/Price Action']</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16870</th>\n",
              "      <td>$AAPL at resistance right here...sold my share...</td>\n",
              "      <td>[{'snippets': '['at resistance right here...so...</td>\n",
              "      <td>['at resistance right here...sold my shares']</td>\n",
              "      <td>-0.238</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>['Stock/Price Action/Bearish/Bearish Behavior']</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17219</th>\n",
              "      <td>$AGN and $PYPL under pressure along with the m...</td>\n",
              "      <td>[{'snippets': '['under pressure along with the...</td>\n",
              "      <td>['under pressure along with the market']</td>\n",
              "      <td>0.014</td>\n",
              "      <td>PYPL</td>\n",
              "      <td>['Stock/Price Action/Bearish/Bearish Behavior']</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17591</th>\n",
              "      <td>Hard to find new buyers of $TSLA at 250.  Shor...</td>\n",
              "      <td>[{'snippets': '['Shorts continue to pile in.']...</td>\n",
              "      <td>['Shorts continue to pile in.']</td>\n",
              "      <td>-0.373</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>['Stock/Price Action/Volatility/Short Selling']</td>\n",
              "      <td>negative</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17840</th>\n",
              "      <td>$FB I've been dead on so far. Such a bloated v...</td>\n",
              "      <td>[{'snippets': '['Such a bloated valuation']', ...</td>\n",
              "      <td>['Such a bloated valuation']</td>\n",
              "      <td>-0.536</td>\n",
              "      <td>FB</td>\n",
              "      <td>['Stock/Fundamentals']</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18250</th>\n",
              "      <td>$STX move off the bottom but still in bear mar...</td>\n",
              "      <td>[{'snippets': '['move off the bottom but still...</td>\n",
              "      <td>['move off the bottom but still in bear marke']</td>\n",
              "      <td>-0.421</td>\n",
              "      <td>WDC</td>\n",
              "      <td>['Market/Market']</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18895</th>\n",
              "      <td>Why $TWTR is doomed in 1 chart $FB $GOOG  http...</td>\n",
              "      <td>[{'snippets': '['doomed in 1 chart']', 'sentim...</td>\n",
              "      <td>['doomed in 1 chart']</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>GOOG</td>\n",
              "      <td>['Stock/Technical Analysis']</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence  ... prediction\n",
              "15031  stole my tweet. really wouldn't be surprised i...  ...   negative\n",
              "15034  $DPZ broke out now of his bull flag channel an...  ...   negative\n",
              "15260  $YELP wayyy overvalued right now IMO. Should b...  ...    neutral\n",
              "15313  $PRLB hanging tough in down market due to anal...  ...   negative\n",
              "15329  Surprising to see $JWN and $SKS sales numbers ...  ...   negative\n",
              "15345   $SPY $MITK fast 56pc dive http://stks.co/3ffN $$  ...   positive\n",
              "15372  Short interest increases yet again http://stks...  ...   positive\n",
              "15462  $GMCR with the way this has been acting, it ma...  ...   positive\n",
              "15648  RT @StockTwits RT @fallondpicks Breadth Consol...  ...   positive\n",
              "16200                         $PRGN A bottom right here?  ...   negative\n",
              "16215  $AMZN Trailing 12 months operating cash flow r...  ...   positive\n",
              "16270  $RIG whos ever pushing this is crazy, get read...  ...   positive\n",
              "16306  @saltwaternurse $INO can test 10 again in next...  ...   positive\n",
              "16403                                    $PLUG bear raid  ...   positive\n",
              "16477  $UBNT still having some trouble at the resista...  ...   positive\n",
              "16525  $CDTI bounce here on support or H&S setup this...  ...   negative\n",
              "16870  $AAPL at resistance right here...sold my share...  ...   positive\n",
              "17219  $AGN and $PYPL under pressure along with the m...  ...   positive\n",
              "17591  Hard to find new buyers of $TSLA at 250.  Shor...  ...    neutral\n",
              "17840  $FB I've been dead on so far. Such a bloated v...  ...   positive\n",
              "18250  $STX move off the bottom but still in bear mar...  ...   positive\n",
              "18895  Why $TWTR is doomed in 1 chart $FB $GOOG  http...  ...   positive\n",
              "\n",
              "[22 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-kFNOB7IrAKR",
        "outputId": "565eb640-736b-4f5c-8df4-f1a82746e34b"
      },
      "source": [
        "fiqa_post.loc[15034].sentence"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'$DPZ broke out now of his bull flag channel and make new highs, but volume is very poor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5GpF3rOrAHk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02eyK8rFrAE6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "uCXVHNQz-92L",
        "outputId": "47f8dd69-b3a7-4811-f407-c22c6292a0c9"
      },
      "source": [
        "fiqa_post[fiqa_post['prediction'].astype(str).str.lower() == fiqa_post['sentiment'].astype(str).str.lower()]"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>info</th>\n",
              "      <th>snippets</th>\n",
              "      <th>sentiment_score</th>\n",
              "      <th>target</th>\n",
              "      <th>aspects</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14876</th>\n",
              "      <td>$IACI http://stks.co/tJU Looks good on the wee...</td>\n",
              "      <td>[{'snippets': '['Looks good on the weekly char...</td>\n",
              "      <td>['Looks good on the weekly chart.']</td>\n",
              "      <td>0.379</td>\n",
              "      <td>IACI</td>\n",
              "      <td>['Stock/Technical Analysis']</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14877</th>\n",
              "      <td>$pcln back over \"up\" trendline from 10/4</td>\n",
              "      <td>[{'snippets': '['back over \"up\" trendline']', ...</td>\n",
              "      <td>['back over \"up\" trendline']</td>\n",
              "      <td>0.308</td>\n",
              "      <td>PCLN</td>\n",
              "      <td>['Stock/Price Action/Bullish']</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14882</th>\n",
              "      <td>Profit taking on $AAPL this morning?  That has...</td>\n",
              "      <td>[{'snippets': '['That has to be the pressure o...</td>\n",
              "      <td>['That has to be the pressure on the stock']</td>\n",
              "      <td>0.222</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>['Stock/Price Action/Bearish']</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14905</th>\n",
              "      <td>I'm liking the price action in $SWKS, currentl...</td>\n",
              "      <td>[{'snippets': '[\"I'm liking the price action\"]...</td>\n",
              "      <td>[\"I'm liking the price action\"]</td>\n",
              "      <td>0.603</td>\n",
              "      <td>SWKS</td>\n",
              "      <td>['Stock/Price Action']</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14924</th>\n",
              "      <td>$SPPI..building RS. Sweet. I want this to brea...</td>\n",
              "      <td>[{'snippets': '['I want this to break a new 52...</td>\n",
              "      <td>['I want this to break a new 52week']</td>\n",
              "      <td>0.601</td>\n",
              "      <td>SPPI</td>\n",
              "      <td>['Stock/Price Action/Bullish']</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19031</th>\n",
              "      <td>Yahoo stock is up to $36.46 as the bidding war...</td>\n",
              "      <td>[{'snippets': '['the bidding war picks up for ...</td>\n",
              "      <td>['the bidding war picks up for the company']</td>\n",
              "      <td>0.391</td>\n",
              "      <td>YHOO</td>\n",
              "      <td>['Corporate/M&amp;A/M&amp;A']</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19052</th>\n",
              "      <td>Starbucks shares down as much as ~4.2% $SBUX h...</td>\n",
              "      <td>[{'snippets': '['shares down as much as ~4.2%'...</td>\n",
              "      <td>['shares down as much as ~4.2%']</td>\n",
              "      <td>-0.383</td>\n",
              "      <td>SBUX</td>\n",
              "      <td>['Stock/Price Action/Bearish/Bearish Behavior']</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19095</th>\n",
              "      <td>$SBUX down PM, from $DB downgrade.. PT cut fro...</td>\n",
              "      <td>[{'snippets': '['down PM, from $DB downgrade']...</td>\n",
              "      <td>['down PM, from $DB downgrade']</td>\n",
              "      <td>-0.531</td>\n",
              "      <td>SBUX</td>\n",
              "      <td>['Stock/Coverage/AnalystRatings/Downgrade']</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19119</th>\n",
              "      <td>Qualcomm: 10% Dividend Increase Rewards Patien...</td>\n",
              "      <td>[{'snippets': '['Dividend Increase Rewards Pat...</td>\n",
              "      <td>['Dividend Increase Rewards Patient Investors']</td>\n",
              "      <td>0.484</td>\n",
              "      <td>QCOM</td>\n",
              "      <td>['Corporate/Dividend Policy']</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19163</th>\n",
              "      <td>Notable gainers among liquid option names this...</td>\n",
              "      <td>[{'snippets': '['Notable gainers among liquid ...</td>\n",
              "      <td>['Notable gainers among liquid option names th...</td>\n",
              "      <td>0.513</td>\n",
              "      <td>X</td>\n",
              "      <td>['Stock/Options']</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>205 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence  ... prediction\n",
              "14876  $IACI http://stks.co/tJU Looks good on the wee...  ...   positive\n",
              "14877           $pcln back over \"up\" trendline from 10/4  ...   positive\n",
              "14882  Profit taking on $AAPL this morning?  That has...  ...   positive\n",
              "14905  I'm liking the price action in $SWKS, currentl...  ...   positive\n",
              "14924  $SPPI..building RS. Sweet. I want this to brea...  ...   positive\n",
              "...                                                  ...  ...        ...\n",
              "19031  Yahoo stock is up to $36.46 as the bidding war...  ...   positive\n",
              "19052  Starbucks shares down as much as ~4.2% $SBUX h...  ...   negative\n",
              "19095  $SBUX down PM, from $DB downgrade.. PT cut fro...  ...   negative\n",
              "19119  Qualcomm: 10% Dividend Increase Rewards Patien...  ...   positive\n",
              "19163  Notable gainers among liquid option names this...  ...   positive\n",
              "\n",
              "[205 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxxeo_IUE4hl",
        "outputId": "750339fb-222e-4737-cb6e-84a115d8b0d1"
      },
      "source": [
        "model_path"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/gdrive/MyDrive/source/mjfastbert/models')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6zDUwzhtDV6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "cb52a4fc-0c04-4470-dfba-ad49c8927323"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=\"/content/gdrive/MyDrive/source/mjfastbert/models/bert-base-uncased/\",\n",
        "    tokenizer=transformer_tokenizer\n",
        ")"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model name '/content/gdrive/MyDrive/source/mjfastbert/models/bert-base-uncased/' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-japanese, bert-base-japanese-whole-word-masking, bert-base-japanese-char, bert-base-japanese-char-whole-word-masking, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased, bart-large, bart-large-mnli, bart-cnn, openai-gpt, transfo-xl-wt103, gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2, ctrl, xlnet-base-cased, xlnet-large-cased, xlm-mlm-en-2048, xlm-mlm-ende-1024, xlm-mlm-enfr-1024, xlm-mlm-enro-1024, xlm-mlm-tlm-xnli15-1024, xlm-mlm-xnli15-1024, xlm-clm-enfr-1024, xlm-clm-ende-1024, xlm-mlm-17-1280, xlm-mlm-100-1280, roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector, distilbert-base-uncased, distilbert-base-uncased-distilled-squad, distilbert-base-cased, distilbert-base-cased-distilled-squad, distilbert-base-german-cased, distilbert-base-multilingual-cased, distilbert-base-uncased-finetuned-sst-2-english, albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2, camembert-base, umberto-commoncrawl-cased-v1, umberto-wikipedia-uncased-v1, t5-small, t5-base, t5-large, t5-3b, t5-11b, xlm-roberta-base, xlm-roberta-large, xlm-roberta-large-finetuned-conll02-dutch, xlm-roberta-large-finetuned-conll02-spanish, xlm-roberta-large-finetuned-conll03-english, xlm-roberta-large-finetuned-conll03-german, flaubert-small-cased, flaubert-base-uncased, flaubert-base-cased, flaubert-large-cased). We assumed 'https://s3.amazonaws.com/models.huggingface.co/bert//content/gdrive/MyDrive/source/mjfastbert/models/bert-base-uncased//modelcard.json' was a path or url to a model card file named modelcard.json or a directory containing such a file but couldn't find any such file at this path or url.\n",
            "Creating an empty model card.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, pretrained_config_archive_map, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresolved_config_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_from_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-15bbea507279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"fill-mask\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/source/mjfastbert/models/bert-base-uncased/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformer_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/pipelines.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, modelcard, framework, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m                 \u001b[0;34m\"Trying to load the model with Tensorflow.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m             )\n\u001b[0;32m-> 1091\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelcard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelcard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODEL_WITH_LM_HEAD_MAPPING\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \"\"\"\n\u001b[1;32m    182\u001b[0m         config_dict, _ = PretrainedConfig.get_config_dict(\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_config_archive_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mALL_PRETRAINED_CONFIG_ARCHIVE_MAP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         )\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, pretrained_config_archive_map, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m                     )\n\u001b[1;32m    242\u001b[0m                 )\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Model name '/content/gdrive/MyDrive/source/mjfastbert/models/bert-base-uncased/' was not found in model name list. We assumed 'https://s3.amazonaws.com/models.huggingface.co/bert//content/gdrive/MyDrive/source/mjfastbert/models/bert-base-uncased//config.json' was a path, a model identifier, or url to a configuration file named config.json or a directory containing such a file but couldn't find any such file at this path or url."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "WWFOjeAiEeQP",
        "outputId": "2e47b6e2-86cf-4fa6-8bbc-fa801bc51a25"
      },
      "source": [
        "fill_mask(\"Yahoo stock is up <mask>.\")"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-e6223bff587b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfill_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Yahoo stock is up <mask>.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/pipelines.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_and_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/pipelines.py\u001b[0m in \u001b[0;36m_parse_and_tokenize\u001b[0;34m(self, *texts, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# Filter out features not available on specific models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/pipelines.py\u001b[0m in \u001b[0;36minputs_for_model\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDistilBertConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXLMConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRobertaConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute 'config'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9NQHUFgtDV-"
      },
      "source": [
        "## Export Learner\n",
        "In order to export and load the learner you can do these operations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hKS0wl8tDV_"
      },
      "source": [
        "learner.export(file = models_path / 'transformer.pkl');"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hh89k25tDWC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "05491143-7f2e-4cae-a1db-203f5c02b0bf"
      },
      "source": [
        "export_learner = load_learner(model_path , file = 'transformer.pkl')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WlErEzkANxZ"
      },
      "source": [
        "Further train the model on FIQA dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YRL7QAMvARzP",
        "outputId": "d3ebab03-f1dd-48b5-ddce-850208a2b897"
      },
      "source": [
        "fiqa_databunch = (TextList.from_df(fiqa_post, cols='sentence', processor=transformer_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols= 'sentiment')\n",
        "             .add_test(test)\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "xOtIO7B7Ayc9",
        "outputId": "7e0e2249-d816-41fa-d609-790161be5487"
      },
      "source": [
        "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
        "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
        "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
        "fiqa_databunch.show_batch()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] token : [CLS]\n",
            "[SEP] token : [SEP]\n",
            "[PAD] token : [PAD]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>[CLS] $ aapl a new long if 110 . 61 is broken . targets are 112 . 19 , 119 . 86 &amp; 123 . 82 . bears must reta ##ke 102 . 77 . $ q ##q ##q $ n ##q _ f $ nd ##x ht ##tp ##s : / / t . co / 6 ##l ##3m ##1 ##w ##xc ##h ##w [SEP]</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] tesla to recall 2 , 700 model x suv ##s over seat issue ht ##tp ##s : / / t . co / odp ##ran ##59 ##x ##q $ ts ##la ht ##tp ##s : / / t . co / x ##vn ##4b ##li ##w ##py ht ##tp ##s : / / t . co / th ##f ##v ##wt ##nr ##ps [SEP] [PAD]</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] $ sd ##s + 1 . 46 % 15 . 32 , picking up some speed . may 16 calls now + 35 % . 19 : ht ##tp : / / st ##ks . co / 3 ##ei ##k , next week $ 16 calls . 11 ##c : ht ##tp : / / st ##ks . co / 3 ##ei ##l [SEP] [PAD]</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] $ ts ##la recalls 2 , 700 model x vehicles ; shares volatile ht ##tp ##s : / / t . co / tc ##k ##q ##zn ##mi ##q ##x # ts ##la # tech # stock ##market ht ##tp ##s : / / t . co / fem ##h ##j ##tam ##q ##j [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] most bullish stocks on twitter during this dip . $ yhoo $ gd ##x $ goo ##gl $ st ##z $ gold $ ew $ vz $ cel ##g $ sbu ##x $ sc ##ty more : ht ##tp ##s : / / t . co / iu ##z ##je ##lf ##wt ##3 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WeTLPcfB1r0"
      },
      "source": [
        "new_pretrained_language_model_path = Path(\".\") / \"/content/gdrive/MyDrive/source/mjfastbert/models/FinBERT-phrasebank-fiqa\""
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtvMPiXwKzVP",
        "outputId": "ec082399-ca07-40c9-fbde-6e796672e578"
      },
      "source": [
        "config = config_class.from_pretrained(new_pretrained_language_model_path)\n",
        "config.num_labels = 3\n",
        "config.use_bfloat16 = use_fp16\n",
        "print(config)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertConfig {\n",
            "  \"architectures\": null,\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 3,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30873\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USFbo7PALDEX"
      },
      "source": [
        "transformer_model = model_class.from_pretrained(new_pretrained_language_model_path, config = config)\n",
        "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
        "\n",
        "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5unaB5ILLsBC"
      },
      "source": [
        "from fastai.callbacks import *\n",
        "from transformers import AdamW\n",
        "from functools import partial\n",
        "\n",
        "CustomAdamW = partial(AdamW, correct_bias=False)\n",
        "\n",
        "learner = Learner(fiqa_databunch, \n",
        "                  custom_transformer_model, \n",
        "                  opt_func = CustomAdamW, \n",
        "                  metrics=[accuracy, error_rate])\n",
        "\n",
        "# Show graph of learner stats and metrics after each epoch.\n",
        "learner.callbacks.append(ShowGraph(learner))\n",
        "\n",
        "# Put learn in FP16 precision mode. --> Seems to not working\n",
        "if use_fp16: learner = learner.to_fp16()"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygj1hTHPLsEd",
        "outputId": "a6066e4e-4cd7-483a-cfec-d3457fc770f9"
      },
      "source": [
        "num_groups = len(learner.layer_groups)\n",
        "print('Learner split in',num_groups,'groups')"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learner split in 1 groups\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rq7wS48Lr-j",
        "outputId": "e0540094-d8b6-4aa5-b881-4d6a56ec8acd"
      },
      "source": [
        "print(learner.model)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CustomTransformerModel(\n",
            "  (transformer): BertForSequenceClassification(\n",
            "    (bert): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(30873, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1U84l0HMMFc"
      },
      "source": [
        "list_layers = [learner.model.transformer.bert.embeddings,\n",
        "              learner.model.transformer.bert.encoder.layer[0],\n",
        "              learner.model.transformer.bert.encoder.layer[1],\n",
        "              learner.model.transformer.bert.encoder.layer[2],\n",
        "              learner.model.transformer.bert.encoder.layer[3],\n",
        "              learner.model.transformer.bert.encoder.layer[4],\n",
        "              learner.model.transformer.bert.encoder.layer[5],\n",
        "              learner.model.transformer.bert.encoder.layer[6],\n",
        "              learner.model.transformer.bert.encoder.layer[7],\n",
        "              learner.model.transformer.bert.encoder.layer[8],\n",
        "              learner.model.transformer.bert.encoder.layer[9],\n",
        "              learner.model.transformer.bert.encoder.layer[10],\n",
        "              learner.model.transformer.bert.encoder.layer[11],\n",
        "              learner.model.transformer.bert.pooler]\n",
        "\n",
        "learner.split(list_layers);"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZGJzNVqMMI6",
        "outputId": "bcfe2fca-2336-4de6-dbc6-3313d3685f0a"
      },
      "source": [
        "num_groups = len(learner.layer_groups)\n",
        "print('Learner split in',num_groups,'groups')"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learner split in 14 groups\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d98akPYLMMDU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goN987IaMXFx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GHrWTznMXJk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mCPm4uxCEp6",
        "outputId": "dc6229e6-9350-44c6-af65-19f44fdfd495"
      },
      "source": [
        "!ls {new_pretrained_language_model_path}"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "config.json  transformer.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIV3GbmitDWE"
      },
      "source": [
        "As mentioned [here](https://docs.fast.ai/basic_train.html#load_learner), you have to be careful that each custom classes - like ``TransformersVocab`` - are first defined before executing ``load_learner``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOyIFdI1tDWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e27986bb-3ee1-4230-9632-8cbc2e001462"
      },
      "source": [
        "export_learner.predict('This is the worst movie of 2020')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category tensor(1), tensor(1), tensor([0.1403, 0.5158, 0.3439]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cPVfm-etDWI"
      },
      "source": [
        "## Creating prediction\n",
        "Now that the model is trained, we want to generate predictions from the test dataset.\n",
        "\n",
        "As specified in Keita Kurita's [article](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/), as the function ``get_preds`` does not return elements in order by default, you will have to resort the elements into their correct order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxAOTr6ntDWJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b4b09c6c-7005-4ed0-f4ef-f7b7890f8da8"
      },
      "source": [
        "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    the get_preds method does not yield the elements in order by default\n",
        "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
        "    \"\"\"\n",
        "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
        "    sampler = [i for i in databunch.dl(ds_type).sampler]\n",
        "    reverse_sampler = np.argsort(sampler)\n",
        "    return preds[reverse_sampler, :]\n",
        "\n",
        "test_preds = get_preds_as_nparray(DatasetType.Test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEgPpJZvRqCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6532ffa-29e4-4d3e-d381-ea61989af03e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<enum 'DatasetType'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aBstwsItDWM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "4340d5d8-5421-4e82-ab69-b9f9cf943192"
      },
      "source": [
        "sample_submission = pd.read_csv('sampleSubmission.csv')\n",
        "sample_submission['Sentiment'] = np.argmax(test_preds,axis=1)\n",
        "sample_submission.to_csv(\"predictions.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-7392dceb0e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sampleSubmission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictions.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sampleSubmission.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctmDJmvbtDWP"
      },
      "source": [
        "We check the order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc98RPuFtDWQ",
        "outputId": "06c25213-8a10-450d-96d2-4db94c8b5e16"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>8545</td>\n",
              "      <td>An</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine effort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  SentenceId                                             Phrase\n",
              "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
              "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
              "2    156063        8545                                                 An\n",
              "3    156064        8545  intermittently pleasing but mostly routine effort\n",
              "4    156065        8545         intermittently pleasing but mostly routine"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVTNa0nitDWT",
        "outputId": "b2aaf830-3994-4d5d-99f8-f25a2e769d03"
      },
      "source": [
        "sample_submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  Sentiment\n",
              "0    156061          2\n",
              "1    156062          2\n",
              "2    156063          2\n",
              "3    156064          2\n",
              "4    156065          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIlucxAUtDWX",
        "outputId": "b48b69f4-678d-4c82-bcd8-45a6ed791b84"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "def create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n",
        "    html = '<a href={filename}>{title}</a>'\n",
        "    html = html.format(title=title,filename=filename)\n",
        "    return HTML(html)\n",
        "\n",
        "# create a link to download the dataframe which was saved with .to_csv method\n",
        "create_download_link(filename='predictions.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<a href=predictions.csv>Download CSV file</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_TJA84sUQxs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "8d3d9c72-28ce-4995-93d1-f5dcdb3ddd1f"
      },
      "source": [
        "TextList.from_df()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-a64f343f0693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlanguage_model_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: language_model_learner() missing 2 required positional arguments: 'data' and 'arch'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cREB0iPWUQ8p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtBjoeI7UQ6g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIUufl83UQ4t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLz_Lp_ytDWa"
      },
      "source": [
        "We can now submit our predictions to Kaggle !  In our example, without playing too much with the parameters, we get a score of 0.70059, which leads us to the 5th position on the leaderboard! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XrnhXDQtDWa"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "In this NoteBook, I explain how to combine the ``transformers`` library with the beloved ``fastai`` library. It aims to make you understand where to look and modify both libraries to make them work together. Likely, it allows you to use **Slanted Triangular Learning Rates**, **Discriminate Learning Rate** and even **Gradual Unfreezing**. As a result, without even tunning the parameters, you can obtain rapidly state-of-the-art results.\n",
        "\n",
        "This year, the transformers became an essential tool to NLP. Because of that, I think that pre-trained transformers architectures will be integrated soon to future versions of fastai. Meanwhile, this tutorial is a good starter.\n",
        "\n",
        "I hope you enjoyed this first article and found it useful. \n",
        "Thanks for reading and don't hesitate in leaving questions or suggestions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTHSa9PbtDWb"
      },
      "source": [
        "# References\n",
        "* Hugging Face, Transformers GitHub (Nov 2019), [https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)\n",
        "* Fast.ai, Fastai documentation (Nov 2019), [https://docs.fast.ai/text.html](https://docs.fast.ai/text.html)\n",
        "* Jeremy Howard & Sebastian Ruder, Universal Language Model Fine-tuning for Text Classification (May 2018), [https://arxiv.org/abs/1801.06146](https://arxiv.org/abs/1801.06146)\n",
        "* Keita Kurita's article : [A Tutorial to Fine-Tuning BERT with Fast AI](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/) (May 2019)\n",
        "* Dev Sharma's article : [Using RoBERTa with Fastai for NLP](https://medium.com/analytics-vidhya/using-roberta-with-fastai-for-nlp-7ed3fed21f6c) (Sep 2019)"
      ]
    }
  ]
}